{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb3fsqEN14w8"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "### Business problem overview\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the top business goal. To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    "In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6mlYbgfUjuY"
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "The telecom company in Southeast Asia is facing an increase in customer churn and wants to reduce the loss of high-value customers. They aim to predict churn in the ninth month using data from the previous three months. The company plans to analyze various factors such as demographics, usage patterns, service quality, and complaints to identify variables that affect churn. They will focus on high-value customers and build machine learning models for churn prediction. These models will help predict churn likelihood and identify important variables to address underlying issues and improve customer satisfaction.\n",
    "\n",
    "These models will serve two purposes.\n",
    "\n",
    "*   First, they will predict whether a high-value customer is likely to churn in\n",
    "the near future. By gaining insights into this aspect, the company can take proactive steps such as offering special plans, discounts, or personalized offers to retain these customers.\n",
    "*   Second, the models will identify important variables that strongly predict churn. These variables will shed light on why customers choose to switch to other networks, enabling the company to address underlying issues and improve customer satisfaction.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LbA-XghZT55"
   },
   "source": [
    "# Tasks Involved\n",
    "\n",
    "**Task 1: Import libraries and load the dataset**\n",
    "\n",
    "**Task 2: Understand and explore the data**\n",
    "*   Analyze different feature types in the data\n",
    "*   Handle missing values by imputation\n",
    "*   Identify the relevant data required for the problem\n",
    "\n",
    "**Task 3: Conduct feature engineering**\n",
    "*   Extract new relevant features from the data set\n",
    "*   Filter high-value customers\n",
    "*   Derive the target variable “churn” based on the existing features\n",
    "\n",
    "**Task 4: Visualize the data**\n",
    "*   Analyze the data to extract relevant insights through informative visualizations\n",
    "*   Look for any outliers and treat them\n",
    "\n",
    "**Task 5: Modeling**\n",
    "*   Divide the data into train-test splits\n",
    "*   Handle class imbalance\n",
    "*   Build different machine learning models and evaluate their performance\n",
    "*   Tune the hyperparameters to optimize the performance for the best model\n",
    "*   Train and evaluate a neural network model with the optimal combination of hyperparameters\n",
    "\n",
    "**Task 6: Business insights and recommendations**\n",
    "*   Understand the profitability of the telecommunication service program, and estimate the impact of your model using misclassification costs\n",
    "*   Propose a solution to leverage customer interaction/feedback data and predict those who are highly likely to churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc7Vumkt14xA"
   },
   "source": [
    "# Task 1: Importing the required libraries and loading the data set\n",
    "\n",
    "**Description**\n",
    "\n",
    "\n",
    "In this task, you will load all the methods and packages required to perform the various tasks in this capstone project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGbN3M4dfy4r"
   },
   "source": [
    "First, import the required packages and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FATks0vWd81X"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFJYv5a0gTX-"
   },
   "source": [
    "Mount Google Drive to your VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROSYshGBQ2de"
   },
   "outputs": [],
   "source": [
    "# Import the required library to mount Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount your Google Drive to the Colab notebook\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q9XkMRZgeEb"
   },
   "source": [
    "Import the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dVrlMmuIRAtM"
   },
   "outputs": [],
   "source": [
    "# Read the training data from a CSV file stored in your Google Drive\n",
    "#churn = pd.read_csv('/content/drive/MyDrive/UMD/telecom_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K1YfGJ8qd81a"
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "churn = pd.read_csv(r\"C:\\Users\\adity\\Downloads\\telecom_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xO8AGhsq4wSC"
   },
   "source": [
    "Checklist:\n",
    "\n",
    "\n",
    "*   Imported the required packages\n",
    "*   Mounted your Google Drive to access the data\n",
    "*   Imported the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtbG26H714xD"
   },
   "source": [
    "# Task 2: Understanding and exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jW2mSbzgzZh"
   },
   "source": [
    "### Description\n",
    "\n",
    "In this task, you will explore the data that you have just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kMmULcO3d81b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>offnet_mou_9</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_ic_mou_9</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>roam_og_mou_9</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_9</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_9</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_9</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_9</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>loc_og_mou_9</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2t_mou_9</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2m_mou_9</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2f_mou_9</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_t2c_mou_9</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>std_og_mou_9</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>isd_og_mou_9</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>spl_og_mou_9</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>og_others_9</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_9</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_9</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_9</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>loc_ic_mou_9</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_9</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_9</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_9</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_9</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>std_ic_mou_9</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_9</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_9</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>ic_others_9</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_9</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>last_day_rch_amt_9</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>date_of_last_rech_data_9</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>total_rech_data_9</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>max_rech_data_9</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_2g_9</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>count_rech_3g_9</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>av_rech_amt_data_9</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_3g_9</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>arpu_2g_9</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>night_pck_user_9</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>monthly_2g_9</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>sachet_2g_9</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>monthly_3g_9</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>21.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>362</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>08-08-2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>6/21/2014</td>\n",
       "      <td>7/16/2014</td>\n",
       "      <td>08-08-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.13</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.57</td>\n",
       "      <td>150.76</td>\n",
       "      <td>109.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>355.074</td>\n",
       "      <td>268.321</td>\n",
       "      <td>86.285</td>\n",
       "      <td>24.11</td>\n",
       "      <td>78.68</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>15.74</td>\n",
       "      <td>99.84</td>\n",
       "      <td>304.76</td>\n",
       "      <td>53.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.88</td>\n",
       "      <td>74.56</td>\n",
       "      <td>7.68</td>\n",
       "      <td>18.34</td>\n",
       "      <td>11.51</td>\n",
       "      <td>75.94</td>\n",
       "      <td>291.86</td>\n",
       "      <td>53.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.39</td>\n",
       "      <td>150.51</td>\n",
       "      <td>299.54</td>\n",
       "      <td>72.11</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>23.43</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.31</td>\n",
       "      <td>178.53</td>\n",
       "      <td>312.44</td>\n",
       "      <td>72.11</td>\n",
       "      <td>1.61</td>\n",
       "      <td>29.91</td>\n",
       "      <td>29.23</td>\n",
       "      <td>116.09</td>\n",
       "      <td>17.48</td>\n",
       "      <td>65.38</td>\n",
       "      <td>375.58</td>\n",
       "      <td>56.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.93</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.09</td>\n",
       "      <td>104.23</td>\n",
       "      <td>408.43</td>\n",
       "      <td>173.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.49</td>\n",
       "      <td>15.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.84</td>\n",
       "      <td>15.01</td>\n",
       "      <td>26.83</td>\n",
       "      <td>104.23</td>\n",
       "      <td>423.28</td>\n",
       "      <td>188.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>384</td>\n",
       "      <td>283</td>\n",
       "      <td>121</td>\n",
       "      <td>44</td>\n",
       "      <td>154</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/25/2014</td>\n",
       "      <td>08-10-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.07</td>\n",
       "      <td>365.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.61</td>\n",
       "      <td>7.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>189.058</td>\n",
       "      <td>210.226</td>\n",
       "      <td>290.714</td>\n",
       "      <td>11.54</td>\n",
       "      <td>55.24</td>\n",
       "      <td>37.26</td>\n",
       "      <td>74.81</td>\n",
       "      <td>143.33</td>\n",
       "      <td>220.59</td>\n",
       "      <td>208.36</td>\n",
       "      <td>118.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.94</td>\n",
       "      <td>7.19</td>\n",
       "      <td>28.74</td>\n",
       "      <td>13.58</td>\n",
       "      <td>14.39</td>\n",
       "      <td>29.34</td>\n",
       "      <td>16.86</td>\n",
       "      <td>38.46</td>\n",
       "      <td>28.16</td>\n",
       "      <td>24.11</td>\n",
       "      <td>21.79</td>\n",
       "      <td>15.61</td>\n",
       "      <td>22.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135.54</td>\n",
       "      <td>45.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>60.66</td>\n",
       "      <td>67.41</td>\n",
       "      <td>67.66</td>\n",
       "      <td>64.81</td>\n",
       "      <td>4.34</td>\n",
       "      <td>26.49</td>\n",
       "      <td>22.58</td>\n",
       "      <td>8.76</td>\n",
       "      <td>41.81</td>\n",
       "      <td>67.41</td>\n",
       "      <td>75.53</td>\n",
       "      <td>9.28</td>\n",
       "      <td>1.48</td>\n",
       "      <td>14.76</td>\n",
       "      <td>22.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.64</td>\n",
       "      <td>108.68</td>\n",
       "      <td>120.94</td>\n",
       "      <td>18.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.56</td>\n",
       "      <td>236.84</td>\n",
       "      <td>96.84</td>\n",
       "      <td>42.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>155.33</td>\n",
       "      <td>412.94</td>\n",
       "      <td>285.46</td>\n",
       "      <td>124.94</td>\n",
       "      <td>115.69</td>\n",
       "      <td>71.11</td>\n",
       "      <td>67.46</td>\n",
       "      <td>148.23</td>\n",
       "      <td>14.38</td>\n",
       "      <td>15.44</td>\n",
       "      <td>38.89</td>\n",
       "      <td>38.98</td>\n",
       "      <td>99.48</td>\n",
       "      <td>122.29</td>\n",
       "      <td>49.63</td>\n",
       "      <td>158.19</td>\n",
       "      <td>229.56</td>\n",
       "      <td>208.86</td>\n",
       "      <td>155.99</td>\n",
       "      <td>345.41</td>\n",
       "      <td>72.41</td>\n",
       "      <td>71.29</td>\n",
       "      <td>28.69</td>\n",
       "      <td>49.44</td>\n",
       "      <td>45.18</td>\n",
       "      <td>177.01</td>\n",
       "      <td>167.09</td>\n",
       "      <td>118.18</td>\n",
       "      <td>21.73</td>\n",
       "      <td>58.34</td>\n",
       "      <td>43.23</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.33</td>\n",
       "      <td>306.66</td>\n",
       "      <td>239.03</td>\n",
       "      <td>171.49</td>\n",
       "      <td>370.04</td>\n",
       "      <td>519.53</td>\n",
       "      <td>395.03</td>\n",
       "      <td>517.74</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>315</td>\n",
       "      <td>116</td>\n",
       "      <td>358</td>\n",
       "      <td>86</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>6/17/2014</td>\n",
       "      <td>7/24/2014</td>\n",
       "      <td>8/14/2014</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/17/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>251.102</td>\n",
       "      <td>508.054</td>\n",
       "      <td>389.500</td>\n",
       "      <td>99.91</td>\n",
       "      <td>54.39</td>\n",
       "      <td>310.98</td>\n",
       "      <td>241.71</td>\n",
       "      <td>123.31</td>\n",
       "      <td>109.01</td>\n",
       "      <td>71.68</td>\n",
       "      <td>113.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.86</td>\n",
       "      <td>44.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.09</td>\n",
       "      <td>39.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.68</td>\n",
       "      <td>34.81</td>\n",
       "      <td>10.61</td>\n",
       "      <td>15.49</td>\n",
       "      <td>107.43</td>\n",
       "      <td>83.21</td>\n",
       "      <td>22.46</td>\n",
       "      <td>65.46</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.91</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>183.03</td>\n",
       "      <td>118.68</td>\n",
       "      <td>37.99</td>\n",
       "      <td>83.03</td>\n",
       "      <td>26.23</td>\n",
       "      <td>14.89</td>\n",
       "      <td>289.58</td>\n",
       "      <td>226.21</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.73</td>\n",
       "      <td>6.53</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.23</td>\n",
       "      <td>16.63</td>\n",
       "      <td>296.11</td>\n",
       "      <td>236.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.09</td>\n",
       "      <td>43.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>223.23</td>\n",
       "      <td>135.31</td>\n",
       "      <td>352.21</td>\n",
       "      <td>362.54</td>\n",
       "      <td>62.08</td>\n",
       "      <td>19.98</td>\n",
       "      <td>8.04</td>\n",
       "      <td>41.73</td>\n",
       "      <td>113.96</td>\n",
       "      <td>64.51</td>\n",
       "      <td>20.28</td>\n",
       "      <td>52.86</td>\n",
       "      <td>57.43</td>\n",
       "      <td>27.09</td>\n",
       "      <td>19.84</td>\n",
       "      <td>65.59</td>\n",
       "      <td>233.48</td>\n",
       "      <td>111.59</td>\n",
       "      <td>48.18</td>\n",
       "      <td>160.19</td>\n",
       "      <td>43.48</td>\n",
       "      <td>66.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.84</td>\n",
       "      <td>1.33</td>\n",
       "      <td>38.56</td>\n",
       "      <td>4.94</td>\n",
       "      <td>13.98</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.99</td>\n",
       "      <td>105.01</td>\n",
       "      <td>4.94</td>\n",
       "      <td>143.83</td>\n",
       "      <td>280.08</td>\n",
       "      <td>216.61</td>\n",
       "      <td>53.13</td>\n",
       "      <td>305.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>230</td>\n",
       "      <td>310</td>\n",
       "      <td>601</td>\n",
       "      <td>410</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>309.876</td>\n",
       "      <td>238.174</td>\n",
       "      <td>163.426</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>76.96</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>45.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>149.44</td>\n",
       "      <td>83.89</td>\n",
       "      <td>58.78</td>\n",
       "      <td>67.64</td>\n",
       "      <td>91.88</td>\n",
       "      <td>124.26</td>\n",
       "      <td>37.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.96</td>\n",
       "      <td>241.33</td>\n",
       "      <td>208.16</td>\n",
       "      <td>98.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>127.28</td>\n",
       "      <td>241.33</td>\n",
       "      <td>208.16</td>\n",
       "      <td>104.59</td>\n",
       "      <td>105.68</td>\n",
       "      <td>88.49</td>\n",
       "      <td>233.81</td>\n",
       "      <td>154.56</td>\n",
       "      <td>106.84</td>\n",
       "      <td>109.54</td>\n",
       "      <td>104.13</td>\n",
       "      <td>48.24</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>214.03</td>\n",
       "      <td>198.04</td>\n",
       "      <td>337.94</td>\n",
       "      <td>202.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.31</td>\n",
       "      <td>216.44</td>\n",
       "      <td>198.29</td>\n",
       "      <td>338.81</td>\n",
       "      <td>205.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>350</td>\n",
       "      <td>287</td>\n",
       "      <td>200</td>\n",
       "      <td>56</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>08-09-2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>06-04-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>50.258</td>\n",
       "      <td>58.810</td>\n",
       "      <td>83.386</td>\n",
       "      <td>170.826</td>\n",
       "      <td>50.16</td>\n",
       "      <td>43.63</td>\n",
       "      <td>85.48</td>\n",
       "      <td>138.79</td>\n",
       "      <td>19.28</td>\n",
       "      <td>13.44</td>\n",
       "      <td>14.46</td>\n",
       "      <td>46.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.16</td>\n",
       "      <td>43.63</td>\n",
       "      <td>85.48</td>\n",
       "      <td>138.79</td>\n",
       "      <td>16.39</td>\n",
       "      <td>8.83</td>\n",
       "      <td>12.38</td>\n",
       "      <td>44.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.56</td>\n",
       "      <td>52.46</td>\n",
       "      <td>97.86</td>\n",
       "      <td>185.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>69.44</td>\n",
       "      <td>57.08</td>\n",
       "      <td>99.94</td>\n",
       "      <td>185.71</td>\n",
       "      <td>28.73</td>\n",
       "      <td>30.03</td>\n",
       "      <td>56.26</td>\n",
       "      <td>68.38</td>\n",
       "      <td>49.19</td>\n",
       "      <td>57.44</td>\n",
       "      <td>62.46</td>\n",
       "      <td>84.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>77.93</td>\n",
       "      <td>87.48</td>\n",
       "      <td>118.73</td>\n",
       "      <td>152.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>77.03</td>\n",
       "      <td>71.06</td>\n",
       "      <td>37.93</td>\n",
       "      <td>52.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.03</td>\n",
       "      <td>71.06</td>\n",
       "      <td>37.93</td>\n",
       "      <td>52.03</td>\n",
       "      <td>155.39</td>\n",
       "      <td>158.76</td>\n",
       "      <td>157.13</td>\n",
       "      <td>205.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>6/19/2014</td>\n",
       "      <td>7/17/2014</td>\n",
       "      <td>8/24/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>429.023</td>\n",
       "      <td>190.704</td>\n",
       "      <td>255.114</td>\n",
       "      <td>114.751</td>\n",
       "      <td>71.03</td>\n",
       "      <td>45.03</td>\n",
       "      <td>76.66</td>\n",
       "      <td>15.23</td>\n",
       "      <td>262.73</td>\n",
       "      <td>49.24</td>\n",
       "      <td>92.08</td>\n",
       "      <td>50.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.03</td>\n",
       "      <td>45.03</td>\n",
       "      <td>76.14</td>\n",
       "      <td>15.23</td>\n",
       "      <td>252.23</td>\n",
       "      <td>48.71</td>\n",
       "      <td>80.63</td>\n",
       "      <td>50.33</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>333.64</td>\n",
       "      <td>93.74</td>\n",
       "      <td>156.78</td>\n",
       "      <td>65.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>333.76</td>\n",
       "      <td>94.81</td>\n",
       "      <td>168.74</td>\n",
       "      <td>65.91</td>\n",
       "      <td>1857.99</td>\n",
       "      <td>1427.04</td>\n",
       "      <td>1896.43</td>\n",
       "      <td>2334.88</td>\n",
       "      <td>248.64</td>\n",
       "      <td>336.96</td>\n",
       "      <td>265.28</td>\n",
       "      <td>231.41</td>\n",
       "      <td>20.24</td>\n",
       "      <td>22.69</td>\n",
       "      <td>2.51</td>\n",
       "      <td>6.19</td>\n",
       "      <td>2126.89</td>\n",
       "      <td>1786.71</td>\n",
       "      <td>2164.23</td>\n",
       "      <td>2572.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2128.41</td>\n",
       "      <td>1788.06</td>\n",
       "      <td>2167.11</td>\n",
       "      <td>2572.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>499</td>\n",
       "      <td>222</td>\n",
       "      <td>294</td>\n",
       "      <td>141</td>\n",
       "      <td>90</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>6/28/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>9/28/2014</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1673</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>1069.180</td>\n",
       "      <td>1349.850</td>\n",
       "      <td>3171.480</td>\n",
       "      <td>500.000</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.23</td>\n",
       "      <td>33.49</td>\n",
       "      <td>31.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.74</td>\n",
       "      <td>12.59</td>\n",
       "      <td>38.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.39</td>\n",
       "      <td>31.38</td>\n",
       "      <td>40.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308.63</td>\n",
       "      <td>447.38</td>\n",
       "      <td>162.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.13</td>\n",
       "      <td>55.14</td>\n",
       "      <td>53.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>422.16</td>\n",
       "      <td>533.91</td>\n",
       "      <td>255.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.30</td>\n",
       "      <td>23.29</td>\n",
       "      <td>12.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.89</td>\n",
       "      <td>31.76</td>\n",
       "      <td>49.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.66</td>\n",
       "      <td>20.08</td>\n",
       "      <td>16.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.86</td>\n",
       "      <td>75.14</td>\n",
       "      <td>77.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487.53</td>\n",
       "      <td>609.24</td>\n",
       "      <td>350.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.14</td>\n",
       "      <td>32.26</td>\n",
       "      <td>27.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.56</td>\n",
       "      <td>221.49</td>\n",
       "      <td>121.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.16</td>\n",
       "      <td>101.46</td>\n",
       "      <td>39.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>427.88</td>\n",
       "      <td>355.23</td>\n",
       "      <td>188.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.89</td>\n",
       "      <td>11.83</td>\n",
       "      <td>30.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.44</td>\n",
       "      <td>126.99</td>\n",
       "      <td>141.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.19</td>\n",
       "      <td>34.24</td>\n",
       "      <td>22.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.54</td>\n",
       "      <td>173.08</td>\n",
       "      <td>193.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626.46</td>\n",
       "      <td>558.04</td>\n",
       "      <td>428.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.06</td>\n",
       "      <td>14.53</td>\n",
       "      <td>31.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.74</td>\n",
       "      <td>15.19</td>\n",
       "      <td>15.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1580</td>\n",
       "      <td>790</td>\n",
       "      <td>3638</td>\n",
       "      <td>0</td>\n",
       "      <td>1580</td>\n",
       "      <td>790</td>\n",
       "      <td>1580</td>\n",
       "      <td>0</td>\n",
       "      <td>6/27/2014</td>\n",
       "      <td>7/25/2014</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>779</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>802</td>\n",
       "      <td>57.74</td>\n",
       "      <td>19.38</td>\n",
       "      <td>18.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>378.721</td>\n",
       "      <td>492.223</td>\n",
       "      <td>137.362</td>\n",
       "      <td>166.787</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>33.46</td>\n",
       "      <td>94.66</td>\n",
       "      <td>80.63</td>\n",
       "      <td>136.48</td>\n",
       "      <td>108.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297.13</td>\n",
       "      <td>217.59</td>\n",
       "      <td>12.49</td>\n",
       "      <td>26.13</td>\n",
       "      <td>80.96</td>\n",
       "      <td>70.58</td>\n",
       "      <td>50.54</td>\n",
       "      <td>34.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>378.09</td>\n",
       "      <td>288.18</td>\n",
       "      <td>63.04</td>\n",
       "      <td>60.71</td>\n",
       "      <td>116.56</td>\n",
       "      <td>133.43</td>\n",
       "      <td>22.58</td>\n",
       "      <td>7.33</td>\n",
       "      <td>13.69</td>\n",
       "      <td>10.04</td>\n",
       "      <td>75.69</td>\n",
       "      <td>74.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.26</td>\n",
       "      <td>143.48</td>\n",
       "      <td>98.28</td>\n",
       "      <td>81.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>508.36</td>\n",
       "      <td>431.66</td>\n",
       "      <td>171.56</td>\n",
       "      <td>142.18</td>\n",
       "      <td>23.84</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.31</td>\n",
       "      <td>4.03</td>\n",
       "      <td>57.58</td>\n",
       "      <td>13.98</td>\n",
       "      <td>15.48</td>\n",
       "      <td>17.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.43</td>\n",
       "      <td>23.83</td>\n",
       "      <td>15.79</td>\n",
       "      <td>21.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.43</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.65</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.43</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.53</td>\n",
       "      <td>103.86</td>\n",
       "      <td>28.49</td>\n",
       "      <td>16.54</td>\n",
       "      <td>34.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>437</td>\n",
       "      <td>601</td>\n",
       "      <td>120</td>\n",
       "      <td>186</td>\n",
       "      <td>90</td>\n",
       "      <td>154</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>6/25/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/30/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/23/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>356.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>750.95</td>\n",
       "      <td>11.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315</td>\n",
       "      <td>21.03</td>\n",
       "      <td>910.65</td>\n",
       "      <td>122.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>119.518</td>\n",
       "      <td>247.435</td>\n",
       "      <td>170.231</td>\n",
       "      <td>160.042</td>\n",
       "      <td>33.89</td>\n",
       "      <td>30.11</td>\n",
       "      <td>22.43</td>\n",
       "      <td>27.84</td>\n",
       "      <td>63.48</td>\n",
       "      <td>54.16</td>\n",
       "      <td>78.34</td>\n",
       "      <td>123.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.89</td>\n",
       "      <td>30.11</td>\n",
       "      <td>22.43</td>\n",
       "      <td>27.84</td>\n",
       "      <td>38.03</td>\n",
       "      <td>40.06</td>\n",
       "      <td>34.93</td>\n",
       "      <td>37.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.93</td>\n",
       "      <td>70.18</td>\n",
       "      <td>57.36</td>\n",
       "      <td>65.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.45</td>\n",
       "      <td>14.09</td>\n",
       "      <td>43.41</td>\n",
       "      <td>83.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>14.09</td>\n",
       "      <td>43.41</td>\n",
       "      <td>86.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98.04</td>\n",
       "      <td>84.28</td>\n",
       "      <td>100.78</td>\n",
       "      <td>151.33</td>\n",
       "      <td>129.34</td>\n",
       "      <td>124.34</td>\n",
       "      <td>49.93</td>\n",
       "      <td>313.38</td>\n",
       "      <td>132.94</td>\n",
       "      <td>96.24</td>\n",
       "      <td>122.58</td>\n",
       "      <td>65.06</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>262.69</td>\n",
       "      <td>220.59</td>\n",
       "      <td>172.51</td>\n",
       "      <td>378.93</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.38</td>\n",
       "      <td>32.86</td>\n",
       "      <td>78.21</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.16</td>\n",
       "      <td>78.21</td>\n",
       "      <td>1.74</td>\n",
       "      <td>5.56</td>\n",
       "      <td>303.98</td>\n",
       "      <td>327.31</td>\n",
       "      <td>219.86</td>\n",
       "      <td>412.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.11</td>\n",
       "      <td>28.49</td>\n",
       "      <td>45.59</td>\n",
       "      <td>28.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>195</td>\n",
       "      <td>210</td>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>154</td>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>6/29/2014</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>8/29/2014</td>\n",
       "      <td>9/20/2014</td>\n",
       "      <td>110</td>\n",
       "      <td>154</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>902</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0        109             0.0             0.0             0.0   \n",
       "1        109             0.0             0.0             0.0   \n",
       "2        109             0.0             0.0             0.0   \n",
       "3        109             0.0             0.0             0.0   \n",
       "4        109             0.0             0.0             0.0   \n",
       "5        109             0.0             0.0             0.0   \n",
       "6        109             0.0             0.0             0.0   \n",
       "7        109             0.0             0.0             0.0   \n",
       "8        109             0.0             0.0             0.0   \n",
       "9        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "5            6/30/2014            7/31/2014            8/31/2014   \n",
       "6            6/30/2014            7/31/2014            8/31/2014   \n",
       "7            6/30/2014            7/31/2014            8/31/2014   \n",
       "8            6/30/2014            7/31/2014            8/31/2014   \n",
       "9            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9    arpu_6    arpu_7    arpu_8   arpu_9  onnet_mou_6  \\\n",
       "0            9/30/2014   197.385   214.816   213.803   21.100          NaN   \n",
       "1            9/30/2014    34.047   355.074   268.321   86.285        24.11   \n",
       "2            9/30/2014   167.690   189.058   210.226  290.714        11.54   \n",
       "3            9/30/2014   221.338   251.102   508.054  389.500        99.91   \n",
       "4            9/30/2014   261.636   309.876   238.174  163.426        50.31   \n",
       "5            9/30/2014    50.258    58.810    83.386  170.826        50.16   \n",
       "6            9/30/2014   429.023   190.704   255.114  114.751        71.03   \n",
       "7            9/30/2014  1069.180  1349.850  3171.480  500.000        57.84   \n",
       "8            9/30/2014   378.721   492.223   137.362  166.787       413.69   \n",
       "9            9/30/2014   119.518   247.435   170.231  160.042        33.89   \n",
       "\n",
       "   onnet_mou_7  onnet_mou_8  onnet_mou_9  offnet_mou_6  offnet_mou_7  \\\n",
       "0          NaN         0.00          NaN           NaN           NaN   \n",
       "1        78.68         7.68        18.34         15.74         99.84   \n",
       "2        55.24        37.26        74.81        143.33        220.59   \n",
       "3        54.39       310.98       241.71        123.31        109.01   \n",
       "4       149.44        83.89        58.78         76.96         91.88   \n",
       "5        43.63        85.48       138.79         19.28         13.44   \n",
       "6        45.03        76.66        15.23        262.73         49.24   \n",
       "7        54.68        52.29          NaN        453.43        567.16   \n",
       "8       351.03        35.08        33.46         94.66         80.63   \n",
       "9        30.11        22.43        27.84         63.48         54.16   \n",
       "\n",
       "   offnet_mou_8  offnet_mou_9  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0          0.00           NaN            NaN            NaN           0.00   \n",
       "1        304.76         53.76           0.00           0.00           0.00   \n",
       "2        208.36        118.91           0.00           0.00           0.00   \n",
       "3         71.68        113.54           0.00          54.86          44.38   \n",
       "4        124.26         45.81           0.00           0.00           0.00   \n",
       "5         14.46         46.91           0.00           0.00           0.00   \n",
       "6         92.08         50.33           0.00           0.00           0.00   \n",
       "7        325.91           NaN          16.23          33.49          31.64   \n",
       "8        136.48        108.71           0.00           0.00           0.00   \n",
       "9         78.34        123.48           0.00           0.00           0.00   \n",
       "\n",
       "   roam_ic_mou_9  roam_og_mou_6  roam_og_mou_7  roam_og_mou_8  roam_og_mou_9  \\\n",
       "0            NaN            NaN            NaN           0.00            NaN   \n",
       "1           0.00           0.00           0.00           0.00           0.00   \n",
       "2          38.49           0.00           0.00           0.00          70.94   \n",
       "3           0.00           0.00          28.09          39.04           0.00   \n",
       "4           0.00           0.00           0.00           0.00           0.00   \n",
       "5           0.00           0.00           0.00           0.00           0.00   \n",
       "6           0.00           0.00           0.00           0.00           0.00   \n",
       "7            NaN          23.74          12.59          38.06            NaN   \n",
       "8           0.00           0.00           0.00           0.00           0.00   \n",
       "9           0.00           0.00           0.00           0.00           0.00   \n",
       "\n",
       "   loc_og_t2t_mou_6  loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2t_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1             23.88             74.56              7.68             18.34   \n",
       "2              7.19             28.74             13.58             14.39   \n",
       "3             73.68             34.81             10.61             15.49   \n",
       "4             50.31            149.44             83.89             58.78   \n",
       "5             50.16             43.63             85.48            138.79   \n",
       "6             71.03             45.03             76.14             15.23   \n",
       "7             51.39             31.38             40.28               NaN   \n",
       "8            297.13            217.59             12.49             26.13   \n",
       "9             33.89             30.11             22.43             27.84   \n",
       "\n",
       "   loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  loc_og_t2m_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1             11.51             75.94            291.86             53.76   \n",
       "2             29.34             16.86             38.46             28.16   \n",
       "3            107.43             83.21             22.46             65.46   \n",
       "4             67.64             91.88            124.26             37.89   \n",
       "5             16.39              8.83             12.38             44.78   \n",
       "6            252.23             48.71             80.63             50.33   \n",
       "7            308.63            447.38            162.28               NaN   \n",
       "8             80.96             70.58             50.54             34.58   \n",
       "9             38.03             40.06             34.93             37.26   \n",
       "\n",
       "   loc_og_t2f_mou_6  loc_og_t2f_mou_7  loc_og_t2f_mou_8  loc_og_t2f_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1              0.00              0.00              0.00              0.00   \n",
       "2             24.11             21.79             15.61             22.24   \n",
       "3              1.91              0.65              4.91              2.06   \n",
       "4              0.00              0.00              0.00              1.93   \n",
       "5              0.00              0.00              0.00              2.13   \n",
       "6             10.38              0.00              0.00              0.00   \n",
       "7             62.13             55.14             53.23               NaN   \n",
       "8              0.00              0.00              0.00              0.00   \n",
       "9              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_t2c_mou_6  loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_t2c_mou_9  \\\n",
       "0               NaN               NaN              0.00               NaN   \n",
       "1              0.00              2.91              0.00              0.00   \n",
       "2              0.00            135.54             45.76              0.48   \n",
       "3              0.00              0.00              0.00              0.00   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "6              0.11              0.00              0.00              0.00   \n",
       "7              0.00              0.00              0.00               NaN   \n",
       "8              0.00              0.00              7.15              0.00   \n",
       "9              0.00              0.00              0.00              0.00   \n",
       "\n",
       "   loc_og_mou_6  loc_og_mou_7  loc_og_mou_8  loc_og_mou_9  std_og_t2t_mou_6  \\\n",
       "0           NaN           NaN          0.00           NaN               NaN   \n",
       "1         35.39        150.51        299.54         72.11              0.23   \n",
       "2         60.66         67.41         67.66         64.81              4.34   \n",
       "3        183.03        118.68         37.99         83.03             26.23   \n",
       "4        117.96        241.33        208.16         98.61              0.00   \n",
       "5         66.56         52.46         97.86        185.71              0.00   \n",
       "6        333.64         93.74        156.78         65.56              0.00   \n",
       "7        422.16        533.91        255.79           NaN              4.30   \n",
       "8        378.09        288.18         63.04         60.71            116.56   \n",
       "9         71.93         70.18         57.36         65.11              0.00   \n",
       "\n",
       "   std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2t_mou_9  std_og_t2m_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              4.11              0.00              0.00              0.00   \n",
       "2             26.49             22.58              8.76             41.81   \n",
       "3             14.89            289.58            226.21              2.99   \n",
       "4              0.00              0.00              0.00              9.31   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "6              0.00              0.51              0.00              0.00   \n",
       "7             23.29             12.01               NaN             49.89   \n",
       "8            133.43             22.58              7.33             13.69   \n",
       "9              0.00              0.00              0.00             25.45   \n",
       "\n",
       "   std_og_t2m_mou_7  std_og_t2m_mou_8  std_og_t2m_mou_9  std_og_t2f_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.46              0.13              0.00              0.00   \n",
       "2             67.41             75.53              9.28              1.48   \n",
       "3              1.73              6.53              9.99              0.00   \n",
       "4              0.00              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00              2.88   \n",
       "6              0.53             11.45              0.00              0.00   \n",
       "7             31.76             49.14               NaN              6.66   \n",
       "8             10.04             75.69             74.13              0.00   \n",
       "9             14.09             43.41             83.26              0.00   \n",
       "\n",
       "   std_og_t2f_mou_7  std_og_t2f_mou_8  std_og_t2f_mou_9  std_og_t2c_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2             14.76             22.83              0.00               0.0   \n",
       "3              0.00              0.00              0.00               0.0   \n",
       "4              0.00              0.00              0.00               0.0   \n",
       "5              4.61              2.08              0.00               0.0   \n",
       "6              0.00              0.00              0.00               0.0   \n",
       "7             20.08             16.68               NaN               0.0   \n",
       "8              0.00              0.00              0.00               0.0   \n",
       "9              0.00              0.00              2.94               0.0   \n",
       "\n",
       "   std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_t2c_mou_9  std_og_mou_6  \\\n",
       "0               NaN               0.0               NaN           NaN   \n",
       "1               0.0               0.0               0.0          0.23   \n",
       "2               0.0               0.0               0.0         47.64   \n",
       "3               0.0               0.0               0.0         29.23   \n",
       "4               0.0               0.0               0.0          9.31   \n",
       "5               0.0               0.0               0.0          2.88   \n",
       "6               0.0               0.0               0.0          0.00   \n",
       "7               0.0               0.0               NaN         60.86   \n",
       "8               0.0               0.0               0.0        130.26   \n",
       "9               0.0               0.0               0.0         25.45   \n",
       "\n",
       "   std_og_mou_7  std_og_mou_8  std_og_mou_9  isd_og_mou_6  isd_og_mou_7  \\\n",
       "0           NaN          0.00           NaN           NaN           NaN   \n",
       "1          4.58          0.13          0.00           0.0          0.00   \n",
       "2        108.68        120.94         18.04           0.0          0.00   \n",
       "3         16.63        296.11        236.21           0.0          0.00   \n",
       "4          0.00          0.00          0.00           0.0          0.00   \n",
       "5          4.61          2.08          0.00           0.0          0.00   \n",
       "6          0.53         11.96          0.00           0.0          0.00   \n",
       "7         75.14         77.84           NaN           0.0          0.18   \n",
       "8        143.48         98.28         81.46           0.0          0.00   \n",
       "9         14.09         43.41         86.21           0.0          0.00   \n",
       "\n",
       "   isd_og_mou_8  isd_og_mou_9  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  \\\n",
       "0          0.00           NaN           NaN           NaN          0.00   \n",
       "1          0.00           0.0          4.68         23.43         12.76   \n",
       "2          0.00           0.0         46.56        236.84         96.84   \n",
       "3          0.00           0.0         10.96          0.00         18.09   \n",
       "4          0.00           0.0          0.00          0.00          0.00   \n",
       "5          0.00           0.0          0.00          0.00          0.00   \n",
       "6          0.00           0.0          0.11          0.53          0.00   \n",
       "7         10.01           NaN          4.50          0.00          6.50   \n",
       "8          0.00           0.0          0.00          0.00         10.23   \n",
       "9          0.00           0.0          0.66          0.00          0.00   \n",
       "\n",
       "   spl_og_mou_9  og_others_6  og_others_7  og_others_8  og_others_9  \\\n",
       "0           NaN          NaN          NaN          0.0          NaN   \n",
       "1          0.00         0.00          0.0          0.0         0.00   \n",
       "2         42.08         0.45          0.0          0.0         0.00   \n",
       "3         43.29         0.00          0.0          0.0         0.00   \n",
       "4          5.98         0.00          0.0          0.0         0.00   \n",
       "5          0.00         0.00          0.0          0.0         0.00   \n",
       "6          0.00         0.00          0.0          0.0         0.35   \n",
       "7           NaN         0.00          0.0          0.0          NaN   \n",
       "8          0.00         0.00          0.0          0.0         0.00   \n",
       "9          0.00         0.00          0.0          0.0         0.00   \n",
       "\n",
       "   total_og_mou_6  total_og_mou_7  total_og_mou_8  total_og_mou_9  \\\n",
       "0            0.00            0.00            0.00            0.00   \n",
       "1           40.31          178.53          312.44           72.11   \n",
       "2          155.33          412.94          285.46          124.94   \n",
       "3          223.23          135.31          352.21          362.54   \n",
       "4          127.28          241.33          208.16          104.59   \n",
       "5           69.44           57.08           99.94          185.71   \n",
       "6          333.76           94.81          168.74           65.91   \n",
       "7          487.53          609.24          350.16            0.00   \n",
       "8          508.36          431.66          171.56          142.18   \n",
       "9           98.04           84.28          100.78          151.33   \n",
       "\n",
       "   loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  loc_ic_t2t_mou_9  \\\n",
       "0               NaN               NaN              0.16               NaN   \n",
       "1              1.61             29.91             29.23            116.09   \n",
       "2            115.69             71.11             67.46            148.23   \n",
       "3             62.08             19.98              8.04             41.73   \n",
       "4            105.68             88.49            233.81            154.56   \n",
       "5             28.73             30.03             56.26             68.38   \n",
       "6           1857.99           1427.04           1896.43           2334.88   \n",
       "7             58.14             32.26             27.31               NaN   \n",
       "8             23.84              9.84              0.31              4.03   \n",
       "9            129.34            124.34             49.93            313.38   \n",
       "\n",
       "   loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  loc_ic_t2m_mou_8  loc_ic_t2m_mou_9  \\\n",
       "0               NaN               NaN              4.13               NaN   \n",
       "1             17.48             65.38            375.58             56.93   \n",
       "2             14.38             15.44             38.89             38.98   \n",
       "3            113.96             64.51             20.28             52.86   \n",
       "4            106.84            109.54            104.13             48.24   \n",
       "5             49.19             57.44             62.46             84.01   \n",
       "6            248.64            336.96            265.28            231.41   \n",
       "7            217.56            221.49            121.19               NaN   \n",
       "8             57.58             13.98             15.48             17.34   \n",
       "9            132.94             96.24            122.58             65.06   \n",
       "\n",
       "   loc_ic_t2f_mou_6  loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_t2f_mou_9  \\\n",
       "0               NaN               NaN              1.15               NaN   \n",
       "1              0.00              8.93              3.61              0.00   \n",
       "2             99.48            122.29             49.63            158.19   \n",
       "3             57.43             27.09             19.84             65.59   \n",
       "4              1.50              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "6             20.24             22.69              2.51              6.19   \n",
       "7            152.16            101.46             39.53               NaN   \n",
       "8              0.00              0.00              0.00              0.00   \n",
       "9              0.40              0.00              0.00              0.48   \n",
       "\n",
       "   loc_ic_mou_6  loc_ic_mou_7  loc_ic_mou_8  loc_ic_mou_9  std_ic_t2t_mou_6  \\\n",
       "0           NaN           NaN          5.44           NaN               NaN   \n",
       "1         19.09        104.23        408.43        173.03              0.00   \n",
       "2        229.56        208.86        155.99        345.41             72.41   \n",
       "3        233.48        111.59         48.18        160.19             43.48   \n",
       "4        214.03        198.04        337.94        202.81              0.00   \n",
       "5         77.93         87.48        118.73        152.39              0.00   \n",
       "6       2126.89       1786.71       2164.23       2572.49              0.00   \n",
       "7        427.88        355.23        188.04           NaN             36.89   \n",
       "8         81.43         23.83         15.79         21.38              0.00   \n",
       "9        262.69        220.59        172.51        378.93              0.30   \n",
       "\n",
       "   std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2t_mou_9  std_ic_t2m_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00              2.35              0.00              5.90   \n",
       "2             71.29             28.69             49.44             45.18   \n",
       "3             66.44              0.00            129.84              1.33   \n",
       "4              0.00              0.86              2.31              1.93   \n",
       "5              0.00              0.00              0.00              0.00   \n",
       "6              0.00              0.00              0.00              1.39   \n",
       "7             11.83             30.39               NaN             91.44   \n",
       "8              0.58              0.10              0.00             22.43   \n",
       "9              0.00              0.00              4.38             32.86   \n",
       "\n",
       "   std_ic_t2m_mou_7  std_ic_t2m_mou_8  std_ic_t2m_mou_9  std_ic_t2f_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00             12.49             15.01              0.00   \n",
       "2            177.01            167.09            118.18             21.73   \n",
       "3             38.56              4.94             13.98              1.18   \n",
       "4              0.25              0.00              0.00              0.00   \n",
       "5              0.00              0.00              0.00             77.03   \n",
       "6              0.76              2.60              0.00              0.00   \n",
       "7            126.99            141.33               NaN             52.19   \n",
       "8              4.08              0.65             13.53              0.00   \n",
       "9             78.21              1.74              1.18              0.00   \n",
       "\n",
       "   std_ic_t2f_mou_7  std_ic_t2f_mou_8  std_ic_t2f_mou_9  std_ic_t2o_mou_6  \\\n",
       "0               NaN              0.00               NaN               NaN   \n",
       "1              0.00              0.00              0.00               0.0   \n",
       "2             58.34             43.23              3.86               0.0   \n",
       "3              0.00              0.00              0.00               0.0   \n",
       "4              0.00              0.00              0.00               0.0   \n",
       "5             71.06             37.93             52.03               0.0   \n",
       "6              0.00              0.00              0.00               0.0   \n",
       "7             34.24             22.21               NaN               0.0   \n",
       "8              0.00              0.00              0.00               0.0   \n",
       "9              0.00              0.00              0.00               0.0   \n",
       "\n",
       "   std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_t2o_mou_9  std_ic_mou_6  \\\n",
       "0               NaN               0.0               NaN           NaN   \n",
       "1               0.0               0.0               0.0          5.90   \n",
       "2               0.0               0.0               0.0        139.33   \n",
       "3               0.0               0.0               0.0         45.99   \n",
       "4               0.0               0.0               0.0          1.93   \n",
       "5               0.0               0.0               0.0         77.03   \n",
       "6               0.0               0.0               0.0          1.39   \n",
       "7               0.0               0.0               NaN        180.54   \n",
       "8               0.0               0.0               0.0         22.43   \n",
       "9               0.0               0.0               0.0         33.16   \n",
       "\n",
       "   std_ic_mou_7  std_ic_mou_8  std_ic_mou_9  total_ic_mou_6  total_ic_mou_7  \\\n",
       "0           NaN          0.00           NaN            0.00            0.00   \n",
       "1          0.00         14.84         15.01           26.83          104.23   \n",
       "2        306.66        239.03        171.49          370.04          519.53   \n",
       "3        105.01          4.94        143.83          280.08          216.61   \n",
       "4          0.25          0.86          2.31          216.44          198.29   \n",
       "5         71.06         37.93         52.03          155.39          158.76   \n",
       "6          0.76          2.60          0.00         2128.41         1788.06   \n",
       "7        173.08        193.94           NaN          626.46          558.04   \n",
       "8          4.66          0.75         13.53          103.86           28.49   \n",
       "9         78.21          1.74          5.56          303.98          327.31   \n",
       "\n",
       "   total_ic_mou_8  total_ic_mou_9  spl_ic_mou_6  spl_ic_mou_7  spl_ic_mou_8  \\\n",
       "0            5.44            0.00           NaN           NaN          0.00   \n",
       "1          423.28          188.04          0.00          0.00          0.00   \n",
       "2          395.03          517.74          0.21          0.00          0.00   \n",
       "3           53.13          305.38          0.59          0.00          0.00   \n",
       "4          338.81          205.31          0.00          0.00          0.00   \n",
       "5          157.13          205.39          0.43          0.21          0.23   \n",
       "6         2167.11         2572.49          0.00          0.00          0.00   \n",
       "7          428.74            0.00          0.21          0.00          0.00   \n",
       "8           16.54           34.91          0.00          0.00          0.00   \n",
       "9          219.86          412.63          0.00          0.00          0.00   \n",
       "\n",
       "   spl_ic_mou_9  isd_ic_mou_6  isd_ic_mou_7  isd_ic_mou_8  isd_ic_mou_9  \\\n",
       "0           NaN           NaN           NaN          0.00           NaN   \n",
       "1          0.00          1.83          0.00          0.00          0.00   \n",
       "2          0.45          0.00          0.85          0.00          0.01   \n",
       "3          0.55          0.00          0.00          0.00          0.00   \n",
       "4          0.18          0.00          0.00          0.00          0.00   \n",
       "5          0.53          0.00          0.00          0.00          0.00   \n",
       "6          0.00          0.00          0.00          0.00          0.00   \n",
       "7           NaN          2.06         14.53         31.59           NaN   \n",
       "8          0.00          0.00          0.00          0.00          0.00   \n",
       "9          0.00          8.11         28.49         45.59         28.13   \n",
       "\n",
       "   ic_others_6  ic_others_7  ic_others_8  ic_others_9  total_rech_num_6  \\\n",
       "0          NaN          NaN         0.00          NaN                 4   \n",
       "1         0.00         0.00         0.00         0.00                 4   \n",
       "2         0.93         3.14         0.00         0.36                 5   \n",
       "3         0.00         0.00         0.00         0.80                10   \n",
       "4         0.48         0.00         0.00         0.00                 5   \n",
       "5         0.00         0.00         0.23         0.43                 2   \n",
       "6         0.11         0.58         0.28         0.00                15   \n",
       "7        15.74        15.19        15.14          NaN                 5   \n",
       "8         0.00         0.00         0.00         0.00                19   \n",
       "9         0.00         0.00         0.00         0.00                 4   \n",
       "\n",
       "   total_rech_num_7  total_rech_num_8  total_rech_num_9  total_rech_amt_6  \\\n",
       "0                 3                 2                 6               362   \n",
       "1                 9                11                 5                74   \n",
       "2                 4                 2                 7               168   \n",
       "3                11                18                14               230   \n",
       "4                 6                 3                 4               196   \n",
       "5                 2                 3                 3               120   \n",
       "6                10                11                 7               499   \n",
       "7                 5                 7                 3              1580   \n",
       "8                21                14                15               437   \n",
       "9                 2                 5                 3               220   \n",
       "\n",
       "   total_rech_amt_7  total_rech_amt_8  total_rech_amt_9  max_rech_amt_6  \\\n",
       "0               252               252                 0             252   \n",
       "1               384               283               121              44   \n",
       "2               315               116               358              86   \n",
       "3               310               601               410              60   \n",
       "4               350               287               200              56   \n",
       "5                 0               130               130             120   \n",
       "6               222               294               141              90   \n",
       "7               790              3638                 0            1580   \n",
       "8               601               120               186              90   \n",
       "9               195               210               180             110   \n",
       "\n",
       "   max_rech_amt_7  max_rech_amt_8  max_rech_amt_9 date_of_last_rech_6  \\\n",
       "0             252             252               0           6/21/2014   \n",
       "1             154              65              50           6/29/2014   \n",
       "2             200              86             100           6/17/2014   \n",
       "3              50              50              50           6/28/2014   \n",
       "4             110             110              50           6/26/2014   \n",
       "5               0             130             130           6/19/2014   \n",
       "6              37              50              30           6/28/2014   \n",
       "7             790            1580               0           6/27/2014   \n",
       "8             154              30              36           6/25/2014   \n",
       "9             154              50             130           6/29/2014   \n",
       "\n",
       "  date_of_last_rech_7 date_of_last_rech_8 date_of_last_rech_9  \\\n",
       "0           7/16/2014          08-08-2014           9/28/2014   \n",
       "1           7/31/2014           8/28/2014           9/30/2014   \n",
       "2           7/24/2014           8/14/2014           9/29/2014   \n",
       "3           7/31/2014           8/31/2014           9/30/2014   \n",
       "4           7/28/2014          08-09-2014           9/28/2014   \n",
       "5           7/17/2014           8/24/2014           9/28/2014   \n",
       "6           7/31/2014           8/28/2014           9/28/2014   \n",
       "7           7/25/2014           8/26/2014           9/30/2014   \n",
       "8           7/31/2014           8/30/2014           9/30/2014   \n",
       "9           7/23/2014           8/29/2014           9/20/2014   \n",
       "\n",
       "   last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "0                 252                 252                 252   \n",
       "1                  44                  23                  30   \n",
       "2                   0                 200                  86   \n",
       "3                  30                  50                  50   \n",
       "4                  50                 110                 110   \n",
       "5                 120                   0                   0   \n",
       "6                  37                  24                  10   \n",
       "7                   0                   0                 779   \n",
       "8                  50                   0                  10   \n",
       "9                 110                 154                  30   \n",
       "\n",
       "   last_day_rch_amt_9 date_of_last_rech_data_6 date_of_last_rech_data_7  \\\n",
       "0                   0                6/21/2014                7/16/2014   \n",
       "1                   0                      NaN                7/25/2014   \n",
       "2                   0                      NaN                      NaN   \n",
       "3                  30                      NaN                      NaN   \n",
       "4                  50               06-04-2014                      NaN   \n",
       "5                   0                      NaN                      NaN   \n",
       "6                  24                      NaN                      NaN   \n",
       "7                   0                      NaN                      NaN   \n",
       "8                   0                      NaN                7/31/2014   \n",
       "9                  50                      NaN                7/23/2014   \n",
       "\n",
       "  date_of_last_rech_data_8 date_of_last_rech_data_9  total_rech_data_6  \\\n",
       "0               08-08-2014                      NaN                1.0   \n",
       "1               08-10-2014                      NaN                NaN   \n",
       "2                      NaN                9/17/2014                NaN   \n",
       "3                      NaN                      NaN                NaN   \n",
       "4                      NaN                      NaN                1.0   \n",
       "5                      NaN                      NaN                NaN   \n",
       "6                      NaN                      NaN                NaN   \n",
       "7                      NaN                      NaN                NaN   \n",
       "8                8/23/2014                      NaN                NaN   \n",
       "9                      NaN                      NaN                NaN   \n",
       "\n",
       "   total_rech_data_7  total_rech_data_8  total_rech_data_9  max_rech_data_6  \\\n",
       "0                1.0                1.0                NaN            252.0   \n",
       "1                1.0                2.0                NaN              NaN   \n",
       "2                NaN                NaN                1.0              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4                NaN                NaN                NaN             56.0   \n",
       "5                NaN                NaN                NaN              NaN   \n",
       "6                NaN                NaN                NaN              NaN   \n",
       "7                NaN                NaN                NaN              NaN   \n",
       "8                2.0                3.0                NaN              NaN   \n",
       "9                1.0                NaN                NaN              NaN   \n",
       "\n",
       "   max_rech_data_7  max_rech_data_8  max_rech_data_9  count_rech_2g_6  \\\n",
       "0            252.0            252.0              NaN              0.0   \n",
       "1            154.0             25.0              NaN              NaN   \n",
       "2              NaN              NaN             46.0              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              1.0   \n",
       "5              NaN              NaN              NaN              NaN   \n",
       "6              NaN              NaN              NaN              NaN   \n",
       "7              NaN              NaN              NaN              NaN   \n",
       "8            154.0             23.0              NaN              NaN   \n",
       "9            154.0              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_2g_7  count_rech_2g_8  count_rech_2g_9  count_rech_3g_6  \\\n",
       "0              0.0              0.0              NaN              1.0   \n",
       "1              1.0              2.0              NaN              NaN   \n",
       "2              NaN              NaN              1.0              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              0.0   \n",
       "5              NaN              NaN              NaN              NaN   \n",
       "6              NaN              NaN              NaN              NaN   \n",
       "7              NaN              NaN              NaN              NaN   \n",
       "8              2.0              3.0              NaN              NaN   \n",
       "9              1.0              NaN              NaN              NaN   \n",
       "\n",
       "   count_rech_3g_7  count_rech_3g_8  count_rech_3g_9  av_rech_amt_data_6  \\\n",
       "0              1.0              1.0              NaN               252.0   \n",
       "1              0.0              0.0              NaN                 NaN   \n",
       "2              NaN              NaN              0.0                 NaN   \n",
       "3              NaN              NaN              NaN                 NaN   \n",
       "4              NaN              NaN              NaN                56.0   \n",
       "5              NaN              NaN              NaN                 NaN   \n",
       "6              NaN              NaN              NaN                 NaN   \n",
       "7              NaN              NaN              NaN                 NaN   \n",
       "8              0.0              0.0              NaN                 NaN   \n",
       "9              0.0              NaN              NaN                 NaN   \n",
       "\n",
       "   av_rech_amt_data_7  av_rech_amt_data_8  av_rech_amt_data_9  vol_2g_mb_6  \\\n",
       "0               252.0               252.0                 NaN        30.13   \n",
       "1               154.0                50.0                 NaN         0.00   \n",
       "2                 NaN                 NaN                46.0         0.00   \n",
       "3                 NaN                 NaN                 NaN         0.00   \n",
       "4                 NaN                 NaN                 NaN         0.00   \n",
       "5                 NaN                 NaN                 NaN         0.00   \n",
       "6                 NaN                 NaN                 NaN         0.00   \n",
       "7                 NaN                 NaN                 NaN         0.00   \n",
       "8               177.0                69.0                 NaN         0.00   \n",
       "9               154.0                 NaN                 NaN         0.00   \n",
       "\n",
       "   vol_2g_mb_7  vol_2g_mb_8  vol_2g_mb_9  vol_3g_mb_6  vol_3g_mb_7  \\\n",
       "0         1.32         5.75          0.0        83.57       150.76   \n",
       "1       108.07       365.47          0.0         0.00         0.00   \n",
       "2         0.00         0.00          0.0         0.00         0.00   \n",
       "3         0.00         0.00          0.0         0.00         0.00   \n",
       "4         0.00         0.00          0.0         0.00         0.00   \n",
       "5         0.00         0.00          0.0         0.00         0.00   \n",
       "6         0.00         0.00          0.0         0.00         0.00   \n",
       "7         0.00         0.00          0.0         0.00         0.00   \n",
       "8       356.00         0.03          0.0         0.00       750.95   \n",
       "9         7.37         0.00          0.0         0.00         0.00   \n",
       "\n",
       "   vol_3g_mb_8  vol_3g_mb_9  arpu_3g_6  arpu_3g_7  arpu_3g_8  arpu_3g_9  \\\n",
       "0       109.61         0.00     212.17     212.17     212.17        NaN   \n",
       "1         0.00         0.00        NaN       0.00       0.00        NaN   \n",
       "2         0.00         8.42        NaN        NaN        NaN       2.84   \n",
       "3         0.00         0.00        NaN        NaN        NaN        NaN   \n",
       "4         0.00         0.00       0.00        NaN        NaN        NaN   \n",
       "5         0.00         0.00        NaN        NaN        NaN        NaN   \n",
       "6         0.00         0.00        NaN        NaN        NaN        NaN   \n",
       "7         0.00         0.00        NaN        NaN        NaN        NaN   \n",
       "8        11.94         0.00        NaN       0.00      19.83        NaN   \n",
       "9         0.00         0.00        NaN       0.00        NaN        NaN   \n",
       "\n",
       "   arpu_2g_6  arpu_2g_7  arpu_2g_8  arpu_2g_9  night_pck_user_6  \\\n",
       "0     212.17     212.17     212.17        NaN               0.0   \n",
       "1        NaN      28.61       7.60        NaN               NaN   \n",
       "2        NaN        NaN        NaN        0.0               NaN   \n",
       "3        NaN        NaN        NaN        NaN               NaN   \n",
       "4       0.00        NaN        NaN        NaN               0.0   \n",
       "5        NaN        NaN        NaN        NaN               NaN   \n",
       "6        NaN        NaN        NaN        NaN               NaN   \n",
       "7        NaN        NaN        NaN        NaN               NaN   \n",
       "8        NaN       0.00       0.00        NaN               NaN   \n",
       "9        NaN       0.00        NaN        NaN               NaN   \n",
       "\n",
       "   night_pck_user_7  night_pck_user_8  night_pck_user_9  monthly_2g_6  \\\n",
       "0               0.0               0.0               NaN             0   \n",
       "1               0.0               0.0               NaN             0   \n",
       "2               NaN               NaN               0.0             0   \n",
       "3               NaN               NaN               NaN             0   \n",
       "4               NaN               NaN               NaN             0   \n",
       "5               NaN               NaN               NaN             0   \n",
       "6               NaN               NaN               NaN             0   \n",
       "7               NaN               NaN               NaN             0   \n",
       "8               0.0               0.0               NaN             0   \n",
       "9               0.0               NaN               NaN             0   \n",
       "\n",
       "   monthly_2g_7  monthly_2g_8  monthly_2g_9  sachet_2g_6  sachet_2g_7  \\\n",
       "0             0             0             0            0            0   \n",
       "1             1             0             0            0            0   \n",
       "2             0             0             0            0            0   \n",
       "3             0             0             0            0            0   \n",
       "4             0             0             0            1            0   \n",
       "5             0             0             0            0            0   \n",
       "6             0             0             0            0            0   \n",
       "7             0             0             0            0            0   \n",
       "8             1             0             0            0            1   \n",
       "9             1             0             0            0            0   \n",
       "\n",
       "   sachet_2g_8  sachet_2g_9  monthly_3g_6  monthly_3g_7  monthly_3g_8  \\\n",
       "0            0            0             1             1             1   \n",
       "1            2            0             0             0             0   \n",
       "2            0            1             0             0             0   \n",
       "3            0            0             0             0             0   \n",
       "4            0            0             0             0             0   \n",
       "5            0            0             0             0             0   \n",
       "6            0            0             0             0             0   \n",
       "7            0            0             0             0             0   \n",
       "8            3            0             0             0             0   \n",
       "9            0            0             0             0             0   \n",
       "\n",
       "   monthly_3g_9  sachet_3g_6  sachet_3g_7  sachet_3g_8  sachet_3g_9  \\\n",
       "0             0            0            0            0            0   \n",
       "1             0            0            0            0            0   \n",
       "2             0            0            0            0            0   \n",
       "3             0            0            0            0            0   \n",
       "4             0            0            0            0            0   \n",
       "5             0            0            0            0            0   \n",
       "6             0            0            0            0            0   \n",
       "7             0            0            0            0            0   \n",
       "8             0            0            0            0            0   \n",
       "9             0            0            0            0            0   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0        1.0        1.0        1.0        NaN   968       30.40        0.00   \n",
       "1        NaN        1.0        1.0        NaN  1006        0.00        0.00   \n",
       "2        NaN        NaN        NaN        1.0  1103        0.00        0.00   \n",
       "3        NaN        NaN        NaN        NaN  2491        0.00        0.00   \n",
       "4        0.0        NaN        NaN        NaN  1526        0.00        0.00   \n",
       "5        NaN        NaN        NaN        NaN  1471        0.00        0.00   \n",
       "6        NaN        NaN        NaN        NaN  1673        0.00        0.00   \n",
       "7        NaN        NaN        NaN        NaN   802       57.74       19.38   \n",
       "8        NaN        1.0        1.0        NaN   315       21.03      910.65   \n",
       "9        NaN        1.0        NaN        NaN   902        0.00        0.00   \n",
       "\n",
       "   jun_vbc_3g  sep_vbc_3g  \n",
       "0      101.20        3.58  \n",
       "1        0.00        0.00  \n",
       "2        4.17        0.00  \n",
       "3        0.00        0.00  \n",
       "4        0.00        0.00  \n",
       "5        0.00        0.00  \n",
       "6        0.00        0.00  \n",
       "7       18.74        0.00  \n",
       "8      122.16        0.00  \n",
       "9        0.00        0.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at initial rows of the data\n",
    "churn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzDX0O97D8gx"
   },
   "source": [
    "### Data Description\n",
    "\n",
    "There are several types of data that is collected from customers by a telecomminucation service provider. Some of the information that you have to look for data analysis and EDA is given below:\n",
    "- Recharging of the service: There are several variables that describe the duration, maximum, total amount and average of the recharge price of the service they avail, which include the 2G service, the 3G service, internet packages and call services\n",
    "  - av_rech_amt_data: Average recharge data amount\n",
    "  - count_rech_2g: Count of 2G recharges by the customer\n",
    "  - count_rech_3g: Count of 3G recharges by the customer\n",
    "  - max_rech_data: Maximum recharge for mobile internet\n",
    "  - total_rech_data: Total recharge for mobile internet\n",
    "  - max_rech_amt: Maximum recharge amount\n",
    "  - total_rech_amt: Total recharge amount\n",
    "  - total_rech_num: Total number of times customer recharged\n",
    "\n",
    "- Call and Internet service: They specify the amount of calls, type of calling service used (STD, ISD, Roaming), type of internet service and amount of internet usage over a specific period of time\n",
    "  - total_calls_mou: Total minutes of voice calls\n",
    "  - total_internet_mb: Total amount of internet usage in MB\n",
    "  - arpu: Average revenue per user\n",
    "  - onnet_mou: The minutes of usage for all kind of calls within the same operator network\n",
    "  - offnet_mou: The minutes of usage for all kind of calls outside the operator T network\n",
    "  - Minutes of usage for outgoing calls for each type of call service:\n",
    "    - loc_og_mou\n",
    "    - std_og_mou\n",
    "    - isd_og_mou\n",
    "    - spl_og_mou\n",
    "    - roam_og_mou\n",
    "    - total_og_mou\n",
    "  - Minutes of usage for incoming calls for each type of call service:\n",
    "    - loc_ic_mou\n",
    "    - std_ic_mou\n",
    "    - isd_ic_mou\n",
    "    - spl_ic_mou\n",
    "    - roam_ic_mou\n",
    "    - total_ic_mou\n",
    "  - total_rech_num: Total number of recharge\n",
    "  - total_rech_amt: Total amount of recharge\n",
    "  - max_rech_amt: Maximum recharge amount\n",
    "  - total_rech_data: Total recharge for mobile internet\n",
    "  - max_rech_data: Maximum recharge for mobile internet\n",
    "  - av_rech_amt_data: Average recharge amount for mobile internet\n",
    "  - vol_2g_mb: Mobile internet usage volumn for 2G\n",
    "  - vol_3g_mb: Mobile internet usage volumn for 3G\n",
    "\n",
    "\n",
    "The categorical variables present in the data set are given below:\n",
    "  - night_pck_user: Prepaid service schemes for use during specific night hours only\n",
    "  - fb_user: Service scheme to avail services of Facebook and similar social networking sites\n",
    "\n",
    "\n",
    "\n",
    "Most of the variables have their values recorded for 4 different months. The variable names end with the month number as explained below:\n",
    "- *.6: KPI for the month of June\n",
    "- *.7: KPI for the month of July\n",
    "- *.8: KPI for the month of August\n",
    "- *.9: KPI for the month of September\n",
    "\n",
    "The rest of variables have been defined in the detailed data description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2TWuExKhadX"
   },
   "source": [
    "Print information about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RUt5O3eZd81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Data columns (total 225 columns):\n",
      " #    Column                    Dtype  \n",
      "---   ------                    -----  \n",
      " 0    circle_id                 int64  \n",
      " 1    loc_og_t2o_mou            float64\n",
      " 2    std_og_t2o_mou            float64\n",
      " 3    loc_ic_t2o_mou            float64\n",
      " 4    last_date_of_month_6      object \n",
      " 5    last_date_of_month_7      object \n",
      " 6    last_date_of_month_8      object \n",
      " 7    last_date_of_month_9      object \n",
      " 8    arpu_6                    float64\n",
      " 9    arpu_7                    float64\n",
      " 10   arpu_8                    float64\n",
      " 11   arpu_9                    float64\n",
      " 12   onnet_mou_6               float64\n",
      " 13   onnet_mou_7               float64\n",
      " 14   onnet_mou_8               float64\n",
      " 15   onnet_mou_9               float64\n",
      " 16   offnet_mou_6              float64\n",
      " 17   offnet_mou_7              float64\n",
      " 18   offnet_mou_8              float64\n",
      " 19   offnet_mou_9              float64\n",
      " 20   roam_ic_mou_6             float64\n",
      " 21   roam_ic_mou_7             float64\n",
      " 22   roam_ic_mou_8             float64\n",
      " 23   roam_ic_mou_9             float64\n",
      " 24   roam_og_mou_6             float64\n",
      " 25   roam_og_mou_7             float64\n",
      " 26   roam_og_mou_8             float64\n",
      " 27   roam_og_mou_9             float64\n",
      " 28   loc_og_t2t_mou_6          float64\n",
      " 29   loc_og_t2t_mou_7          float64\n",
      " 30   loc_og_t2t_mou_8          float64\n",
      " 31   loc_og_t2t_mou_9          float64\n",
      " 32   loc_og_t2m_mou_6          float64\n",
      " 33   loc_og_t2m_mou_7          float64\n",
      " 34   loc_og_t2m_mou_8          float64\n",
      " 35   loc_og_t2m_mou_9          float64\n",
      " 36   loc_og_t2f_mou_6          float64\n",
      " 37   loc_og_t2f_mou_7          float64\n",
      " 38   loc_og_t2f_mou_8          float64\n",
      " 39   loc_og_t2f_mou_9          float64\n",
      " 40   loc_og_t2c_mou_6          float64\n",
      " 41   loc_og_t2c_mou_7          float64\n",
      " 42   loc_og_t2c_mou_8          float64\n",
      " 43   loc_og_t2c_mou_9          float64\n",
      " 44   loc_og_mou_6              float64\n",
      " 45   loc_og_mou_7              float64\n",
      " 46   loc_og_mou_8              float64\n",
      " 47   loc_og_mou_9              float64\n",
      " 48   std_og_t2t_mou_6          float64\n",
      " 49   std_og_t2t_mou_7          float64\n",
      " 50   std_og_t2t_mou_8          float64\n",
      " 51   std_og_t2t_mou_9          float64\n",
      " 52   std_og_t2m_mou_6          float64\n",
      " 53   std_og_t2m_mou_7          float64\n",
      " 54   std_og_t2m_mou_8          float64\n",
      " 55   std_og_t2m_mou_9          float64\n",
      " 56   std_og_t2f_mou_6          float64\n",
      " 57   std_og_t2f_mou_7          float64\n",
      " 58   std_og_t2f_mou_8          float64\n",
      " 59   std_og_t2f_mou_9          float64\n",
      " 60   std_og_t2c_mou_6          float64\n",
      " 61   std_og_t2c_mou_7          float64\n",
      " 62   std_og_t2c_mou_8          float64\n",
      " 63   std_og_t2c_mou_9          float64\n",
      " 64   std_og_mou_6              float64\n",
      " 65   std_og_mou_7              float64\n",
      " 66   std_og_mou_8              float64\n",
      " 67   std_og_mou_9              float64\n",
      " 68   isd_og_mou_6              float64\n",
      " 69   isd_og_mou_7              float64\n",
      " 70   isd_og_mou_8              float64\n",
      " 71   isd_og_mou_9              float64\n",
      " 72   spl_og_mou_6              float64\n",
      " 73   spl_og_mou_7              float64\n",
      " 74   spl_og_mou_8              float64\n",
      " 75   spl_og_mou_9              float64\n",
      " 76   og_others_6               float64\n",
      " 77   og_others_7               float64\n",
      " 78   og_others_8               float64\n",
      " 79   og_others_9               float64\n",
      " 80   total_og_mou_6            float64\n",
      " 81   total_og_mou_7            float64\n",
      " 82   total_og_mou_8            float64\n",
      " 83   total_og_mou_9            float64\n",
      " 84   loc_ic_t2t_mou_6          float64\n",
      " 85   loc_ic_t2t_mou_7          float64\n",
      " 86   loc_ic_t2t_mou_8          float64\n",
      " 87   loc_ic_t2t_mou_9          float64\n",
      " 88   loc_ic_t2m_mou_6          float64\n",
      " 89   loc_ic_t2m_mou_7          float64\n",
      " 90   loc_ic_t2m_mou_8          float64\n",
      " 91   loc_ic_t2m_mou_9          float64\n",
      " 92   loc_ic_t2f_mou_6          float64\n",
      " 93   loc_ic_t2f_mou_7          float64\n",
      " 94   loc_ic_t2f_mou_8          float64\n",
      " 95   loc_ic_t2f_mou_9          float64\n",
      " 96   loc_ic_mou_6              float64\n",
      " 97   loc_ic_mou_7              float64\n",
      " 98   loc_ic_mou_8              float64\n",
      " 99   loc_ic_mou_9              float64\n",
      " 100  std_ic_t2t_mou_6          float64\n",
      " 101  std_ic_t2t_mou_7          float64\n",
      " 102  std_ic_t2t_mou_8          float64\n",
      " 103  std_ic_t2t_mou_9          float64\n",
      " 104  std_ic_t2m_mou_6          float64\n",
      " 105  std_ic_t2m_mou_7          float64\n",
      " 106  std_ic_t2m_mou_8          float64\n",
      " 107  std_ic_t2m_mou_9          float64\n",
      " 108  std_ic_t2f_mou_6          float64\n",
      " 109  std_ic_t2f_mou_7          float64\n",
      " 110  std_ic_t2f_mou_8          float64\n",
      " 111  std_ic_t2f_mou_9          float64\n",
      " 112  std_ic_t2o_mou_6          float64\n",
      " 113  std_ic_t2o_mou_7          float64\n",
      " 114  std_ic_t2o_mou_8          float64\n",
      " 115  std_ic_t2o_mou_9          float64\n",
      " 116  std_ic_mou_6              float64\n",
      " 117  std_ic_mou_7              float64\n",
      " 118  std_ic_mou_8              float64\n",
      " 119  std_ic_mou_9              float64\n",
      " 120  total_ic_mou_6            float64\n",
      " 121  total_ic_mou_7            float64\n",
      " 122  total_ic_mou_8            float64\n",
      " 123  total_ic_mou_9            float64\n",
      " 124  spl_ic_mou_6              float64\n",
      " 125  spl_ic_mou_7              float64\n",
      " 126  spl_ic_mou_8              float64\n",
      " 127  spl_ic_mou_9              float64\n",
      " 128  isd_ic_mou_6              float64\n",
      " 129  isd_ic_mou_7              float64\n",
      " 130  isd_ic_mou_8              float64\n",
      " 131  isd_ic_mou_9              float64\n",
      " 132  ic_others_6               float64\n",
      " 133  ic_others_7               float64\n",
      " 134  ic_others_8               float64\n",
      " 135  ic_others_9               float64\n",
      " 136  total_rech_num_6          int64  \n",
      " 137  total_rech_num_7          int64  \n",
      " 138  total_rech_num_8          int64  \n",
      " 139  total_rech_num_9          int64  \n",
      " 140  total_rech_amt_6          int64  \n",
      " 141  total_rech_amt_7          int64  \n",
      " 142  total_rech_amt_8          int64  \n",
      " 143  total_rech_amt_9          int64  \n",
      " 144  max_rech_amt_6            int64  \n",
      " 145  max_rech_amt_7            int64  \n",
      " 146  max_rech_amt_8            int64  \n",
      " 147  max_rech_amt_9            int64  \n",
      " 148  date_of_last_rech_6       object \n",
      " 149  date_of_last_rech_7       object \n",
      " 150  date_of_last_rech_8       object \n",
      " 151  date_of_last_rech_9       object \n",
      " 152  last_day_rch_amt_6        int64  \n",
      " 153  last_day_rch_amt_7        int64  \n",
      " 154  last_day_rch_amt_8        int64  \n",
      " 155  last_day_rch_amt_9        int64  \n",
      " 156  date_of_last_rech_data_6  object \n",
      " 157  date_of_last_rech_data_7  object \n",
      " 158  date_of_last_rech_data_8  object \n",
      " 159  date_of_last_rech_data_9  object \n",
      " 160  total_rech_data_6         float64\n",
      " 161  total_rech_data_7         float64\n",
      " 162  total_rech_data_8         float64\n",
      " 163  total_rech_data_9         float64\n",
      " 164  max_rech_data_6           float64\n",
      " 165  max_rech_data_7           float64\n",
      " 166  max_rech_data_8           float64\n",
      " 167  max_rech_data_9           float64\n",
      " 168  count_rech_2g_6           float64\n",
      " 169  count_rech_2g_7           float64\n",
      " 170  count_rech_2g_8           float64\n",
      " 171  count_rech_2g_9           float64\n",
      " 172  count_rech_3g_6           float64\n",
      " 173  count_rech_3g_7           float64\n",
      " 174  count_rech_3g_8           float64\n",
      " 175  count_rech_3g_9           float64\n",
      " 176  av_rech_amt_data_6        float64\n",
      " 177  av_rech_amt_data_7        float64\n",
      " 178  av_rech_amt_data_8        float64\n",
      " 179  av_rech_amt_data_9        float64\n",
      " 180  vol_2g_mb_6               float64\n",
      " 181  vol_2g_mb_7               float64\n",
      " 182  vol_2g_mb_8               float64\n",
      " 183  vol_2g_mb_9               float64\n",
      " 184  vol_3g_mb_6               float64\n",
      " 185  vol_3g_mb_7               float64\n",
      " 186  vol_3g_mb_8               float64\n",
      " 187  vol_3g_mb_9               float64\n",
      " 188  arpu_3g_6                 float64\n",
      " 189  arpu_3g_7                 float64\n",
      " 190  arpu_3g_8                 float64\n",
      " 191  arpu_3g_9                 float64\n",
      " 192  arpu_2g_6                 float64\n",
      " 193  arpu_2g_7                 float64\n",
      " 194  arpu_2g_8                 float64\n",
      " 195  arpu_2g_9                 float64\n",
      " 196  night_pck_user_6          float64\n",
      " 197  night_pck_user_7          float64\n",
      " 198  night_pck_user_8          float64\n",
      " 199  night_pck_user_9          float64\n",
      " 200  monthly_2g_6              int64  \n",
      " 201  monthly_2g_7              int64  \n",
      " 202  monthly_2g_8              int64  \n",
      " 203  monthly_2g_9              int64  \n",
      " 204  sachet_2g_6               int64  \n",
      " 205  sachet_2g_7               int64  \n",
      " 206  sachet_2g_8               int64  \n",
      " 207  sachet_2g_9               int64  \n",
      " 208  monthly_3g_6              int64  \n",
      " 209  monthly_3g_7              int64  \n",
      " 210  monthly_3g_8              int64  \n",
      " 211  monthly_3g_9              int64  \n",
      " 212  sachet_3g_6               int64  \n",
      " 213  sachet_3g_7               int64  \n",
      " 214  sachet_3g_8               int64  \n",
      " 215  sachet_3g_9               int64  \n",
      " 216  fb_user_6                 float64\n",
      " 217  fb_user_7                 float64\n",
      " 218  fb_user_8                 float64\n",
      " 219  fb_user_9                 float64\n",
      " 220  aon                       int64  \n",
      " 221  aug_vbc_3g                float64\n",
      " 222  jul_vbc_3g                float64\n",
      " 223  jun_vbc_3g                float64\n",
      " 224  sep_vbc_3g                float64\n",
      "dtypes: float64(179), int64(34), object(12)\n",
      "memory usage: 171.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# summary of different feature types\n",
    "churn.info(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtGfrAgqhvQm"
   },
   "source": [
    "Display the summary statistics for the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HcEuQeWkd81c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>arpu_9</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>onnet_mou_9</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>offnet_mou_9</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_ic_mou_9</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>roam_og_mou_9</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_9</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_7</th>\n",
       "      <th>loc_og_t2m_mou_8</th>\n",
       "      <th>loc_og_t2m_mou_9</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_7</th>\n",
       "      <th>loc_og_t2f_mou_8</th>\n",
       "      <th>loc_og_t2f_mou_9</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_7</th>\n",
       "      <th>loc_og_t2c_mou_8</th>\n",
       "      <th>loc_og_t2c_mou_9</th>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <th>loc_og_mou_9</th>\n",
       "      <th>std_og_t2t_mou_6</th>\n",
       "      <th>std_og_t2t_mou_7</th>\n",
       "      <th>std_og_t2t_mou_8</th>\n",
       "      <th>std_og_t2t_mou_9</th>\n",
       "      <th>std_og_t2m_mou_6</th>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <th>std_og_t2m_mou_8</th>\n",
       "      <th>std_og_t2m_mou_9</th>\n",
       "      <th>std_og_t2f_mou_6</th>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <th>std_og_t2f_mou_8</th>\n",
       "      <th>std_og_t2f_mou_9</th>\n",
       "      <th>std_og_t2c_mou_6</th>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <th>std_og_t2c_mou_8</th>\n",
       "      <th>std_og_t2c_mou_9</th>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <th>std_og_mou_9</th>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <th>isd_og_mou_9</th>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <th>spl_og_mou_9</th>\n",
       "      <th>og_others_6</th>\n",
       "      <th>og_others_7</th>\n",
       "      <th>og_others_8</th>\n",
       "      <th>og_others_9</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>total_og_mou_9</th>\n",
       "      <th>loc_ic_t2t_mou_6</th>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <th>loc_ic_t2t_mou_8</th>\n",
       "      <th>loc_ic_t2t_mou_9</th>\n",
       "      <th>loc_ic_t2m_mou_6</th>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <th>loc_ic_t2m_mou_8</th>\n",
       "      <th>loc_ic_t2m_mou_9</th>\n",
       "      <th>loc_ic_t2f_mou_6</th>\n",
       "      <th>loc_ic_t2f_mou_7</th>\n",
       "      <th>loc_ic_t2f_mou_8</th>\n",
       "      <th>loc_ic_t2f_mou_9</th>\n",
       "      <th>loc_ic_mou_6</th>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <th>loc_ic_mou_9</th>\n",
       "      <th>std_ic_t2t_mou_6</th>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <th>std_ic_t2t_mou_8</th>\n",
       "      <th>std_ic_t2t_mou_9</th>\n",
       "      <th>std_ic_t2m_mou_6</th>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <th>std_ic_t2m_mou_8</th>\n",
       "      <th>std_ic_t2m_mou_9</th>\n",
       "      <th>std_ic_t2f_mou_6</th>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <th>std_ic_t2f_mou_8</th>\n",
       "      <th>std_ic_t2f_mou_9</th>\n",
       "      <th>std_ic_t2o_mou_6</th>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <th>std_ic_t2o_mou_8</th>\n",
       "      <th>std_ic_t2o_mou_9</th>\n",
       "      <th>std_ic_mou_6</th>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <th>std_ic_mou_8</th>\n",
       "      <th>std_ic_mou_9</th>\n",
       "      <th>total_ic_mou_6</th>\n",
       "      <th>total_ic_mou_7</th>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <th>total_ic_mou_9</th>\n",
       "      <th>spl_ic_mou_6</th>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <th>spl_ic_mou_9</th>\n",
       "      <th>isd_ic_mou_6</th>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <th>isd_ic_mou_8</th>\n",
       "      <th>isd_ic_mou_9</th>\n",
       "      <th>ic_others_6</th>\n",
       "      <th>ic_others_7</th>\n",
       "      <th>ic_others_8</th>\n",
       "      <th>ic_others_9</th>\n",
       "      <th>total_rech_num_6</th>\n",
       "      <th>total_rech_num_7</th>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <th>total_rech_num_9</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_rech_amt_9</th>\n",
       "      <th>max_rech_amt_6</th>\n",
       "      <th>max_rech_amt_7</th>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <th>max_rech_amt_9</th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <th>date_of_last_rech_9</th>\n",
       "      <th>last_day_rch_amt_6</th>\n",
       "      <th>last_day_rch_amt_7</th>\n",
       "      <th>last_day_rch_amt_8</th>\n",
       "      <th>last_day_rch_amt_9</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <th>date_of_last_rech_data_8</th>\n",
       "      <th>date_of_last_rech_data_9</th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>total_rech_data_9</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>max_rech_data_9</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_2g_9</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>count_rech_3g_9</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>av_rech_amt_data_9</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>vol_2g_mb_9</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_3g_mb_9</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <th>arpu_3g_8</th>\n",
       "      <th>arpu_3g_9</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>arpu_2g_9</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <th>night_pck_user_9</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>monthly_2g_9</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>sachet_2g_9</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>monthly_3g_9</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99999.0</td>\n",
       "      <td>98981.0</td>\n",
       "      <td>98981.0</td>\n",
       "      <td>98981.0</td>\n",
       "      <td>99999</td>\n",
       "      <td>99398</td>\n",
       "      <td>98899</td>\n",
       "      <td>98340</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.0</td>\n",
       "      <td>96140.0</td>\n",
       "      <td>94621.0</td>\n",
       "      <td>92254.0</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.0</td>\n",
       "      <td>96140.0</td>\n",
       "      <td>94621.0</td>\n",
       "      <td>92254.0</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>96062.000000</td>\n",
       "      <td>96140.000000</td>\n",
       "      <td>94621.000000</td>\n",
       "      <td>92254.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>98392</td>\n",
       "      <td>98232</td>\n",
       "      <td>96377</td>\n",
       "      <td>95239</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>25153</td>\n",
       "      <td>25571</td>\n",
       "      <td>26339</td>\n",
       "      <td>25922</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.00000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/29/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99999</td>\n",
       "      <td>99398</td>\n",
       "      <td>98899</td>\n",
       "      <td>98340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16960</td>\n",
       "      <td>17288</td>\n",
       "      <td>14706</td>\n",
       "      <td>22623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1888</td>\n",
       "      <td>1813</td>\n",
       "      <td>1998</td>\n",
       "      <td>2329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.987358</td>\n",
       "      <td>278.536648</td>\n",
       "      <td>279.154731</td>\n",
       "      <td>261.645069</td>\n",
       "      <td>132.395875</td>\n",
       "      <td>133.670805</td>\n",
       "      <td>133.018098</td>\n",
       "      <td>130.302327</td>\n",
       "      <td>197.935577</td>\n",
       "      <td>197.045133</td>\n",
       "      <td>196.574803</td>\n",
       "      <td>190.337222</td>\n",
       "      <td>9.950013</td>\n",
       "      <td>7.149898</td>\n",
       "      <td>7.292981</td>\n",
       "      <td>6.343841</td>\n",
       "      <td>13.911337</td>\n",
       "      <td>9.818732</td>\n",
       "      <td>9.971890</td>\n",
       "      <td>8.555519</td>\n",
       "      <td>47.100763</td>\n",
       "      <td>46.473010</td>\n",
       "      <td>45.887806</td>\n",
       "      <td>44.584446</td>\n",
       "      <td>93.342088</td>\n",
       "      <td>91.397131</td>\n",
       "      <td>91.755128</td>\n",
       "      <td>90.463192</td>\n",
       "      <td>3.751013</td>\n",
       "      <td>3.792985</td>\n",
       "      <td>3.677991</td>\n",
       "      <td>3.655123</td>\n",
       "      <td>1.123056</td>\n",
       "      <td>1.368500</td>\n",
       "      <td>1.433821</td>\n",
       "      <td>1.232726</td>\n",
       "      <td>144.201175</td>\n",
       "      <td>141.670476</td>\n",
       "      <td>141.328209</td>\n",
       "      <td>138.709970</td>\n",
       "      <td>79.829870</td>\n",
       "      <td>83.299598</td>\n",
       "      <td>83.282673</td>\n",
       "      <td>82.342919</td>\n",
       "      <td>87.299624</td>\n",
       "      <td>90.804137</td>\n",
       "      <td>89.838390</td>\n",
       "      <td>86.276622</td>\n",
       "      <td>1.129011</td>\n",
       "      <td>1.115010</td>\n",
       "      <td>1.067792</td>\n",
       "      <td>1.042362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.261218</td>\n",
       "      <td>175.221436</td>\n",
       "      <td>174.191498</td>\n",
       "      <td>169.664466</td>\n",
       "      <td>0.798277</td>\n",
       "      <td>0.776572</td>\n",
       "      <td>0.791247</td>\n",
       "      <td>0.723892</td>\n",
       "      <td>3.916811</td>\n",
       "      <td>4.978279</td>\n",
       "      <td>5.053769</td>\n",
       "      <td>4.412767</td>\n",
       "      <td>0.454157</td>\n",
       "      <td>0.030235</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>0.047456</td>\n",
       "      <td>305.133424</td>\n",
       "      <td>310.231175</td>\n",
       "      <td>304.119513</td>\n",
       "      <td>289.279198</td>\n",
       "      <td>47.922365</td>\n",
       "      <td>47.990520</td>\n",
       "      <td>47.211362</td>\n",
       "      <td>46.281794</td>\n",
       "      <td>107.475650</td>\n",
       "      <td>107.120493</td>\n",
       "      <td>108.460515</td>\n",
       "      <td>106.155471</td>\n",
       "      <td>12.084305</td>\n",
       "      <td>12.599697</td>\n",
       "      <td>11.751834</td>\n",
       "      <td>12.173105</td>\n",
       "      <td>167.491059</td>\n",
       "      <td>167.719540</td>\n",
       "      <td>167.432575</td>\n",
       "      <td>164.619293</td>\n",
       "      <td>9.575993</td>\n",
       "      <td>10.011904</td>\n",
       "      <td>9.883921</td>\n",
       "      <td>9.432479</td>\n",
       "      <td>20.722240</td>\n",
       "      <td>21.656415</td>\n",
       "      <td>21.183211</td>\n",
       "      <td>19.620913</td>\n",
       "      <td>2.156397</td>\n",
       "      <td>2.216923</td>\n",
       "      <td>2.085004</td>\n",
       "      <td>2.173419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.457179</td>\n",
       "      <td>33.887833</td>\n",
       "      <td>33.154735</td>\n",
       "      <td>31.229344</td>\n",
       "      <td>200.130037</td>\n",
       "      <td>202.853055</td>\n",
       "      <td>198.750783</td>\n",
       "      <td>189.214260</td>\n",
       "      <td>0.061557</td>\n",
       "      <td>0.033585</td>\n",
       "      <td>0.040361</td>\n",
       "      <td>0.163137</td>\n",
       "      <td>7.460608</td>\n",
       "      <td>8.334936</td>\n",
       "      <td>8.442001</td>\n",
       "      <td>8.063003</td>\n",
       "      <td>0.854656</td>\n",
       "      <td>1.012960</td>\n",
       "      <td>0.970800</td>\n",
       "      <td>1.017162</td>\n",
       "      <td>7.558806</td>\n",
       "      <td>7.700367</td>\n",
       "      <td>7.212912</td>\n",
       "      <td>6.893019</td>\n",
       "      <td>327.514615</td>\n",
       "      <td>322.962970</td>\n",
       "      <td>324.157122</td>\n",
       "      <td>303.345673</td>\n",
       "      <td>104.637486</td>\n",
       "      <td>104.752398</td>\n",
       "      <td>107.728207</td>\n",
       "      <td>101.943889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.156252</td>\n",
       "      <td>59.385804</td>\n",
       "      <td>62.641716</td>\n",
       "      <td>43.901249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.463802</td>\n",
       "      <td>2.666419</td>\n",
       "      <td>2.651999</td>\n",
       "      <td>2.441170</td>\n",
       "      <td>126.393392</td>\n",
       "      <td>126.729459</td>\n",
       "      <td>125.717301</td>\n",
       "      <td>124.94144</td>\n",
       "      <td>1.864668</td>\n",
       "      <td>2.044699</td>\n",
       "      <td>2.016288</td>\n",
       "      <td>1.781807</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>0.621720</td>\n",
       "      <td>0.635711</td>\n",
       "      <td>0.659363</td>\n",
       "      <td>192.600982</td>\n",
       "      <td>200.981292</td>\n",
       "      <td>197.526489</td>\n",
       "      <td>192.734315</td>\n",
       "      <td>51.904956</td>\n",
       "      <td>51.229937</td>\n",
       "      <td>50.170154</td>\n",
       "      <td>44.719701</td>\n",
       "      <td>121.396219</td>\n",
       "      <td>128.995847</td>\n",
       "      <td>135.410689</td>\n",
       "      <td>136.056613</td>\n",
       "      <td>89.555057</td>\n",
       "      <td>89.384120</td>\n",
       "      <td>91.173849</td>\n",
       "      <td>100.264116</td>\n",
       "      <td>86.398003</td>\n",
       "      <td>85.914450</td>\n",
       "      <td>86.599478</td>\n",
       "      <td>93.712026</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.020844</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.079641</td>\n",
       "      <td>0.083221</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.068781</td>\n",
       "      <td>0.389384</td>\n",
       "      <td>0.439634</td>\n",
       "      <td>0.450075</td>\n",
       "      <td>0.393104</td>\n",
       "      <td>0.075921</td>\n",
       "      <td>0.078581</td>\n",
       "      <td>0.082941</td>\n",
       "      <td>0.086341</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.080401</td>\n",
       "      <td>0.084501</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.914404</td>\n",
       "      <td>0.908764</td>\n",
       "      <td>0.890808</td>\n",
       "      <td>0.860968</td>\n",
       "      <td>1219.854749</td>\n",
       "      <td>68.170248</td>\n",
       "      <td>66.839062</td>\n",
       "      <td>60.021204</td>\n",
       "      <td>3.299373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.439770</td>\n",
       "      <td>338.156291</td>\n",
       "      <td>344.474791</td>\n",
       "      <td>341.998630</td>\n",
       "      <td>297.207406</td>\n",
       "      <td>308.794148</td>\n",
       "      <td>308.951589</td>\n",
       "      <td>308.477668</td>\n",
       "      <td>316.851613</td>\n",
       "      <td>325.862803</td>\n",
       "      <td>327.170662</td>\n",
       "      <td>319.396092</td>\n",
       "      <td>72.825411</td>\n",
       "      <td>73.447948</td>\n",
       "      <td>68.402466</td>\n",
       "      <td>57.137537</td>\n",
       "      <td>71.443196</td>\n",
       "      <td>58.455762</td>\n",
       "      <td>64.713221</td>\n",
       "      <td>58.438186</td>\n",
       "      <td>150.856393</td>\n",
       "      <td>155.318705</td>\n",
       "      <td>151.184830</td>\n",
       "      <td>147.995390</td>\n",
       "      <td>162.780544</td>\n",
       "      <td>157.492308</td>\n",
       "      <td>156.537048</td>\n",
       "      <td>158.681454</td>\n",
       "      <td>14.230438</td>\n",
       "      <td>14.264986</td>\n",
       "      <td>13.270996</td>\n",
       "      <td>13.457549</td>\n",
       "      <td>5.448946</td>\n",
       "      <td>7.533445</td>\n",
       "      <td>6.783335</td>\n",
       "      <td>5.619021</td>\n",
       "      <td>251.751489</td>\n",
       "      <td>248.731086</td>\n",
       "      <td>245.914311</td>\n",
       "      <td>245.934517</td>\n",
       "      <td>252.476533</td>\n",
       "      <td>263.631042</td>\n",
       "      <td>265.486090</td>\n",
       "      <td>267.184991</td>\n",
       "      <td>255.617850</td>\n",
       "      <td>269.347911</td>\n",
       "      <td>271.757783</td>\n",
       "      <td>261.407396</td>\n",
       "      <td>7.984970</td>\n",
       "      <td>8.599406</td>\n",
       "      <td>7.905971</td>\n",
       "      <td>8.261770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.948499</td>\n",
       "      <td>408.922934</td>\n",
       "      <td>411.633049</td>\n",
       "      <td>405.138658</td>\n",
       "      <td>25.765248</td>\n",
       "      <td>25.603052</td>\n",
       "      <td>25.544471</td>\n",
       "      <td>21.310751</td>\n",
       "      <td>14.936449</td>\n",
       "      <td>20.661570</td>\n",
       "      <td>17.855111</td>\n",
       "      <td>16.328227</td>\n",
       "      <td>4.125911</td>\n",
       "      <td>2.161717</td>\n",
       "      <td>2.323464</td>\n",
       "      <td>3.635466</td>\n",
       "      <td>463.419481</td>\n",
       "      <td>480.031178</td>\n",
       "      <td>478.150031</td>\n",
       "      <td>468.980002</td>\n",
       "      <td>140.258485</td>\n",
       "      <td>145.795055</td>\n",
       "      <td>137.239552</td>\n",
       "      <td>140.130610</td>\n",
       "      <td>171.713903</td>\n",
       "      <td>169.423620</td>\n",
       "      <td>169.723759</td>\n",
       "      <td>165.492803</td>\n",
       "      <td>40.140895</td>\n",
       "      <td>42.977442</td>\n",
       "      <td>39.125379</td>\n",
       "      <td>43.840776</td>\n",
       "      <td>254.124029</td>\n",
       "      <td>256.242707</td>\n",
       "      <td>250.025523</td>\n",
       "      <td>249.845070</td>\n",
       "      <td>54.330607</td>\n",
       "      <td>57.411971</td>\n",
       "      <td>55.073186</td>\n",
       "      <td>53.376273</td>\n",
       "      <td>80.793414</td>\n",
       "      <td>86.521393</td>\n",
       "      <td>83.683565</td>\n",
       "      <td>74.913050</td>\n",
       "      <td>16.495594</td>\n",
       "      <td>16.454061</td>\n",
       "      <td>15.812580</td>\n",
       "      <td>15.978601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.283386</td>\n",
       "      <td>113.720168</td>\n",
       "      <td>110.127008</td>\n",
       "      <td>101.982303</td>\n",
       "      <td>291.651671</td>\n",
       "      <td>298.124954</td>\n",
       "      <td>289.321094</td>\n",
       "      <td>284.823024</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.155725</td>\n",
       "      <td>0.146147</td>\n",
       "      <td>0.527860</td>\n",
       "      <td>59.722948</td>\n",
       "      <td>65.219829</td>\n",
       "      <td>63.813098</td>\n",
       "      <td>63.505379</td>\n",
       "      <td>11.955164</td>\n",
       "      <td>12.673099</td>\n",
       "      <td>13.284348</td>\n",
       "      <td>12.381172</td>\n",
       "      <td>7.078405</td>\n",
       "      <td>7.070422</td>\n",
       "      <td>7.203753</td>\n",
       "      <td>7.096261</td>\n",
       "      <td>398.019701</td>\n",
       "      <td>408.114237</td>\n",
       "      <td>416.540455</td>\n",
       "      <td>404.588583</td>\n",
       "      <td>120.614894</td>\n",
       "      <td>124.523970</td>\n",
       "      <td>126.902505</td>\n",
       "      <td>125.375109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.356649</td>\n",
       "      <td>95.915385</td>\n",
       "      <td>104.431816</td>\n",
       "      <td>90.809712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.789128</td>\n",
       "      <td>3.031593</td>\n",
       "      <td>3.074987</td>\n",
       "      <td>2.516339</td>\n",
       "      <td>108.477235</td>\n",
       "      <td>109.765267</td>\n",
       "      <td>109.437851</td>\n",
       "      <td>111.36376</td>\n",
       "      <td>2.570254</td>\n",
       "      <td>2.768332</td>\n",
       "      <td>2.720132</td>\n",
       "      <td>2.214701</td>\n",
       "      <td>1.274428</td>\n",
       "      <td>1.394524</td>\n",
       "      <td>1.422827</td>\n",
       "      <td>1.411513</td>\n",
       "      <td>192.646318</td>\n",
       "      <td>196.791224</td>\n",
       "      <td>191.301305</td>\n",
       "      <td>188.400286</td>\n",
       "      <td>213.356445</td>\n",
       "      <td>212.302217</td>\n",
       "      <td>212.347892</td>\n",
       "      <td>198.653570</td>\n",
       "      <td>544.247227</td>\n",
       "      <td>541.494013</td>\n",
       "      <td>558.775335</td>\n",
       "      <td>577.394194</td>\n",
       "      <td>193.124653</td>\n",
       "      <td>195.893924</td>\n",
       "      <td>188.180936</td>\n",
       "      <td>216.291992</td>\n",
       "      <td>172.767523</td>\n",
       "      <td>176.379871</td>\n",
       "      <td>168.247852</td>\n",
       "      <td>171.384224</td>\n",
       "      <td>0.156391</td>\n",
       "      <td>0.150014</td>\n",
       "      <td>0.142863</td>\n",
       "      <td>0.125366</td>\n",
       "      <td>0.295058</td>\n",
       "      <td>0.304395</td>\n",
       "      <td>0.299568</td>\n",
       "      <td>0.278120</td>\n",
       "      <td>1.497320</td>\n",
       "      <td>1.636230</td>\n",
       "      <td>1.630263</td>\n",
       "      <td>1.347140</td>\n",
       "      <td>0.363371</td>\n",
       "      <td>0.387231</td>\n",
       "      <td>0.384947</td>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.568344</td>\n",
       "      <td>0.628334</td>\n",
       "      <td>0.660234</td>\n",
       "      <td>0.650457</td>\n",
       "      <td>0.279772</td>\n",
       "      <td>0.287950</td>\n",
       "      <td>0.311885</td>\n",
       "      <td>0.345987</td>\n",
       "      <td>954.733842</td>\n",
       "      <td>267.580450</td>\n",
       "      <td>271.201856</td>\n",
       "      <td>253.938223</td>\n",
       "      <td>32.408353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2258.709000</td>\n",
       "      <td>-2014.045000</td>\n",
       "      <td>-945.808000</td>\n",
       "      <td>-1899.505000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.820000</td>\n",
       "      <td>-26.040000</td>\n",
       "      <td>-24.490000</td>\n",
       "      <td>-71.090000</td>\n",
       "      <td>-35.830000</td>\n",
       "      <td>-15.480000</td>\n",
       "      <td>-55.830000</td>\n",
       "      <td>-45.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.411500</td>\n",
       "      <td>86.980500</td>\n",
       "      <td>84.126000</td>\n",
       "      <td>62.685000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>6.460000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>34.730000</td>\n",
       "      <td>32.190000</td>\n",
       "      <td>31.630000</td>\n",
       "      <td>27.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>9.880000</td>\n",
       "      <td>10.025000</td>\n",
       "      <td>9.810000</td>\n",
       "      <td>8.810000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.110000</td>\n",
       "      <td>17.480000</td>\n",
       "      <td>17.110000</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.740000</td>\n",
       "      <td>43.010000</td>\n",
       "      <td>38.580000</td>\n",
       "      <td>25.510000</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>17.290000</td>\n",
       "      <td>18.590000</td>\n",
       "      <td>18.930000</td>\n",
       "      <td>18.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.390000</td>\n",
       "      <td>32.460000</td>\n",
       "      <td>32.740000</td>\n",
       "      <td>32.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.530000</td>\n",
       "      <td>41.190000</td>\n",
       "      <td>38.290000</td>\n",
       "      <td>32.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>467.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.704000</td>\n",
       "      <td>191.640000</td>\n",
       "      <td>192.080000</td>\n",
       "      <td>176.849000</td>\n",
       "      <td>34.310000</td>\n",
       "      <td>32.330000</td>\n",
       "      <td>32.360000</td>\n",
       "      <td>29.840000</td>\n",
       "      <td>96.310000</td>\n",
       "      <td>91.735000</td>\n",
       "      <td>92.140000</td>\n",
       "      <td>87.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>11.610000</td>\n",
       "      <td>11.730000</td>\n",
       "      <td>11.260000</td>\n",
       "      <td>41.030000</td>\n",
       "      <td>40.430000</td>\n",
       "      <td>40.360000</td>\n",
       "      <td>39.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.110000</td>\n",
       "      <td>63.685000</td>\n",
       "      <td>63.730000</td>\n",
       "      <td>61.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>3.635000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.640000</td>\n",
       "      <td>11.090000</td>\n",
       "      <td>10.410000</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.140000</td>\n",
       "      <td>141.530000</td>\n",
       "      <td>138.610000</td>\n",
       "      <td>125.460000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>15.740000</td>\n",
       "      <td>16.030000</td>\n",
       "      <td>15.660000</td>\n",
       "      <td>56.490000</td>\n",
       "      <td>57.080000</td>\n",
       "      <td>58.240000</td>\n",
       "      <td>56.610000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>92.160000</td>\n",
       "      <td>92.550000</td>\n",
       "      <td>93.830000</td>\n",
       "      <td>91.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.890000</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>5.380000</td>\n",
       "      <td>114.740000</td>\n",
       "      <td>116.340000</td>\n",
       "      <td>114.660000</td>\n",
       "      <td>105.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>2.605000</td>\n",
       "      <td>10.830000</td>\n",
       "      <td>8.810000</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371.060000</td>\n",
       "      <td>365.344500</td>\n",
       "      <td>369.370500</td>\n",
       "      <td>353.466500</td>\n",
       "      <td>118.740000</td>\n",
       "      <td>115.595000</td>\n",
       "      <td>115.860000</td>\n",
       "      <td>112.130000</td>\n",
       "      <td>231.860000</td>\n",
       "      <td>226.815000</td>\n",
       "      <td>228.260000</td>\n",
       "      <td>220.505000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.960000</td>\n",
       "      <td>39.910000</td>\n",
       "      <td>40.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>110.390000</td>\n",
       "      <td>107.560000</td>\n",
       "      <td>109.090000</td>\n",
       "      <td>106.810000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.270000</td>\n",
       "      <td>164.382500</td>\n",
       "      <td>166.110000</td>\n",
       "      <td>162.225000</td>\n",
       "      <td>30.807500</td>\n",
       "      <td>31.132500</td>\n",
       "      <td>30.580000</td>\n",
       "      <td>28.230000</td>\n",
       "      <td>53.290000</td>\n",
       "      <td>54.040000</td>\n",
       "      <td>52.490000</td>\n",
       "      <td>48.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.837500</td>\n",
       "      <td>150.615000</td>\n",
       "      <td>147.940000</td>\n",
       "      <td>142.105000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>372.860000</td>\n",
       "      <td>378.570000</td>\n",
       "      <td>369.900000</td>\n",
       "      <td>353.480000</td>\n",
       "      <td>46.840000</td>\n",
       "      <td>45.810000</td>\n",
       "      <td>46.290000</td>\n",
       "      <td>45.180000</td>\n",
       "      <td>132.387500</td>\n",
       "      <td>130.960000</td>\n",
       "      <td>133.930000</td>\n",
       "      <td>130.490000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>8.282500</td>\n",
       "      <td>8.110000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>208.075000</td>\n",
       "      <td>205.837500</td>\n",
       "      <td>207.280000</td>\n",
       "      <td>202.737500</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>15.030000</td>\n",
       "      <td>15.740000</td>\n",
       "      <td>15.360000</td>\n",
       "      <td>14.260000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>28.310000</td>\n",
       "      <td>27.710000</td>\n",
       "      <td>25.690000</td>\n",
       "      <td>251.670000</td>\n",
       "      <td>250.660000</td>\n",
       "      <td>248.990000</td>\n",
       "      <td>236.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>437.500000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>434.500000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>119.560000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>140.010000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>140.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1807.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>38805.617000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>10427.460000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>9667.130000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>10310.760000</td>\n",
       "      <td>13724.380000</td>\n",
       "      <td>15371.040000</td>\n",
       "      <td>13095.360000</td>\n",
       "      <td>8464.030000</td>\n",
       "      <td>3775.110000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "      <td>4428.460000</td>\n",
       "      <td>6431.330000</td>\n",
       "      <td>7400.660000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>10389.240000</td>\n",
       "      <td>4729.740000</td>\n",
       "      <td>4557.140000</td>\n",
       "      <td>4961.330000</td>\n",
       "      <td>4429.880000</td>\n",
       "      <td>1466.030000</td>\n",
       "      <td>1196.430000</td>\n",
       "      <td>928.490000</td>\n",
       "      <td>927.410000</td>\n",
       "      <td>342.860000</td>\n",
       "      <td>916.240000</td>\n",
       "      <td>502.090000</td>\n",
       "      <td>339.840000</td>\n",
       "      <td>10643.380000</td>\n",
       "      <td>7674.780000</td>\n",
       "      <td>11039.910000</td>\n",
       "      <td>11099.260000</td>\n",
       "      <td>7366.580000</td>\n",
       "      <td>8133.660000</td>\n",
       "      <td>8014.430000</td>\n",
       "      <td>9382.580000</td>\n",
       "      <td>8314.760000</td>\n",
       "      <td>9284.740000</td>\n",
       "      <td>13950.040000</td>\n",
       "      <td>10223.430000</td>\n",
       "      <td>628.560000</td>\n",
       "      <td>544.630000</td>\n",
       "      <td>516.910000</td>\n",
       "      <td>808.490000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8432.990000</td>\n",
       "      <td>10936.730000</td>\n",
       "      <td>13980.060000</td>\n",
       "      <td>11495.310000</td>\n",
       "      <td>5900.660000</td>\n",
       "      <td>5490.280000</td>\n",
       "      <td>5681.540000</td>\n",
       "      <td>4244.530000</td>\n",
       "      <td>1023.210000</td>\n",
       "      <td>2372.510000</td>\n",
       "      <td>1390.880000</td>\n",
       "      <td>1635.710000</td>\n",
       "      <td>800.890000</td>\n",
       "      <td>370.130000</td>\n",
       "      <td>394.930000</td>\n",
       "      <td>787.790000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>11365.310000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>11517.730000</td>\n",
       "      <td>6626.930000</td>\n",
       "      <td>9324.660000</td>\n",
       "      <td>10696.230000</td>\n",
       "      <td>10598.830000</td>\n",
       "      <td>4693.860000</td>\n",
       "      <td>4455.830000</td>\n",
       "      <td>6274.190000</td>\n",
       "      <td>5463.780000</td>\n",
       "      <td>1872.340000</td>\n",
       "      <td>1983.010000</td>\n",
       "      <td>2433.060000</td>\n",
       "      <td>4318.280000</td>\n",
       "      <td>7454.630000</td>\n",
       "      <td>9669.910000</td>\n",
       "      <td>10830.160000</td>\n",
       "      <td>10796.290000</td>\n",
       "      <td>5459.560000</td>\n",
       "      <td>5800.930000</td>\n",
       "      <td>4309.290000</td>\n",
       "      <td>3819.830000</td>\n",
       "      <td>5647.160000</td>\n",
       "      <td>6141.880000</td>\n",
       "      <td>5645.860000</td>\n",
       "      <td>5689.760000</td>\n",
       "      <td>1351.110000</td>\n",
       "      <td>1136.080000</td>\n",
       "      <td>1394.890000</td>\n",
       "      <td>1431.960000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5712.110000</td>\n",
       "      <td>6745.760000</td>\n",
       "      <td>5957.140000</td>\n",
       "      <td>5956.660000</td>\n",
       "      <td>7716.140000</td>\n",
       "      <td>9699.010000</td>\n",
       "      <td>10830.380000</td>\n",
       "      <td>10796.590000</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>21.330000</td>\n",
       "      <td>16.860000</td>\n",
       "      <td>62.380000</td>\n",
       "      <td>6789.410000</td>\n",
       "      <td>5289.540000</td>\n",
       "      <td>4127.010000</td>\n",
       "      <td>5057.740000</td>\n",
       "      <td>1362.940000</td>\n",
       "      <td>1495.940000</td>\n",
       "      <td>2327.510000</td>\n",
       "      <td>1005.230000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>37235.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>4010.000000</td>\n",
       "      <td>4449.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.00000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>7546.000000</td>\n",
       "      <td>4365.000000</td>\n",
       "      <td>4076.000000</td>\n",
       "      <td>4061.000000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>8993.950000</td>\n",
       "      <td>45735.400000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>30036.060000</td>\n",
       "      <td>39221.270000</td>\n",
       "      <td>6362.280000</td>\n",
       "      <td>4980.900000</td>\n",
       "      <td>3716.900000</td>\n",
       "      <td>13884.310000</td>\n",
       "      <td>6433.760000</td>\n",
       "      <td>4809.360000</td>\n",
       "      <td>3483.170000</td>\n",
       "      <td>3467.170000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.210000</td>\n",
       "      <td>2618.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "count     99999.0         98981.0         98981.0         98981.0   \n",
       "unique        NaN             NaN             NaN             NaN   \n",
       "top           NaN             NaN             NaN             NaN   \n",
       "freq          NaN             NaN             NaN             NaN   \n",
       "mean        109.0             0.0             0.0             0.0   \n",
       "std           0.0             0.0             0.0             0.0   \n",
       "min         109.0             0.0             0.0             0.0   \n",
       "25%         109.0             0.0             0.0             0.0   \n",
       "50%         109.0             0.0             0.0             0.0   \n",
       "75%         109.0             0.0             0.0             0.0   \n",
       "max         109.0             0.0             0.0             0.0   \n",
       "\n",
       "       last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "count                 99999                99398                98899   \n",
       "unique                    1                    1                    1   \n",
       "top               6/30/2014            7/31/2014            8/31/2014   \n",
       "freq                  99999                99398                98899   \n",
       "mean                    NaN                  NaN                  NaN   \n",
       "std                     NaN                  NaN                  NaN   \n",
       "min                     NaN                  NaN                  NaN   \n",
       "25%                     NaN                  NaN                  NaN   \n",
       "50%                     NaN                  NaN                  NaN   \n",
       "75%                     NaN                  NaN                  NaN   \n",
       "max                     NaN                  NaN                  NaN   \n",
       "\n",
       "       last_date_of_month_9        arpu_6        arpu_7        arpu_8  \\\n",
       "count                 98340  99999.000000  99999.000000  99999.000000   \n",
       "unique                    1           NaN           NaN           NaN   \n",
       "top               9/30/2014           NaN           NaN           NaN   \n",
       "freq                  98340           NaN           NaN           NaN   \n",
       "mean                    NaN    282.987358    278.536648    279.154731   \n",
       "std                     NaN    328.439770    338.156291    344.474791   \n",
       "min                     NaN  -2258.709000  -2014.045000   -945.808000   \n",
       "25%                     NaN     93.411500     86.980500     84.126000   \n",
       "50%                     NaN    197.704000    191.640000    192.080000   \n",
       "75%                     NaN    371.060000    365.344500    369.370500   \n",
       "max                     NaN  27731.088000  35145.834000  33543.624000   \n",
       "\n",
       "              arpu_9   onnet_mou_6   onnet_mou_7   onnet_mou_8   onnet_mou_9  \\\n",
       "count   99999.000000  96062.000000  96140.000000  94621.000000  92254.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean      261.645069    132.395875    133.670805    133.018098    130.302327   \n",
       "std       341.998630    297.207406    308.794148    308.951589    308.477668   \n",
       "min     -1899.505000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        62.685000      7.380000      6.660000      6.460000      5.330000   \n",
       "50%       176.849000     34.310000     32.330000     32.360000     29.840000   \n",
       "75%       353.466500    118.740000    115.595000    115.860000    112.130000   \n",
       "max     38805.617000   7376.710000   8157.780000  10752.560000  10427.460000   \n",
       "\n",
       "        offnet_mou_6  offnet_mou_7  offnet_mou_8  offnet_mou_9  roam_ic_mou_6  \\\n",
       "count   96062.000000  96140.000000  94621.000000  92254.000000   96062.000000   \n",
       "unique           NaN           NaN           NaN           NaN            NaN   \n",
       "top              NaN           NaN           NaN           NaN            NaN   \n",
       "freq             NaN           NaN           NaN           NaN            NaN   \n",
       "mean      197.935577    197.045133    196.574803    190.337222       9.950013   \n",
       "std       316.851613    325.862803    327.170662    319.396092      72.825411   \n",
       "min         0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%        34.730000     32.190000     31.630000     27.130000       0.000000   \n",
       "50%        96.310000     91.735000     92.140000     87.290000       0.000000   \n",
       "75%       231.860000    226.815000    228.260000    220.505000       0.000000   \n",
       "max      8362.360000   9667.130000  14007.340000  10310.760000   13724.380000   \n",
       "\n",
       "        roam_ic_mou_7  roam_ic_mou_8  roam_ic_mou_9  roam_og_mou_6  \\\n",
       "count    96140.000000   94621.000000   92254.000000   96062.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         7.149898       7.292981       6.343841      13.911337   \n",
       "std         73.447948      68.402466      57.137537      71.443196   \n",
       "min          0.000000       0.000000       0.000000       0.000000   \n",
       "25%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%          0.000000       0.000000       0.000000       0.000000   \n",
       "75%          0.000000       0.000000       0.000000       0.000000   \n",
       "max      15371.040000   13095.360000    8464.030000    3775.110000   \n",
       "\n",
       "        roam_og_mou_7  roam_og_mou_8  roam_og_mou_9  loc_og_t2t_mou_6  \\\n",
       "count    96140.000000   94621.000000   92254.000000      96062.000000   \n",
       "unique            NaN            NaN            NaN               NaN   \n",
       "top               NaN            NaN            NaN               NaN   \n",
       "freq              NaN            NaN            NaN               NaN   \n",
       "mean         9.818732       9.971890       8.555519         47.100763   \n",
       "std         58.455762      64.713221      58.438186        150.856393   \n",
       "min          0.000000       0.000000       0.000000          0.000000   \n",
       "25%          0.000000       0.000000       0.000000          1.660000   \n",
       "50%          0.000000       0.000000       0.000000         11.910000   \n",
       "75%          0.000000       0.000000       0.000000         40.960000   \n",
       "max       2812.040000    5337.040000    4428.460000       6431.330000   \n",
       "\n",
       "        loc_og_t2t_mou_7  loc_og_t2t_mou_8  loc_og_t2t_mou_9  \\\n",
       "count       96140.000000      94621.000000      92254.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           46.473010         45.887806         44.584446   \n",
       "std           155.318705        151.184830        147.995390   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             1.630000          1.600000          1.360000   \n",
       "50%            11.610000         11.730000         11.260000   \n",
       "75%            39.910000         40.110000         39.280000   \n",
       "max          7400.660000      10752.560000      10389.240000   \n",
       "\n",
       "        loc_og_t2m_mou_6  loc_og_t2m_mou_7  loc_og_t2m_mou_8  \\\n",
       "count       96062.000000      96140.000000      94621.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           93.342088         91.397131         91.755128   \n",
       "std           162.780544        157.492308        156.537048   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             9.880000         10.025000          9.810000   \n",
       "50%            41.030000         40.430000         40.360000   \n",
       "75%           110.390000        107.560000        109.090000   \n",
       "max          4729.740000       4557.140000       4961.330000   \n",
       "\n",
       "        loc_og_t2m_mou_9  loc_og_t2f_mou_6  loc_og_t2f_mou_7  \\\n",
       "count       92254.000000      96062.000000      96140.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           90.463192          3.751013          3.792985   \n",
       "std           158.681454         14.230438         14.264986   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             8.810000          0.000000          0.000000   \n",
       "50%            39.120000          0.000000          0.000000   \n",
       "75%           106.810000          2.080000          2.090000   \n",
       "max          4429.880000       1466.030000       1196.430000   \n",
       "\n",
       "        loc_og_t2f_mou_8  loc_og_t2f_mou_9  loc_og_t2c_mou_6  \\\n",
       "count       94621.000000      92254.000000      96062.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean            3.677991          3.655123          1.123056   \n",
       "std            13.270996         13.457549          5.448946   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             0.000000          0.000000          0.000000   \n",
       "75%             2.040000          1.940000          0.000000   \n",
       "max           928.490000        927.410000        342.860000   \n",
       "\n",
       "        loc_og_t2c_mou_7  loc_og_t2c_mou_8  loc_og_t2c_mou_9  loc_og_mou_6  \\\n",
       "count       96140.000000      94621.000000      92254.000000  96062.000000   \n",
       "unique               NaN               NaN               NaN           NaN   \n",
       "top                  NaN               NaN               NaN           NaN   \n",
       "freq                 NaN               NaN               NaN           NaN   \n",
       "mean            1.368500          1.433821          1.232726    144.201175   \n",
       "std             7.533445          6.783335          5.619021    251.751489   \n",
       "min             0.000000          0.000000          0.000000      0.000000   \n",
       "25%             0.000000          0.000000          0.000000     17.110000   \n",
       "50%             0.000000          0.000000          0.000000     65.110000   \n",
       "75%             0.000000          0.000000          0.000000    168.270000   \n",
       "max           916.240000        502.090000        339.840000  10643.380000   \n",
       "\n",
       "        loc_og_mou_7  loc_og_mou_8  loc_og_mou_9  std_og_t2t_mou_6  \\\n",
       "count   96140.000000  94621.000000  92254.000000      96062.000000   \n",
       "unique           NaN           NaN           NaN               NaN   \n",
       "top              NaN           NaN           NaN               NaN   \n",
       "freq             NaN           NaN           NaN               NaN   \n",
       "mean      141.670476    141.328209    138.709970         79.829870   \n",
       "std       248.731086    245.914311    245.934517        252.476533   \n",
       "min         0.000000      0.000000      0.000000          0.000000   \n",
       "25%        17.480000     17.110000     15.560000          0.000000   \n",
       "50%        63.685000     63.730000     61.840000          0.000000   \n",
       "75%       164.382500    166.110000    162.225000         30.807500   \n",
       "max      7674.780000  11039.910000  11099.260000       7366.580000   \n",
       "\n",
       "        std_og_t2t_mou_7  std_og_t2t_mou_8  std_og_t2t_mou_9  \\\n",
       "count       96140.000000      94621.000000      92254.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           83.299598         83.282673         82.342919   \n",
       "std           263.631042        265.486090        267.184991   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             0.000000          0.000000          0.000000   \n",
       "75%            31.132500         30.580000         28.230000   \n",
       "max          8133.660000       8014.430000       9382.580000   \n",
       "\n",
       "        std_og_t2m_mou_6  std_og_t2m_mou_7  std_og_t2m_mou_8  \\\n",
       "count       96062.000000      96140.000000      94621.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           87.299624         90.804137         89.838390   \n",
       "std           255.617850        269.347911        271.757783   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             3.950000          3.635000          3.310000   \n",
       "75%            53.290000         54.040000         52.490000   \n",
       "max          8314.760000       9284.740000      13950.040000   \n",
       "\n",
       "        std_og_t2m_mou_9  std_og_t2f_mou_6  std_og_t2f_mou_7  \\\n",
       "count       92254.000000      96062.000000      96140.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           86.276622          1.129011          1.115010   \n",
       "std           261.407396          7.984970          8.599406   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             2.500000          0.000000          0.000000   \n",
       "75%            48.560000          0.000000          0.000000   \n",
       "max         10223.430000        628.560000        544.630000   \n",
       "\n",
       "        std_og_t2f_mou_8  std_og_t2f_mou_9  std_og_t2c_mou_6  \\\n",
       "count       94621.000000      92254.000000           96062.0   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean            1.067792          1.042362               0.0   \n",
       "std             7.905971          8.261770               0.0   \n",
       "min             0.000000          0.000000               0.0   \n",
       "25%             0.000000          0.000000               0.0   \n",
       "50%             0.000000          0.000000               0.0   \n",
       "75%             0.000000          0.000000               0.0   \n",
       "max           516.910000        808.490000               0.0   \n",
       "\n",
       "        std_og_t2c_mou_7  std_og_t2c_mou_8  std_og_t2c_mou_9  std_og_mou_6  \\\n",
       "count            96140.0           94621.0           92254.0  96062.000000   \n",
       "unique               NaN               NaN               NaN           NaN   \n",
       "top                  NaN               NaN               NaN           NaN   \n",
       "freq                 NaN               NaN               NaN           NaN   \n",
       "mean                 0.0               0.0               0.0    168.261218   \n",
       "std                  0.0               0.0               0.0    389.948499   \n",
       "min                  0.0               0.0               0.0      0.000000   \n",
       "25%                  0.0               0.0               0.0      0.000000   \n",
       "50%                  0.0               0.0               0.0     11.640000   \n",
       "75%                  0.0               0.0               0.0    144.837500   \n",
       "max                  0.0               0.0               0.0   8432.990000   \n",
       "\n",
       "        std_og_mou_7  std_og_mou_8  std_og_mou_9  isd_og_mou_6  isd_og_mou_7  \\\n",
       "count   96140.000000  94621.000000  92254.000000  96062.000000  96140.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean      175.221436    174.191498    169.664466      0.798277      0.776572   \n",
       "std       408.922934    411.633049    405.138658     25.765248     25.603052   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        11.090000     10.410000      8.410000      0.000000      0.000000   \n",
       "75%       150.615000    147.940000    142.105000      0.000000      0.000000   \n",
       "max     10936.730000  13980.060000  11495.310000   5900.660000   5490.280000   \n",
       "\n",
       "        isd_og_mou_8  isd_og_mou_9  spl_og_mou_6  spl_og_mou_7  spl_og_mou_8  \\\n",
       "count   94621.000000  92254.000000  96062.000000  96140.000000  94621.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.791247      0.723892      3.916811      4.978279      5.053769   \n",
       "std        25.544471     21.310751     14.936449     20.661570     17.855111   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      2.430000      3.710000      3.990000   \n",
       "max      5681.540000   4244.530000   1023.210000   2372.510000   1390.880000   \n",
       "\n",
       "        spl_og_mou_9   og_others_6   og_others_7   og_others_8   og_others_9  \\\n",
       "count   92254.000000  96062.000000  96140.000000  94621.000000  92254.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        4.412767      0.454157      0.030235      0.033372      0.047456   \n",
       "std        16.328227      4.125911      2.161717      2.323464      3.635466   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         3.230000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      1635.710000    800.890000    370.130000    394.930000    787.790000   \n",
       "\n",
       "        total_og_mou_6  total_og_mou_7  total_og_mou_8  total_og_mou_9  \\\n",
       "count     99999.000000    99999.000000    99999.000000    99999.000000   \n",
       "unique             NaN             NaN             NaN             NaN   \n",
       "top                NaN             NaN             NaN             NaN   \n",
       "freq               NaN             NaN             NaN             NaN   \n",
       "mean        305.133424      310.231175      304.119513      289.279198   \n",
       "std         463.419481      480.031178      478.150031      468.980002   \n",
       "min           0.000000        0.000000        0.000000        0.000000   \n",
       "25%          44.740000       43.010000       38.580000       25.510000   \n",
       "50%         145.140000      141.530000      138.610000      125.460000   \n",
       "75%         372.860000      378.570000      369.900000      353.480000   \n",
       "max       10674.030000    11365.310000    14043.060000    11517.730000   \n",
       "\n",
       "        loc_ic_t2t_mou_6  loc_ic_t2t_mou_7  loc_ic_t2t_mou_8  \\\n",
       "count       96062.000000      96140.000000      94621.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           47.922365         47.990520         47.211362   \n",
       "std           140.258485        145.795055        137.239552   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             2.990000          3.230000          3.280000   \n",
       "50%            15.690000         15.740000         16.030000   \n",
       "75%            46.840000         45.810000         46.290000   \n",
       "max          6626.930000       9324.660000      10696.230000   \n",
       "\n",
       "        loc_ic_t2t_mou_9  loc_ic_t2m_mou_6  loc_ic_t2m_mou_7  \\\n",
       "count       92254.000000      96062.000000      96140.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           46.281794        107.475650        107.120493   \n",
       "std           140.130610        171.713903        169.423620   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             3.290000         17.290000         18.590000   \n",
       "50%            15.660000         56.490000         57.080000   \n",
       "75%            45.180000        132.387500        130.960000   \n",
       "max         10598.830000       4693.860000       4455.830000   \n",
       "\n",
       "        loc_ic_t2m_mou_8  loc_ic_t2m_mou_9  loc_ic_t2f_mou_6  \\\n",
       "count       94621.000000      92254.000000      96062.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean          108.460515        106.155471         12.084305   \n",
       "std           169.723759        165.492803         40.140895   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%            18.930000         18.560000          0.000000   \n",
       "50%            58.240000         56.610000          0.880000   \n",
       "75%           133.930000        130.490000          8.140000   \n",
       "max          6274.190000       5463.780000       1872.340000   \n",
       "\n",
       "        loc_ic_t2f_mou_7  loc_ic_t2f_mou_8  loc_ic_t2f_mou_9  loc_ic_mou_6  \\\n",
       "count       96140.000000      94621.000000      92254.000000  96062.000000   \n",
       "unique               NaN               NaN               NaN           NaN   \n",
       "top                  NaN               NaN               NaN           NaN   \n",
       "freq                 NaN               NaN               NaN           NaN   \n",
       "mean           12.599697         11.751834         12.173105    167.491059   \n",
       "std            42.977442         39.125379         43.840776    254.124029   \n",
       "min             0.000000          0.000000          0.000000      0.000000   \n",
       "25%             0.000000          0.000000          0.000000     30.390000   \n",
       "50%             0.930000          0.930000          0.960000     92.160000   \n",
       "75%             8.282500          8.110000          8.140000    208.075000   \n",
       "max          1983.010000       2433.060000       4318.280000   7454.630000   \n",
       "\n",
       "        loc_ic_mou_7  loc_ic_mou_8  loc_ic_mou_9  std_ic_t2t_mou_6  \\\n",
       "count   96140.000000  94621.000000  92254.000000      96062.000000   \n",
       "unique           NaN           NaN           NaN               NaN   \n",
       "top              NaN           NaN           NaN               NaN   \n",
       "freq             NaN           NaN           NaN               NaN   \n",
       "mean      167.719540    167.432575    164.619293          9.575993   \n",
       "std       256.242707    250.025523    249.845070         54.330607   \n",
       "min         0.000000      0.000000      0.000000          0.000000   \n",
       "25%        32.460000     32.740000     32.290000          0.000000   \n",
       "50%        92.550000     93.830000     91.640000          0.000000   \n",
       "75%       205.837500    207.280000    202.737500          4.060000   \n",
       "max      9669.910000  10830.160000  10796.290000       5459.560000   \n",
       "\n",
       "        std_ic_t2t_mou_7  std_ic_t2t_mou_8  std_ic_t2t_mou_9  \\\n",
       "count       96140.000000      94621.000000      92254.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           10.011904          9.883921          9.432479   \n",
       "std            57.411971         55.073186         53.376273   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             0.000000          0.000000          0.000000   \n",
       "75%             4.230000          4.080000          3.510000   \n",
       "max          5800.930000       4309.290000       3819.830000   \n",
       "\n",
       "        std_ic_t2m_mou_6  std_ic_t2m_mou_7  std_ic_t2m_mou_8  \\\n",
       "count       96062.000000      96140.000000      94621.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           20.722240         21.656415         21.183211   \n",
       "std            80.793414         86.521393         83.683565   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             2.030000          2.040000          2.030000   \n",
       "75%            15.030000         15.740000         15.360000   \n",
       "max          5647.160000       6141.880000       5645.860000   \n",
       "\n",
       "        std_ic_t2m_mou_9  std_ic_t2f_mou_6  std_ic_t2f_mou_7  \\\n",
       "count       92254.000000      96062.000000      96140.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean           19.620913          2.156397          2.216923   \n",
       "std            74.913050         16.495594         16.454061   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             0.000000          0.000000          0.000000   \n",
       "50%             1.740000          0.000000          0.000000   \n",
       "75%            14.260000          0.000000          0.000000   \n",
       "max          5689.760000       1351.110000       1136.080000   \n",
       "\n",
       "        std_ic_t2f_mou_8  std_ic_t2f_mou_9  std_ic_t2o_mou_6  \\\n",
       "count       94621.000000      92254.000000           96062.0   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean            2.085004          2.173419               0.0   \n",
       "std            15.812580         15.978601               0.0   \n",
       "min             0.000000          0.000000               0.0   \n",
       "25%             0.000000          0.000000               0.0   \n",
       "50%             0.000000          0.000000               0.0   \n",
       "75%             0.000000          0.000000               0.0   \n",
       "max          1394.890000       1431.960000               0.0   \n",
       "\n",
       "        std_ic_t2o_mou_7  std_ic_t2o_mou_8  std_ic_t2o_mou_9  std_ic_mou_6  \\\n",
       "count            96140.0           94621.0           92254.0  96062.000000   \n",
       "unique               NaN               NaN               NaN           NaN   \n",
       "top                  NaN               NaN               NaN           NaN   \n",
       "freq                 NaN               NaN               NaN           NaN   \n",
       "mean                 0.0               0.0               0.0     32.457179   \n",
       "std                  0.0               0.0               0.0    106.283386   \n",
       "min                  0.0               0.0               0.0      0.000000   \n",
       "25%                  0.0               0.0               0.0      0.000000   \n",
       "50%                  0.0               0.0               0.0      5.890000   \n",
       "75%                  0.0               0.0               0.0     26.930000   \n",
       "max                  0.0               0.0               0.0   5712.110000   \n",
       "\n",
       "        std_ic_mou_7  std_ic_mou_8  std_ic_mou_9  total_ic_mou_6  \\\n",
       "count   96140.000000  94621.000000  92254.000000    99999.000000   \n",
       "unique           NaN           NaN           NaN             NaN   \n",
       "top              NaN           NaN           NaN             NaN   \n",
       "freq             NaN           NaN           NaN             NaN   \n",
       "mean       33.887833     33.154735     31.229344      200.130037   \n",
       "std       113.720168    110.127008    101.982303      291.651671   \n",
       "min         0.000000      0.000000      0.000000        0.000000   \n",
       "25%         0.000000      0.010000      0.000000       38.530000   \n",
       "50%         5.960000      5.880000      5.380000      114.740000   \n",
       "75%        28.310000     27.710000     25.690000      251.670000   \n",
       "max      6745.760000   5957.140000   5956.660000     7716.140000   \n",
       "\n",
       "        total_ic_mou_7  total_ic_mou_8  total_ic_mou_9  spl_ic_mou_6  \\\n",
       "count     99999.000000    99999.000000    99999.000000  96062.000000   \n",
       "unique             NaN             NaN             NaN           NaN   \n",
       "top                NaN             NaN             NaN           NaN   \n",
       "freq               NaN             NaN             NaN           NaN   \n",
       "mean        202.853055      198.750783      189.214260      0.061557   \n",
       "std         298.124954      289.321094      284.823024      0.160920   \n",
       "min           0.000000        0.000000        0.000000      0.000000   \n",
       "25%          41.190000       38.290000       32.370000      0.000000   \n",
       "50%         116.340000      114.660000      105.890000      0.000000   \n",
       "75%         250.660000      248.990000      236.320000      0.000000   \n",
       "max        9699.010000    10830.380000    10796.590000     19.760000   \n",
       "\n",
       "        spl_ic_mou_7  spl_ic_mou_8  spl_ic_mou_9  isd_ic_mou_6  isd_ic_mou_7  \\\n",
       "count   96140.000000  94621.000000  92254.000000  96062.000000  96140.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.033585      0.040361      0.163137      7.460608      8.334936   \n",
       "std         0.155725      0.146147      0.527860     59.722948     65.219829   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.060000      0.000000      0.000000   \n",
       "max        21.330000     16.860000     62.380000   6789.410000   5289.540000   \n",
       "\n",
       "        isd_ic_mou_8  isd_ic_mou_9   ic_others_6   ic_others_7   ic_others_8  \\\n",
       "count   94621.000000  92254.000000  96062.000000  96140.000000  94621.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        8.442001      8.063003      0.854656      1.012960      0.970800   \n",
       "std        63.813098     63.505379     11.955164     12.673099     13.284348   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      4127.010000   5057.740000   1362.940000   1495.940000   2327.510000   \n",
       "\n",
       "         ic_others_9  total_rech_num_6  total_rech_num_7  total_rech_num_8  \\\n",
       "count   92254.000000      99999.000000      99999.000000      99999.000000   \n",
       "unique           NaN               NaN               NaN               NaN   \n",
       "top              NaN               NaN               NaN               NaN   \n",
       "freq             NaN               NaN               NaN               NaN   \n",
       "mean        1.017162          7.558806          7.700367          7.212912   \n",
       "std        12.381172          7.078405          7.070422          7.203753   \n",
       "min         0.000000          0.000000          0.000000          0.000000   \n",
       "25%         0.000000          3.000000          3.000000          3.000000   \n",
       "50%         0.000000          6.000000          6.000000          5.000000   \n",
       "75%         0.000000          9.000000         10.000000          9.000000   \n",
       "max      1005.230000        307.000000        138.000000        196.000000   \n",
       "\n",
       "        total_rech_num_9  total_rech_amt_6  total_rech_amt_7  \\\n",
       "count       99999.000000      99999.000000      99999.000000   \n",
       "unique               NaN               NaN               NaN   \n",
       "top                  NaN               NaN               NaN   \n",
       "freq                 NaN               NaN               NaN   \n",
       "mean            6.893019        327.514615        322.962970   \n",
       "std             7.096261        398.019701        408.114237   \n",
       "min             0.000000          0.000000          0.000000   \n",
       "25%             3.000000        109.000000        100.000000   \n",
       "50%             5.000000        230.000000        220.000000   \n",
       "75%             9.000000        437.500000        428.000000   \n",
       "max           131.000000      35190.000000      40335.000000   \n",
       "\n",
       "        total_rech_amt_8  total_rech_amt_9  max_rech_amt_6  max_rech_amt_7  \\\n",
       "count       99999.000000      99999.000000    99999.000000    99999.000000   \n",
       "unique               NaN               NaN             NaN             NaN   \n",
       "top                  NaN               NaN             NaN             NaN   \n",
       "freq                 NaN               NaN             NaN             NaN   \n",
       "mean          324.157122        303.345673      104.637486      104.752398   \n",
       "std           416.540455        404.588583      120.614894      124.523970   \n",
       "min             0.000000          0.000000        0.000000        0.000000   \n",
       "25%            90.000000         52.000000       30.000000       30.000000   \n",
       "50%           225.000000        200.000000      110.000000      110.000000   \n",
       "75%           434.500000        415.000000      120.000000      128.000000   \n",
       "max         45320.000000      37235.000000     4010.000000     4010.000000   \n",
       "\n",
       "        max_rech_amt_8  max_rech_amt_9 date_of_last_rech_6  \\\n",
       "count     99999.000000    99999.000000               98392   \n",
       "unique             NaN             NaN                  30   \n",
       "top                NaN             NaN           6/30/2014   \n",
       "freq               NaN             NaN               16960   \n",
       "mean        107.728207      101.943889                 NaN   \n",
       "std         126.902505      125.375109                 NaN   \n",
       "min           0.000000        0.000000                 NaN   \n",
       "25%          30.000000       28.000000                 NaN   \n",
       "50%          98.000000       61.000000                 NaN   \n",
       "75%         144.000000      144.000000                 NaN   \n",
       "max        4449.000000     3399.000000                 NaN   \n",
       "\n",
       "       date_of_last_rech_7 date_of_last_rech_8 date_of_last_rech_9  \\\n",
       "count                98232               96377               95239   \n",
       "unique                  31                  31                  30   \n",
       "top              7/31/2014           8/31/2014           9/29/2014   \n",
       "freq                 17288               14706               22623   \n",
       "mean                   NaN                 NaN                 NaN   \n",
       "std                    NaN                 NaN                 NaN   \n",
       "min                    NaN                 NaN                 NaN   \n",
       "25%                    NaN                 NaN                 NaN   \n",
       "50%                    NaN                 NaN                 NaN   \n",
       "75%                    NaN                 NaN                 NaN   \n",
       "max                    NaN                 NaN                 NaN   \n",
       "\n",
       "        last_day_rch_amt_6  last_day_rch_amt_7  last_day_rch_amt_8  \\\n",
       "count         99999.000000        99999.000000        99999.000000   \n",
       "unique                 NaN                 NaN                 NaN   \n",
       "top                    NaN                 NaN                 NaN   \n",
       "freq                   NaN                 NaN                 NaN   \n",
       "mean             63.156252           59.385804           62.641716   \n",
       "std              97.356649           95.915385          104.431816   \n",
       "min               0.000000            0.000000            0.000000   \n",
       "25%               0.000000            0.000000            0.000000   \n",
       "50%              30.000000           30.000000           30.000000   \n",
       "75%             110.000000          110.000000          130.000000   \n",
       "max            4010.000000         4010.000000         4449.000000   \n",
       "\n",
       "        last_day_rch_amt_9 date_of_last_rech_data_6 date_of_last_rech_data_7  \\\n",
       "count         99999.000000                    25153                    25571   \n",
       "unique                 NaN                       30                       31   \n",
       "top                    NaN                6/30/2014                7/31/2014   \n",
       "freq                   NaN                     1888                     1813   \n",
       "mean             43.901249                      NaN                      NaN   \n",
       "std              90.809712                      NaN                      NaN   \n",
       "min               0.000000                      NaN                      NaN   \n",
       "25%               0.000000                      NaN                      NaN   \n",
       "50%               0.000000                      NaN                      NaN   \n",
       "75%              50.000000                      NaN                      NaN   \n",
       "max            3399.000000                      NaN                      NaN   \n",
       "\n",
       "       date_of_last_rech_data_8 date_of_last_rech_data_9  total_rech_data_6  \\\n",
       "count                     26339                    25922       25153.000000   \n",
       "unique                       31                       30                NaN   \n",
       "top                   8/31/2014                9/29/2014                NaN   \n",
       "freq                       1998                     2329                NaN   \n",
       "mean                        NaN                      NaN           2.463802   \n",
       "std                         NaN                      NaN           2.789128   \n",
       "min                         NaN                      NaN           1.000000   \n",
       "25%                         NaN                      NaN           1.000000   \n",
       "50%                         NaN                      NaN           1.000000   \n",
       "75%                         NaN                      NaN           3.000000   \n",
       "max                         NaN                      NaN          61.000000   \n",
       "\n",
       "        total_rech_data_7  total_rech_data_8  total_rech_data_9  \\\n",
       "count        25571.000000       26339.000000       25922.000000   \n",
       "unique                NaN                NaN                NaN   \n",
       "top                   NaN                NaN                NaN   \n",
       "freq                  NaN                NaN                NaN   \n",
       "mean             2.666419           2.651999           2.441170   \n",
       "std              3.031593           3.074987           2.516339   \n",
       "min              1.000000           1.000000           1.000000   \n",
       "25%              1.000000           1.000000           1.000000   \n",
       "50%              1.000000           1.000000           2.000000   \n",
       "75%              3.000000           3.000000           3.000000   \n",
       "max             54.000000          60.000000          84.000000   \n",
       "\n",
       "        max_rech_data_6  max_rech_data_7  max_rech_data_8  max_rech_data_9  \\\n",
       "count      25153.000000     25571.000000     26339.000000      25922.00000   \n",
       "unique              NaN              NaN              NaN              NaN   \n",
       "top                 NaN              NaN              NaN              NaN   \n",
       "freq                NaN              NaN              NaN              NaN   \n",
       "mean         126.393392       126.729459       125.717301        124.94144   \n",
       "std          108.477235       109.765267       109.437851        111.36376   \n",
       "min            1.000000         1.000000         1.000000          1.00000   \n",
       "25%           25.000000        25.000000        25.000000         25.00000   \n",
       "50%          145.000000       145.000000       145.000000        145.00000   \n",
       "75%          177.000000       177.000000       179.000000        179.00000   \n",
       "max         1555.000000      1555.000000      1555.000000       1555.00000   \n",
       "\n",
       "        count_rech_2g_6  count_rech_2g_7  count_rech_2g_8  count_rech_2g_9  \\\n",
       "count      25153.000000     25571.000000     26339.000000     25922.000000   \n",
       "unique              NaN              NaN              NaN              NaN   \n",
       "top                 NaN              NaN              NaN              NaN   \n",
       "freq                NaN              NaN              NaN              NaN   \n",
       "mean           1.864668         2.044699         2.016288         1.781807   \n",
       "std            2.570254         2.768332         2.720132         2.214701   \n",
       "min            0.000000         0.000000         0.000000         0.000000   \n",
       "25%            1.000000         1.000000         1.000000         1.000000   \n",
       "50%            1.000000         1.000000         1.000000         1.000000   \n",
       "75%            2.000000         2.000000         2.000000         2.000000   \n",
       "max           42.000000        48.000000        44.000000        40.000000   \n",
       "\n",
       "        count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  count_rech_3g_9  \\\n",
       "count      25153.000000     25571.000000     26339.000000     25922.000000   \n",
       "unique              NaN              NaN              NaN              NaN   \n",
       "top                 NaN              NaN              NaN              NaN   \n",
       "freq                NaN              NaN              NaN              NaN   \n",
       "mean           0.599133         0.621720         0.635711         0.659363   \n",
       "std            1.274428         1.394524         1.422827         1.411513   \n",
       "min            0.000000         0.000000         0.000000         0.000000   \n",
       "25%            0.000000         0.000000         0.000000         0.000000   \n",
       "50%            0.000000         0.000000         0.000000         0.000000   \n",
       "75%            1.000000         1.000000         1.000000         1.000000   \n",
       "max           29.000000        35.000000        45.000000        49.000000   \n",
       "\n",
       "        av_rech_amt_data_6  av_rech_amt_data_7  av_rech_amt_data_8  \\\n",
       "count         25153.000000        25571.000000        26339.000000   \n",
       "unique                 NaN                 NaN                 NaN   \n",
       "top                    NaN                 NaN                 NaN   \n",
       "freq                   NaN                 NaN                 NaN   \n",
       "mean            192.600982          200.981292          197.526489   \n",
       "std             192.646318          196.791224          191.301305   \n",
       "min               1.000000            0.500000            0.500000   \n",
       "25%              82.000000           92.000000           87.000000   \n",
       "50%             154.000000          154.000000          154.000000   \n",
       "75%             252.000000          252.000000          252.000000   \n",
       "max            7546.000000         4365.000000         4076.000000   \n",
       "\n",
       "        av_rech_amt_data_9   vol_2g_mb_6   vol_2g_mb_7   vol_2g_mb_8  \\\n",
       "count         25922.000000  99999.000000  99999.000000  99999.000000   \n",
       "unique                 NaN           NaN           NaN           NaN   \n",
       "top                    NaN           NaN           NaN           NaN   \n",
       "freq                   NaN           NaN           NaN           NaN   \n",
       "mean            192.734315     51.904956     51.229937     50.170154   \n",
       "std             188.400286    213.356445    212.302217    212.347892   \n",
       "min               1.000000      0.000000      0.000000      0.000000   \n",
       "25%              69.000000      0.000000      0.000000      0.000000   \n",
       "50%             164.000000      0.000000      0.000000      0.000000   \n",
       "75%             252.000000      0.000000      0.000000      0.000000   \n",
       "max            4061.000000  10285.900000   7873.550000  11117.610000   \n",
       "\n",
       "         vol_2g_mb_9   vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8   vol_3g_mb_9  \\\n",
       "count   99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean       44.719701    121.396219    128.995847    135.410689    136.056613   \n",
       "std       198.653570    544.247227    541.494013    558.775335    577.394194   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      8993.950000  45735.400000  28144.120000  30036.060000  39221.270000   \n",
       "\n",
       "           arpu_3g_6     arpu_3g_7     arpu_3g_8     arpu_3g_9     arpu_2g_6  \\\n",
       "count   25153.000000  25571.000000  26339.000000  25922.000000  25153.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean       89.555057     89.384120     91.173849    100.264116     86.398003   \n",
       "std       193.124653    195.893924    188.180936    216.291992    172.767523   \n",
       "min       -30.820000    -26.040000    -24.490000    -71.090000    -35.830000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.480000      0.420000      0.880000      2.605000     10.830000   \n",
       "75%       122.070000    119.560000    122.070000    140.010000    122.070000   \n",
       "max      6362.280000   4980.900000   3716.900000  13884.310000   6433.760000   \n",
       "\n",
       "           arpu_2g_7     arpu_2g_8     arpu_2g_9  night_pck_user_6  \\\n",
       "count   25571.000000  26339.000000  25922.000000      25153.000000   \n",
       "unique           NaN           NaN           NaN               NaN   \n",
       "top              NaN           NaN           NaN               NaN   \n",
       "freq             NaN           NaN           NaN               NaN   \n",
       "mean       85.914450     86.599478     93.712026          0.025086   \n",
       "std       176.379871    168.247852    171.384224          0.156391   \n",
       "min       -15.480000    -55.830000    -45.740000          0.000000   \n",
       "25%         0.000000      0.000000      0.000000          0.000000   \n",
       "50%         8.810000      9.270000     14.800000          0.000000   \n",
       "75%       122.070000    122.070000    140.010000          0.000000   \n",
       "max      4809.360000   3483.170000   3467.170000          1.000000   \n",
       "\n",
       "        night_pck_user_7  night_pck_user_8  night_pck_user_9  monthly_2g_6  \\\n",
       "count       25571.000000      26339.000000      25922.000000  99999.000000   \n",
       "unique               NaN               NaN               NaN           NaN   \n",
       "top                  NaN               NaN               NaN           NaN   \n",
       "freq                 NaN               NaN               NaN           NaN   \n",
       "mean            0.023034          0.020844          0.015971      0.079641   \n",
       "std             0.150014          0.142863          0.125366      0.295058   \n",
       "min             0.000000          0.000000          0.000000      0.000000   \n",
       "25%             0.000000          0.000000          0.000000      0.000000   \n",
       "50%             0.000000          0.000000          0.000000      0.000000   \n",
       "75%             0.000000          0.000000          0.000000      0.000000   \n",
       "max             1.000000          1.000000          1.000000      4.000000   \n",
       "\n",
       "        monthly_2g_7  monthly_2g_8  monthly_2g_9   sachet_2g_6   sachet_2g_7  \\\n",
       "count   99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.083221      0.081001      0.068781      0.389384      0.439634   \n",
       "std         0.304395      0.299568      0.278120      1.497320      1.636230   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max         5.000000      5.000000      4.000000     42.000000     48.000000   \n",
       "\n",
       "         sachet_2g_8   sachet_2g_9  monthly_3g_6  monthly_3g_7  monthly_3g_8  \\\n",
       "count   99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.450075      0.393104      0.075921      0.078581      0.082941   \n",
       "std         1.630263      1.347140      0.363371      0.387231      0.384947   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        44.000000     40.000000     14.000000     16.000000     16.000000   \n",
       "\n",
       "        monthly_3g_9   sachet_3g_6   sachet_3g_7   sachet_3g_8   sachet_3g_9  \\\n",
       "count   99999.000000  99999.000000  99999.000000  99999.000000  99999.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.086341      0.074781      0.080401      0.084501      0.084581   \n",
       "std         0.384978      0.568344      0.628334      0.660234      0.650457   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        11.000000     29.000000     35.000000     41.000000     49.000000   \n",
       "\n",
       "           fb_user_6     fb_user_7     fb_user_8     fb_user_9           aon  \\\n",
       "count   25153.000000  25571.000000  26339.000000  25922.000000  99999.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.914404      0.908764      0.890808      0.860968   1219.854749   \n",
       "std         0.279772      0.287950      0.311885      0.345987    954.733842   \n",
       "min         0.000000      0.000000      0.000000      0.000000    180.000000   \n",
       "25%         1.000000      1.000000      1.000000      1.000000    467.000000   \n",
       "50%         1.000000      1.000000      1.000000      1.000000    863.000000   \n",
       "75%         1.000000      1.000000      1.000000      1.000000   1807.500000   \n",
       "max         1.000000      1.000000      1.000000      1.000000   4337.000000   \n",
       "\n",
       "          aug_vbc_3g    jul_vbc_3g    jun_vbc_3g    sep_vbc_3g  \n",
       "count   99999.000000  99999.000000  99999.000000  99999.000000  \n",
       "unique           NaN           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN           NaN  \n",
       "mean       68.170248     66.839062     60.021204      3.299373  \n",
       "std       267.580450    271.201856    253.938223     32.408353  \n",
       "min         0.000000      0.000000      0.000000      0.000000  \n",
       "25%         0.000000      0.000000      0.000000      0.000000  \n",
       "50%         0.000000      0.000000      0.000000      0.000000  \n",
       "75%         0.000000      0.000000      0.000000      0.000000  \n",
       "max     12916.220000   9165.600000  11166.210000   2618.570000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis of data statistics\n",
    "churn.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJS5FIcHhNjF"
   },
   "source": [
    "Create a copy of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Oj9hGK-5d81d"
   },
   "outputs": [],
   "source": [
    "# create backup of data\n",
    "original = churn.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC6k71PhSlQ"
   },
   "source": [
    "Analyze the different types of features present in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PuQOZzFSd81d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ID cols: 1\n",
      "#Date cols:12\n",
      "#Numeric cols:204\n",
      "#Category cols:8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# create column name list by types of columns\n",
    "id_cols = ['circle_id']\n",
    "\n",
    "date_cols = ['last_date_of_month_6',\n",
    "             'last_date_of_month_7',\n",
    "             'last_date_of_month_8',\n",
    "             'last_date_of_month_9',\n",
    "             'date_of_last_rech_6',\n",
    "             'date_of_last_rech_7',\n",
    "             'date_of_last_rech_8',\n",
    "             'date_of_last_rech_9',\n",
    "             'date_of_last_rech_data_6',\n",
    "             'date_of_last_rech_data_7',\n",
    "             'date_of_last_rech_data_8',\n",
    "             'date_of_last_rech_data_9'\n",
    "            ]\n",
    "\n",
    "cat_cols =  ['night_pck_user_6',\n",
    "             'night_pck_user_7',\n",
    "             'night_pck_user_8',\n",
    "             'night_pck_user_9',\n",
    "             'fb_user_6',\n",
    "             'fb_user_7',\n",
    "             'fb_user_8',\n",
    "             'fb_user_9'\n",
    "            ]\n",
    "\n",
    "num_cols = [column for column in churn.columns if column not in id_cols + date_cols + cat_cols]\n",
    "\n",
    "# print the number of columns in each list\n",
    "print(\"#ID cols: %d\\n#Date cols:%d\\n#Numeric cols:%d\\n#Category cols:%d\" % (len(id_cols), len(date_cols), len(num_cols), len(cat_cols)))\n",
    "\n",
    "# check if we have missed any column or not\n",
    "print(len(id_cols) + len(date_cols) + len(num_cols) + len(cat_cols) == churn.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7Ynfkq9d81e"
   },
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "142-o0JAfEje"
   },
   "source": [
    "### Details on Missing Values\n",
    "\n",
    "There are several types of features present in this data set. Some of the information that you have to look for missing value treatment is given below:\n",
    "\n",
    "\n",
    "*   If there are missing values in the columns corresponding to 'Recharging of the service' variables, this is because the customer did not recharge that month.\n",
    "\n",
    "\n",
    "*   If the columns corresponding to 'Call and Internet service' variables that have more than 70% of missing values, you can drop those variables from the data set. If not, then you can use the MICE technique to impute the values in those missing entries.\n",
    "\n",
    "\n",
    "*   If there are missing values in the categorical variables, this means that there is another scheme that the customer has availed from the telecomminucation service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWULF6to6HVt"
   },
   "source": [
    "Find the ratio of missing values in each column in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UfdahxQ2d81f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_3g_6                   74.846748\n",
       "av_rech_amt_data_6          74.846748\n",
       "fb_user_6                   74.846748\n",
       "night_pck_user_6            74.846748\n",
       "total_rech_data_6           74.846748\n",
       "max_rech_data_6             74.846748\n",
       "count_rech_2g_6             74.846748\n",
       "count_rech_3g_6             74.846748\n",
       "date_of_last_rech_data_6    74.846748\n",
       "arpu_2g_6                   74.846748\n",
       "av_rech_amt_data_7          74.428744\n",
       "date_of_last_rech_data_7    74.428744\n",
       "max_rech_data_7             74.428744\n",
       "total_rech_data_7           74.428744\n",
       "arpu_3g_7                   74.428744\n",
       "fb_user_7                   74.428744\n",
       "count_rech_3g_7             74.428744\n",
       "arpu_2g_7                   74.428744\n",
       "night_pck_user_7            74.428744\n",
       "count_rech_2g_7             74.428744\n",
       "arpu_3g_9                   74.077741\n",
       "max_rech_data_9             74.077741\n",
       "date_of_last_rech_data_9    74.077741\n",
       "total_rech_data_9           74.077741\n",
       "arpu_2g_9                   74.077741\n",
       "count_rech_2g_9             74.077741\n",
       "night_pck_user_9            74.077741\n",
       "count_rech_3g_9             74.077741\n",
       "av_rech_amt_data_9          74.077741\n",
       "fb_user_9                   74.077741\n",
       "date_of_last_rech_data_8    73.660737\n",
       "night_pck_user_8            73.660737\n",
       "fb_user_8                   73.660737\n",
       "total_rech_data_8           73.660737\n",
       "av_rech_amt_data_8          73.660737\n",
       "arpu_3g_8                   73.660737\n",
       "count_rech_3g_8             73.660737\n",
       "arpu_2g_8                   73.660737\n",
       "max_rech_data_8             73.660737\n",
       "count_rech_2g_8             73.660737\n",
       "loc_og_t2m_mou_9             7.745077\n",
       "ic_others_9                  7.745077\n",
       "std_og_mou_9                 7.745077\n",
       "isd_og_mou_9                 7.745077\n",
       "isd_ic_mou_9                 7.745077\n",
       "spl_og_mou_9                 7.745077\n",
       "spl_ic_mou_9                 7.745077\n",
       "og_others_9                  7.745077\n",
       "onnet_mou_9                  7.745077\n",
       "offnet_mou_9                 7.745077\n",
       "std_ic_mou_9                 7.745077\n",
       "loc_ic_t2t_mou_9             7.745077\n",
       "loc_ic_t2m_mou_9             7.745077\n",
       "std_ic_t2o_mou_9             7.745077\n",
       "loc_ic_t2f_mou_9             7.745077\n",
       "std_ic_t2f_mou_9             7.745077\n",
       "loc_ic_mou_9                 7.745077\n",
       "std_ic_t2m_mou_9             7.745077\n",
       "std_og_t2c_mou_9             7.745077\n",
       "std_ic_t2t_mou_9             7.745077\n",
       "std_og_t2f_mou_9             7.745077\n",
       "std_og_t2m_mou_9             7.745077\n",
       "roam_og_mou_9                7.745077\n",
       "std_og_t2t_mou_9             7.745077\n",
       "loc_og_t2c_mou_9             7.745077\n",
       "roam_ic_mou_9                7.745077\n",
       "loc_og_t2t_mou_9             7.745077\n",
       "loc_og_mou_9                 7.745077\n",
       "loc_og_t2f_mou_9             7.745077\n",
       "std_ic_t2f_mou_8             5.378054\n",
       "loc_og_t2c_mou_8             5.378054\n",
       "loc_ic_t2f_mou_8             5.378054\n",
       "spl_ic_mou_8                 5.378054\n",
       "loc_ic_mou_8                 5.378054\n",
       "loc_og_t2t_mou_8             5.378054\n",
       "loc_ic_t2m_mou_8             5.378054\n",
       "std_ic_mou_8                 5.378054\n",
       "loc_og_t2f_mou_8             5.378054\n",
       "std_ic_t2t_mou_8             5.378054\n",
       "loc_ic_t2t_mou_8             5.378054\n",
       "loc_og_mou_8                 5.378054\n",
       "std_ic_t2o_mou_8             5.378054\n",
       "onnet_mou_8                  5.378054\n",
       "std_og_t2m_mou_8             5.378054\n",
       "isd_ic_mou_8                 5.378054\n",
       "std_og_t2c_mou_8             5.378054\n",
       "std_og_t2f_mou_8             5.378054\n",
       "offnet_mou_8                 5.378054\n",
       "roam_ic_mou_8                5.378054\n",
       "std_og_mou_8                 5.378054\n",
       "ic_others_8                  5.378054\n",
       "loc_og_t2m_mou_8             5.378054\n",
       "isd_og_mou_8                 5.378054\n",
       "spl_og_mou_8                 5.378054\n",
       "std_ic_t2m_mou_8             5.378054\n",
       "og_others_8                  5.378054\n",
       "std_og_t2t_mou_8             5.378054\n",
       "roam_og_mou_8                5.378054\n",
       "date_of_last_rech_9          4.760048\n",
       "spl_ic_mou_6                 3.937039\n",
       "ic_others_6                  3.937039\n",
       "std_ic_mou_6                 3.937039\n",
       "isd_ic_mou_6                 3.937039\n",
       "std_ic_t2f_mou_6             3.937039\n",
       "std_ic_t2o_mou_6             3.937039\n",
       "loc_og_t2f_mou_6             3.937039\n",
       "loc_og_t2t_mou_6             3.937039\n",
       "std_og_t2c_mou_6             3.937039\n",
       "std_og_t2f_mou_6             3.937039\n",
       "std_og_t2m_mou_6             3.937039\n",
       "isd_og_mou_6                 3.937039\n",
       "std_og_t2t_mou_6             3.937039\n",
       "spl_og_mou_6                 3.937039\n",
       "loc_og_mou_6                 3.937039\n",
       "og_others_6                  3.937039\n",
       "loc_og_t2c_mou_6             3.937039\n",
       "loc_ic_t2t_mou_6             3.937039\n",
       "std_ic_t2m_mou_6             3.937039\n",
       "loc_og_t2m_mou_6             3.937039\n",
       "std_og_mou_6                 3.937039\n",
       "offnet_mou_6                 3.937039\n",
       "onnet_mou_6                  3.937039\n",
       "roam_og_mou_6                3.937039\n",
       "loc_ic_t2f_mou_6             3.937039\n",
       "std_ic_t2t_mou_6             3.937039\n",
       "roam_ic_mou_6                3.937039\n",
       "loc_ic_t2m_mou_6             3.937039\n",
       "loc_ic_mou_6                 3.937039\n",
       "loc_og_t2t_mou_7             3.859039\n",
       "std_og_t2c_mou_7             3.859039\n",
       "std_og_t2f_mou_7             3.859039\n",
       "std_og_t2m_mou_7             3.859039\n",
       "onnet_mou_7                  3.859039\n",
       "offnet_mou_7                 3.859039\n",
       "std_og_t2t_mou_7             3.859039\n",
       "loc_og_mou_7                 3.859039\n",
       "roam_ic_mou_7                3.859039\n",
       "loc_og_t2c_mou_7             3.859039\n",
       "loc_og_t2f_mou_7             3.859039\n",
       "roam_og_mou_7                3.859039\n",
       "loc_og_t2m_mou_7             3.859039\n",
       "std_ic_t2m_mou_7             3.859039\n",
       "loc_ic_t2f_mou_7             3.859039\n",
       "ic_others_7                  3.859039\n",
       "std_og_mou_7                 3.859039\n",
       "std_ic_mou_7                 3.859039\n",
       "loc_ic_t2t_mou_7             3.859039\n",
       "loc_ic_mou_7                 3.859039\n",
       "std_ic_t2f_mou_7             3.859039\n",
       "std_ic_t2t_mou_7             3.859039\n",
       "spl_ic_mou_7                 3.859039\n",
       "og_others_7                  3.859039\n",
       "isd_ic_mou_7                 3.859039\n",
       "spl_og_mou_7                 3.859039\n",
       "isd_og_mou_7                 3.859039\n",
       "std_ic_t2o_mou_7             3.859039\n",
       "loc_ic_t2m_mou_7             3.859039\n",
       "date_of_last_rech_8          3.622036\n",
       "date_of_last_rech_7          1.767018\n",
       "last_date_of_month_9         1.659017\n",
       "date_of_last_rech_6          1.607016\n",
       "last_date_of_month_8         1.100011\n",
       "loc_og_t2o_mou               1.018010\n",
       "loc_ic_t2o_mou               1.018010\n",
       "std_og_t2o_mou               1.018010\n",
       "last_date_of_month_7         0.601006\n",
       "aug_vbc_3g                   0.000000\n",
       "jul_vbc_3g                   0.000000\n",
       "aon                          0.000000\n",
       "jun_vbc_3g                   0.000000\n",
       "monthly_2g_9                 0.000000\n",
       "sachet_3g_6                  0.000000\n",
       "vol_3g_mb_9                  0.000000\n",
       "sachet_3g_8                  0.000000\n",
       "sachet_3g_7                  0.000000\n",
       "monthly_2g_8                 0.000000\n",
       "monthly_3g_9                 0.000000\n",
       "sachet_3g_9                  0.000000\n",
       "monthly_3g_8                 0.000000\n",
       "monthly_3g_7                 0.000000\n",
       "monthly_3g_6                 0.000000\n",
       "sachet_2g_9                  0.000000\n",
       "sachet_2g_8                  0.000000\n",
       "sachet_2g_7                  0.000000\n",
       "sachet_2g_6                  0.000000\n",
       "monthly_2g_7                 0.000000\n",
       "monthly_2g_6                 0.000000\n",
       "circle_id                    0.000000\n",
       "vol_3g_mb_8                  0.000000\n",
       "total_rech_num_9             0.000000\n",
       "total_rech_num_7             0.000000\n",
       "total_rech_num_6             0.000000\n",
       "total_ic_mou_9               0.000000\n",
       "total_ic_mou_8               0.000000\n",
       "total_ic_mou_7               0.000000\n",
       "total_ic_mou_6               0.000000\n",
       "total_og_mou_9               0.000000\n",
       "total_og_mou_8               0.000000\n",
       "total_og_mou_7               0.000000\n",
       "total_og_mou_6               0.000000\n",
       "arpu_9                       0.000000\n",
       "arpu_8                       0.000000\n",
       "arpu_7                       0.000000\n",
       "arpu_6                       0.000000\n",
       "last_date_of_month_6         0.000000\n",
       "total_rech_num_8             0.000000\n",
       "total_rech_amt_6             0.000000\n",
       "vol_3g_mb_7                  0.000000\n",
       "total_rech_amt_7             0.000000\n",
       "vol_3g_mb_6                  0.000000\n",
       "vol_2g_mb_9                  0.000000\n",
       "vol_2g_mb_8                  0.000000\n",
       "vol_2g_mb_7                  0.000000\n",
       "vol_2g_mb_6                  0.000000\n",
       "last_day_rch_amt_9           0.000000\n",
       "last_day_rch_amt_8           0.000000\n",
       "last_day_rch_amt_7           0.000000\n",
       "last_day_rch_amt_6           0.000000\n",
       "max_rech_amt_9               0.000000\n",
       "max_rech_amt_8               0.000000\n",
       "max_rech_amt_7               0.000000\n",
       "max_rech_amt_6               0.000000\n",
       "total_rech_amt_9             0.000000\n",
       "total_rech_amt_8             0.000000\n",
       "sep_vbc_3g                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at missing value ratio in each column\n",
    "missing_ratio = (churn.isnull().sum()*100/churn.shape[0]).sort_values(ascending=False)\n",
    "missing_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 70% missing values: 40\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with more than 70% missing values\n",
    "cols_to_drop = missing_ratio[missing_ratio > 70].index.tolist()\n",
    "print(f\"Columns with more than 70% missing values: {len(cols_to_drop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5uV8nfD6Ryj"
   },
   "source": [
    "**Checkpoint:** You must have observed that there are 40 features with more than 70% of the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faEE1-CDd81f"
   },
   "source": [
    "### i) Impute missing values with zeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFZzljnHG76W"
   },
   "source": [
    "Now that we have the information about the amount of missing values in each column, we can go ahead and perform some imputing and deleting.\n",
    "\n",
    "First, we will start with the columns corresponding to the \"recharging of the service\" information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kM6FEVJSd81f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>total_rech_data_9</th>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <th>count_rech_2g_9</th>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <th>count_rech_3g_8</th>\n",
       "      <th>count_rech_3g_9</th>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <th>max_rech_data_9</th>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <th>av_rech_amt_data_8</th>\n",
       "      <th>av_rech_amt_data_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.00000</td>\n",
       "      <td>25153.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "      <td>26339.000000</td>\n",
       "      <td>25922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.463802</td>\n",
       "      <td>2.666419</td>\n",
       "      <td>2.651999</td>\n",
       "      <td>2.441170</td>\n",
       "      <td>1.864668</td>\n",
       "      <td>2.044699</td>\n",
       "      <td>2.016288</td>\n",
       "      <td>1.781807</td>\n",
       "      <td>0.599133</td>\n",
       "      <td>0.621720</td>\n",
       "      <td>0.635711</td>\n",
       "      <td>0.659363</td>\n",
       "      <td>126.393392</td>\n",
       "      <td>126.729459</td>\n",
       "      <td>125.717301</td>\n",
       "      <td>124.94144</td>\n",
       "      <td>192.600982</td>\n",
       "      <td>200.981292</td>\n",
       "      <td>197.526489</td>\n",
       "      <td>192.734315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.789128</td>\n",
       "      <td>3.031593</td>\n",
       "      <td>3.074987</td>\n",
       "      <td>2.516339</td>\n",
       "      <td>2.570254</td>\n",
       "      <td>2.768332</td>\n",
       "      <td>2.720132</td>\n",
       "      <td>2.214701</td>\n",
       "      <td>1.274428</td>\n",
       "      <td>1.394524</td>\n",
       "      <td>1.422827</td>\n",
       "      <td>1.411513</td>\n",
       "      <td>108.477235</td>\n",
       "      <td>109.765267</td>\n",
       "      <td>109.437851</td>\n",
       "      <td>111.36376</td>\n",
       "      <td>192.646318</td>\n",
       "      <td>196.791224</td>\n",
       "      <td>191.301305</td>\n",
       "      <td>188.400286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.00000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.00000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.00000</td>\n",
       "      <td>7546.000000</td>\n",
       "      <td>4365.000000</td>\n",
       "      <td>4076.000000</td>\n",
       "      <td>4061.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_rech_data_6  total_rech_data_7  total_rech_data_8  \\\n",
       "count       25153.000000       25571.000000       26339.000000   \n",
       "mean            2.463802           2.666419           2.651999   \n",
       "std             2.789128           3.031593           3.074987   \n",
       "min             1.000000           1.000000           1.000000   \n",
       "25%             1.000000           1.000000           1.000000   \n",
       "50%             1.000000           1.000000           1.000000   \n",
       "75%             3.000000           3.000000           3.000000   \n",
       "max            61.000000          54.000000          60.000000   \n",
       "\n",
       "       total_rech_data_9  count_rech_2g_6  count_rech_2g_7  count_rech_2g_8  \\\n",
       "count       25922.000000     25153.000000     25571.000000     26339.000000   \n",
       "mean            2.441170         1.864668         2.044699         2.016288   \n",
       "std             2.516339         2.570254         2.768332         2.720132   \n",
       "min             1.000000         0.000000         0.000000         0.000000   \n",
       "25%             1.000000         1.000000         1.000000         1.000000   \n",
       "50%             2.000000         1.000000         1.000000         1.000000   \n",
       "75%             3.000000         2.000000         2.000000         2.000000   \n",
       "max            84.000000        42.000000        48.000000        44.000000   \n",
       "\n",
       "       count_rech_2g_9  count_rech_3g_6  count_rech_3g_7  count_rech_3g_8  \\\n",
       "count     25922.000000     25153.000000     25571.000000     26339.000000   \n",
       "mean          1.781807         0.599133         0.621720         0.635711   \n",
       "std           2.214701         1.274428         1.394524         1.422827   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           1.000000         0.000000         0.000000         0.000000   \n",
       "50%           1.000000         0.000000         0.000000         0.000000   \n",
       "75%           2.000000         1.000000         1.000000         1.000000   \n",
       "max          40.000000        29.000000        35.000000        45.000000   \n",
       "\n",
       "       count_rech_3g_9  max_rech_data_6  max_rech_data_7  max_rech_data_8  \\\n",
       "count     25922.000000     25153.000000     25571.000000     26339.000000   \n",
       "mean          0.659363       126.393392       126.729459       125.717301   \n",
       "std           1.411513       108.477235       109.765267       109.437851   \n",
       "min           0.000000         1.000000         1.000000         1.000000   \n",
       "25%           0.000000        25.000000        25.000000        25.000000   \n",
       "50%           0.000000       145.000000       145.000000       145.000000   \n",
       "75%           1.000000       177.000000       177.000000       179.000000   \n",
       "max          49.000000      1555.000000      1555.000000      1555.000000   \n",
       "\n",
       "       max_rech_data_9  av_rech_amt_data_6  av_rech_amt_data_7  \\\n",
       "count      25922.00000        25153.000000        25571.000000   \n",
       "mean         124.94144          192.600982          200.981292   \n",
       "std          111.36376          192.646318          196.791224   \n",
       "min            1.00000            1.000000            0.500000   \n",
       "25%           25.00000           82.000000           92.000000   \n",
       "50%          145.00000          154.000000          154.000000   \n",
       "75%          179.00000          252.000000          252.000000   \n",
       "max         1555.00000         7546.000000         4365.000000   \n",
       "\n",
       "       av_rech_amt_data_8  av_rech_amt_data_9  \n",
       "count        26339.000000        25922.000000  \n",
       "mean           197.526489          192.734315  \n",
       "std            191.301305          188.400286  \n",
       "min              0.500000            1.000000  \n",
       "25%             87.000000           69.000000  \n",
       "50%            154.000000          164.000000  \n",
       "75%            252.000000          252.000000  \n",
       "max           4076.000000         4061.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary statistics for the recharge columns\n",
    "recharge_cols = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "                 'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_2g_9',\n",
    "                 'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9',\n",
    "                 'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9',\n",
    "                 'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "                 ]\n",
    "\n",
    "churn[recharge_cols].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkNZDY_C7sRE"
   },
   "source": [
    "Observe whether the date of the last recharge and the total recharge data value are missing together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XycmOJEMd81g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_rech_data_6 date_of_last_rech_data_6\n",
       "1                 NaN                      NaN\n",
       "2                 NaN                      NaN\n",
       "3                 NaN                      NaN\n",
       "5                 NaN                      NaN\n",
       "6                 NaN                      NaN\n",
       "7                 NaN                      NaN\n",
       "8                 NaN                      NaN\n",
       "9                 NaN                      NaN\n",
       "10                NaN                      NaN\n",
       "11                NaN                      NaN\n",
       "12                NaN                      NaN\n",
       "13                NaN                      NaN\n",
       "14                NaN                      NaN\n",
       "15                NaN                      NaN\n",
       "16                NaN                      NaN\n",
       "17                NaN                      NaN\n",
       "18                NaN                      NaN\n",
       "20                NaN                      NaN\n",
       "21                NaN                      NaN\n",
       "22                NaN                      NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can do this by displaying the rows that have null values in these two variables\n",
    "# Display rows where 'date_of_last_rech_data_6' and 'total_rech_data_6' are both null\n",
    "churn.loc[churn.total_rech_data_6.isnull() & churn.date_of_last_rech_data_6.isnull(), [\"total_rech_data_6\", \"date_of_last_rech_data_6\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "As0NTpnFd81g"
   },
   "source": [
    "Impute missing values with zeroes wherever customer didn't recharge their number that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2e7lzAL1d81g"
   },
   "outputs": [],
   "source": [
    "# create a list of recharge columns where we will impute missing values with zeroes\n",
    "zero_impute = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "        'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "        'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vZCXT8dPd81g"
   },
   "outputs": [],
   "source": [
    "# impute missing values with 0 for the above mentioned list of recharge columns\n",
    "\n",
    "churn[zero_impute] = churn[zero_impute].apply(lambda x: x.fillna(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPW6vFZ17xYZ"
   },
   "source": [
    "Check whether the imputation has been done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UVmvI2gZd81g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value ratio:\n",
      "\n",
      "total_rech_data_6     0.0\n",
      "total_rech_data_7     0.0\n",
      "total_rech_data_8     0.0\n",
      "total_rech_data_9     0.0\n",
      "av_rech_amt_data_6    0.0\n",
      "av_rech_amt_data_7    0.0\n",
      "av_rech_amt_data_8    0.0\n",
      "av_rech_amt_data_9    0.0\n",
      "max_rech_data_6       0.0\n",
      "max_rech_data_7       0.0\n",
      "max_rech_data_8       0.0\n",
      "max_rech_data_9       0.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Summary statistics\n",
      "\n",
      "       total_rech_data_6  total_rech_data_7  total_rech_data_8  \\\n",
      "count       99999.000000       99999.000000       99999.000000   \n",
      "mean            0.619726           0.681837           0.698517   \n",
      "std             1.760541           1.924382           1.963417   \n",
      "min             0.000000           0.000000           0.000000   \n",
      "25%             0.000000           0.000000           0.000000   \n",
      "50%             0.000000           0.000000           0.000000   \n",
      "75%             1.000000           1.000000           1.000000   \n",
      "max            61.000000          54.000000          60.000000   \n",
      "\n",
      "       total_rech_data_9  av_rech_amt_data_6  av_rech_amt_data_7  \\\n",
      "count       99999.000000        99999.000000        99999.000000   \n",
      "mean            0.632806           48.445409           51.393440   \n",
      "std             1.669040          127.743863          132.629365   \n",
      "min             0.000000            0.000000            0.000000   \n",
      "25%             0.000000            0.000000            0.000000   \n",
      "50%             0.000000            0.000000            0.000000   \n",
      "75%             1.000000            8.250000           17.000000   \n",
      "max            84.000000         7546.000000         4365.000000   \n",
      "\n",
      "       av_rech_amt_data_8  av_rech_amt_data_9  max_rech_data_6  \\\n",
      "count        99999.000000        99999.000000     99999.000000   \n",
      "mean            52.027022           49.961089        31.792048   \n",
      "std            131.182609          127.804280        77.248778   \n",
      "min              0.000000            0.000000         0.000000   \n",
      "25%              0.000000            0.000000         0.000000   \n",
      "50%              0.000000            0.000000         0.000000   \n",
      "75%             23.000000           17.000000         8.000000   \n",
      "max           4076.000000         4061.000000      1555.000000   \n",
      "\n",
      "       max_rech_data_7  max_rech_data_8  max_rech_data_9  \n",
      "count     99999.000000     99999.000000     99999.000000  \n",
      "mean         32.406314        33.113011        32.387644  \n",
      "std          78.342435        78.872739        78.818696  \n",
      "min           0.000000         0.000000         0.000000  \n",
      "25%           0.000000         0.000000         0.000000  \n",
      "50%           0.000000         0.000000         0.000000  \n",
      "75%          14.000000        17.000000        17.000000  \n",
      "max        1555.000000      1555.000000      1555.000000  \n"
     ]
    }
   ],
   "source": [
    "# now, let's make sure values are imputed correctly\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(churn[zero_impute].isnull().sum()*100/churn.shape[1])\n",
    "\n",
    "# summary\n",
    "print(\"\\n\\nSummary statistics\\n\")\n",
    "print(churn[zero_impute].describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orbznC7q74gz"
   },
   "source": [
    "Drop the id and date columns which are not required in further analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v93kxYHPd81h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping:  (99999, 225)\n",
      "Shape after dropping:  (99999, 212)\n"
     ]
    }
   ],
   "source": [
    "# drop id and all the date columns\n",
    "print(\"Shape before dropping: \", churn.shape)\n",
    "\n",
    "churn.drop(columns=id_cols + date_cols, inplace=True)\n",
    "print(\"Shape after dropping: \", churn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZjdXHUKd81h"
   },
   "source": [
    "### ii) Replace NaN values in categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqaOOj-qkaFv"
   },
   "source": [
    "The categorical variables present in the data set are given below:\n",
    "  - night_pck_user: Prepaid service schemes for use during specific night hours only\n",
    "  - fb_user: Service scheme to avail services of Facebook and similar social networking sites\n",
    "\n",
    "If there are missing values, this means that there is another scheme that the customer has availed from the telecomminucation service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h_v0ZV_d81h"
   },
   "source": [
    "We will replace missing values in the categorical values with '-1' where '-1' will be a new category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cy0PvmSJd81h"
   },
   "outputs": [],
   "source": [
    "# replace missing values with '-1' in categorical columns\n",
    "churn[cat_cols] = churn[cat_cols].apply(lambda x: x.fillna(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HP2G8yb8IMl"
   },
   "source": [
    "Check for the missing value ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GzXMjtRBd81h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value ratio:\n",
      "\n",
      "night_pck_user_6    0.0\n",
      "night_pck_user_7    0.0\n",
      "night_pck_user_8    0.0\n",
      "night_pck_user_9    0.0\n",
      "fb_user_6           0.0\n",
      "fb_user_7           0.0\n",
      "fb_user_8           0.0\n",
      "fb_user_9           0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# missing value ratio\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(churn[cat_cols].isnull().sum()*100/churn.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAvcvw2Dd81h"
   },
   "source": [
    "### iii) Drop variables with more than a given threshold of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7YbBJUjHPdb"
   },
   "source": [
    "Here, we will be removing the column variables that have more than 70% of its elements missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sQLEKv75d81h"
   },
   "outputs": [],
   "source": [
    "initial_cols = churn.shape[1]\n",
    "\n",
    "# Insert the threshold value of missing entries\n",
    "MISSING_THRESHOLD = 0.70\n",
    "\n",
    "# Extract a list of columns that have less than the threshold of missing values\n",
    "include_cols = list(churn.apply(lambda column: True if column.isnull().sum()/churn.shape[0] < MISSING_THRESHOLD else False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rnZKs1mRd81i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns dropped: 16\n"
     ]
    }
   ],
   "source": [
    "# Include the columns extracted in the above list in the main data set\n",
    "# These columns will have the percentage of missing values less than the threshold\n",
    "# Include the columns extracted in the above list in the main data set\n",
    "churn = churn.loc[:, include_cols]\n",
    "\n",
    "# Display the number of columns dropped\n",
    "columns_dropped =  initial_cols - churn.shape[1] \n",
    "print(f\"Number of columns dropped: {columns_dropped}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74XouiVt-50t"
   },
   "source": [
    "**Checkpoint:** You must have dropped 16 columns in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std_ic_t2t_mou_9      7.745077\n",
       "loc_og_t2t_mou_9      7.745077\n",
       "loc_og_t2f_mou_9      7.745077\n",
       "loc_og_t2c_mou_9      7.745077\n",
       "loc_og_mou_9          7.745077\n",
       "std_og_t2t_mou_9      7.745077\n",
       "std_og_t2m_mou_9      7.745077\n",
       "std_og_t2f_mou_9      7.745077\n",
       "std_og_mou_9          7.745077\n",
       "isd_og_mou_9          7.745077\n",
       "spl_og_mou_9          7.745077\n",
       "og_others_9           7.745077\n",
       "spl_ic_mou_9          7.745077\n",
       "loc_ic_t2t_mou_9      7.745077\n",
       "loc_ic_t2m_mou_9      7.745077\n",
       "loc_ic_t2f_mou_9      7.745077\n",
       "loc_ic_mou_9          7.745077\n",
       "std_ic_t2m_mou_9      7.745077\n",
       "std_ic_t2f_mou_9      7.745077\n",
       "std_ic_t2o_mou_9      7.745077\n",
       "std_ic_mou_9          7.745077\n",
       "loc_og_t2m_mou_9      7.745077\n",
       "std_og_t2c_mou_9      7.745077\n",
       "roam_og_mou_9         7.745077\n",
       "ic_others_9           7.745077\n",
       "onnet_mou_9           7.745077\n",
       "roam_ic_mou_9         7.745077\n",
       "isd_ic_mou_9          7.745077\n",
       "offnet_mou_9          7.745077\n",
       "spl_og_mou_8          5.378054\n",
       "std_og_t2c_mou_8      5.378054\n",
       "og_others_8           5.378054\n",
       "std_og_t2m_mou_8      5.378054\n",
       "loc_ic_mou_8          5.378054\n",
       "std_og_t2f_mou_8      5.378054\n",
       "loc_ic_t2f_mou_8      5.378054\n",
       "onnet_mou_8           5.378054\n",
       "loc_ic_t2m_mou_8      5.378054\n",
       "std_og_t2t_mou_8      5.378054\n",
       "std_og_mou_8          5.378054\n",
       "loc_ic_t2t_mou_8      5.378054\n",
       "isd_og_mou_8          5.378054\n",
       "offnet_mou_8          5.378054\n",
       "isd_ic_mou_8          5.378054\n",
       "roam_ic_mou_8         5.378054\n",
       "std_ic_t2t_mou_8      5.378054\n",
       "spl_ic_mou_8          5.378054\n",
       "loc_og_t2f_mou_8      5.378054\n",
       "loc_og_t2t_mou_8      5.378054\n",
       "loc_og_mou_8          5.378054\n",
       "std_ic_t2m_mou_8      5.378054\n",
       "std_ic_mou_8          5.378054\n",
       "loc_og_t2m_mou_8      5.378054\n",
       "roam_og_mou_8         5.378054\n",
       "loc_og_t2c_mou_8      5.378054\n",
       "std_ic_t2f_mou_8      5.378054\n",
       "ic_others_8           5.378054\n",
       "std_ic_t2o_mou_8      5.378054\n",
       "isd_ic_mou_6          3.937039\n",
       "loc_ic_t2t_mou_6      3.937039\n",
       "std_ic_mou_6          3.937039\n",
       "std_ic_t2o_mou_6      3.937039\n",
       "loc_ic_t2m_mou_6      3.937039\n",
       "std_ic_t2m_mou_6      3.937039\n",
       "loc_ic_t2f_mou_6      3.937039\n",
       "onnet_mou_6           3.937039\n",
       "std_ic_t2f_mou_6      3.937039\n",
       "loc_ic_mou_6          3.937039\n",
       "ic_others_6           3.937039\n",
       "std_ic_t2t_mou_6      3.937039\n",
       "offnet_mou_6          3.937039\n",
       "loc_og_t2t_mou_6      3.937039\n",
       "spl_ic_mou_6          3.937039\n",
       "std_og_mou_6          3.937039\n",
       "og_others_6           3.937039\n",
       "std_og_t2f_mou_6      3.937039\n",
       "loc_og_mou_6          3.937039\n",
       "roam_og_mou_6         3.937039\n",
       "roam_ic_mou_6         3.937039\n",
       "std_og_t2c_mou_6      3.937039\n",
       "std_og_t2t_mou_6      3.937039\n",
       "loc_og_t2c_mou_6      3.937039\n",
       "std_og_t2m_mou_6      3.937039\n",
       "isd_og_mou_6          3.937039\n",
       "spl_og_mou_6          3.937039\n",
       "loc_og_t2f_mou_6      3.937039\n",
       "loc_og_t2m_mou_6      3.937039\n",
       "std_ic_t2o_mou_7      3.859039\n",
       "roam_og_mou_7         3.859039\n",
       "ic_others_7           3.859039\n",
       "loc_og_t2c_mou_7      3.859039\n",
       "std_ic_t2f_mou_7      3.859039\n",
       "loc_og_t2f_mou_7      3.859039\n",
       "std_ic_mou_7          3.859039\n",
       "loc_og_t2m_mou_7      3.859039\n",
       "loc_og_mou_7          3.859039\n",
       "std_ic_t2m_mou_7      3.859039\n",
       "og_others_7           3.859039\n",
       "roam_ic_mou_7         3.859039\n",
       "std_og_t2t_mou_7      3.859039\n",
       "std_og_mou_7          3.859039\n",
       "offnet_mou_7          3.859039\n",
       "loc_og_t2t_mou_7      3.859039\n",
       "isd_ic_mou_7          3.859039\n",
       "spl_og_mou_7          3.859039\n",
       "isd_og_mou_7          3.859039\n",
       "loc_ic_t2t_mou_7      3.859039\n",
       "loc_ic_t2m_mou_7      3.859039\n",
       "std_ic_t2t_mou_7      3.859039\n",
       "onnet_mou_7           3.859039\n",
       "std_og_t2c_mou_7      3.859039\n",
       "loc_ic_t2f_mou_7      3.859039\n",
       "std_og_t2f_mou_7      3.859039\n",
       "loc_ic_mou_7          3.859039\n",
       "std_og_t2m_mou_7      3.859039\n",
       "spl_ic_mou_7          3.859039\n",
       "loc_og_t2o_mou        1.018010\n",
       "std_og_t2o_mou        1.018010\n",
       "loc_ic_t2o_mou        1.018010\n",
       "total_ic_mou_8        0.000000\n",
       "night_pck_user_7      0.000000\n",
       "sachet_2g_6           0.000000\n",
       "monthly_2g_9          0.000000\n",
       "monthly_2g_8          0.000000\n",
       "monthly_2g_7          0.000000\n",
       "monthly_2g_6          0.000000\n",
       "night_pck_user_9      0.000000\n",
       "night_pck_user_8      0.000000\n",
       "night_pck_user_6      0.000000\n",
       "sachet_2g_8           0.000000\n",
       "vol_3g_mb_9           0.000000\n",
       "vol_3g_mb_8           0.000000\n",
       "vol_3g_mb_7           0.000000\n",
       "vol_3g_mb_6           0.000000\n",
       "vol_2g_mb_9           0.000000\n",
       "vol_2g_mb_8           0.000000\n",
       "vol_2g_mb_7           0.000000\n",
       "sachet_2g_7           0.000000\n",
       "sachet_2g_9           0.000000\n",
       "av_rech_amt_data_9    0.000000\n",
       "monthly_3g_6          0.000000\n",
       "jun_vbc_3g            0.000000\n",
       "jul_vbc_3g            0.000000\n",
       "aug_vbc_3g            0.000000\n",
       "aon                   0.000000\n",
       "fb_user_9             0.000000\n",
       "fb_user_8             0.000000\n",
       "fb_user_7             0.000000\n",
       "fb_user_6             0.000000\n",
       "sachet_3g_9           0.000000\n",
       "sachet_3g_8           0.000000\n",
       "sachet_3g_7           0.000000\n",
       "sachet_3g_6           0.000000\n",
       "monthly_3g_9          0.000000\n",
       "monthly_3g_8          0.000000\n",
       "monthly_3g_7          0.000000\n",
       "vol_2g_mb_6           0.000000\n",
       "av_rech_amt_data_7    0.000000\n",
       "av_rech_amt_data_8    0.000000\n",
       "arpu_7                0.000000\n",
       "total_rech_amt_7      0.000000\n",
       "total_rech_amt_6      0.000000\n",
       "total_rech_num_9      0.000000\n",
       "total_rech_num_8      0.000000\n",
       "total_rech_num_7      0.000000\n",
       "total_rech_num_6      0.000000\n",
       "arpu_6                0.000000\n",
       "arpu_8                0.000000\n",
       "total_ic_mou_9        0.000000\n",
       "arpu_9                0.000000\n",
       "total_og_mou_6        0.000000\n",
       "total_og_mou_7        0.000000\n",
       "total_og_mou_8        0.000000\n",
       "total_og_mou_9        0.000000\n",
       "total_ic_mou_6        0.000000\n",
       "total_ic_mou_7        0.000000\n",
       "total_rech_amt_8      0.000000\n",
       "total_rech_amt_9      0.000000\n",
       "max_rech_amt_6        0.000000\n",
       "max_rech_amt_7        0.000000\n",
       "av_rech_amt_data_6    0.000000\n",
       "max_rech_data_9       0.000000\n",
       "max_rech_data_8       0.000000\n",
       "max_rech_data_7       0.000000\n",
       "max_rech_data_6       0.000000\n",
       "total_rech_data_9     0.000000\n",
       "total_rech_data_8     0.000000\n",
       "total_rech_data_7     0.000000\n",
       "total_rech_data_6     0.000000\n",
       "last_day_rch_amt_9    0.000000\n",
       "last_day_rch_amt_8    0.000000\n",
       "last_day_rch_amt_7    0.000000\n",
       "last_day_rch_amt_6    0.000000\n",
       "max_rech_amt_9        0.000000\n",
       "max_rech_amt_8        0.000000\n",
       "sep_vbc_3g            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at missing value ratio in each column\n",
    "(churn.isnull().sum()*100/churn.shape[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVbD6u5kd81i"
   },
   "source": [
    "### iv) Impute missing values using MICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMdp2spW14xJ"
   },
   "source": [
    "[MICE](https://scikit-learn.org/stable/modules/impute.html) is called \"Multiple Imputation by Chained Equation\". It uses machine learning techniques in order to see what are the trends in the values of that column. Using this information, it will smartly fill in the missing values in that column.\n",
    "\n",
    "MICE is now called Iterative Imputer.\n",
    "\n",
    "You can specify the machine learning algorithm to be used in order to fill in the missing values of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fL3-VmJL14xK"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from fancyimpute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN3kmZ0GIong"
   },
   "source": [
    "So, we will be using linear regression for filling the missing values in the rest of the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7iDa6Llpd81i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (99999, 196)\n",
      "[IterativeImputer] Ending imputation round 1/1, elapsed time 194.09\n",
      "[IterativeImputer] Change: 242617.62280941426, scaled tolerance: 45.735400000000006 \n"
     ]
    }
   ],
   "source": [
    "churn_cols = churn.columns\n",
    "\n",
    "# using MICE technique to impute missing values in the rest of the columns\n",
    "# Implement the Iterative Imputer technique to impute appropriate values in the missing entries of the rest of the numeric columns\n",
    "# Note: Set the 'estimator' parameter to 'lr'  - This specifies that we will be using linear regression to estimate the missing values\n",
    "# Note: Set the 'missing_values' parameter to 'np.nan' - This specifies that we have impute the entries which are NaNs\n",
    "# Note: Set the 'max_iter' parameter to '1' - This specifies the number of iterations the algorithm scans through the data set\n",
    "#       to converge to appropriate values it is going to impute in the missing entries. It takes around 6 min to run.\n",
    "# Note: Set the 'verbose' parameter to '2' - This specifies the amount of details it will show while imputing\n",
    "# Note: Set the 'imputation_order' parameter to 'roman' - This specifies the order in which features will be imputed. 'roman' means left to right\n",
    "# Note: Set the 'random_state' parameter to '0' - This is for reproducibility\n",
    "lr = LinearRegression()\n",
    "imp = IterativeImputer(estimator = lr,\n",
    "                      missing_values = np.nan,\n",
    "                      max_iter = 1,\n",
    "                      verbose = 2,\n",
    "                      imputation_order = 'roman',\n",
    "                      random_state = 0)\n",
    "\n",
    "churn = imp.fit_transform(churn)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.  ,    0.  ,    0.  , ...,    0.  ,  101.2 ,    3.58],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    4.17,    0.  ],\n",
       "       ...,\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ..., 1151.03, 1173.18,    0.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5RX4Qew1d81i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc_og_t2o_mou        0.0\n",
      "std_og_t2o_mou        0.0\n",
      "loc_ic_t2o_mou        0.0\n",
      "arpu_6                0.0\n",
      "arpu_7                0.0\n",
      "arpu_8                0.0\n",
      "arpu_9                0.0\n",
      "onnet_mou_6           0.0\n",
      "onnet_mou_7           0.0\n",
      "onnet_mou_8           0.0\n",
      "onnet_mou_9           0.0\n",
      "offnet_mou_6          0.0\n",
      "offnet_mou_7          0.0\n",
      "offnet_mou_8          0.0\n",
      "offnet_mou_9          0.0\n",
      "roam_ic_mou_6         0.0\n",
      "roam_ic_mou_7         0.0\n",
      "roam_ic_mou_8         0.0\n",
      "roam_ic_mou_9         0.0\n",
      "roam_og_mou_6         0.0\n",
      "roam_og_mou_7         0.0\n",
      "roam_og_mou_8         0.0\n",
      "roam_og_mou_9         0.0\n",
      "loc_og_t2t_mou_6      0.0\n",
      "loc_og_t2t_mou_7      0.0\n",
      "loc_og_t2t_mou_8      0.0\n",
      "loc_og_t2t_mou_9      0.0\n",
      "loc_og_t2m_mou_6      0.0\n",
      "loc_og_t2m_mou_7      0.0\n",
      "loc_og_t2m_mou_8      0.0\n",
      "loc_og_t2m_mou_9      0.0\n",
      "loc_og_t2f_mou_6      0.0\n",
      "loc_og_t2f_mou_7      0.0\n",
      "loc_og_t2f_mou_8      0.0\n",
      "loc_og_t2f_mou_9      0.0\n",
      "loc_og_t2c_mou_6      0.0\n",
      "loc_og_t2c_mou_7      0.0\n",
      "loc_og_t2c_mou_8      0.0\n",
      "loc_og_t2c_mou_9      0.0\n",
      "loc_og_mou_6          0.0\n",
      "loc_og_mou_7          0.0\n",
      "loc_og_mou_8          0.0\n",
      "loc_og_mou_9          0.0\n",
      "std_og_t2t_mou_6      0.0\n",
      "std_og_t2t_mou_7      0.0\n",
      "std_og_t2t_mou_8      0.0\n",
      "std_og_t2t_mou_9      0.0\n",
      "std_og_t2m_mou_6      0.0\n",
      "std_og_t2m_mou_7      0.0\n",
      "std_og_t2m_mou_8      0.0\n",
      "std_og_t2m_mou_9      0.0\n",
      "std_og_t2f_mou_6      0.0\n",
      "std_og_t2f_mou_7      0.0\n",
      "std_og_t2f_mou_8      0.0\n",
      "std_og_t2f_mou_9      0.0\n",
      "std_og_t2c_mou_6      0.0\n",
      "std_og_t2c_mou_7      0.0\n",
      "std_og_t2c_mou_8      0.0\n",
      "std_og_t2c_mou_9      0.0\n",
      "std_og_mou_6          0.0\n",
      "std_og_mou_7          0.0\n",
      "std_og_mou_8          0.0\n",
      "std_og_mou_9          0.0\n",
      "isd_og_mou_6          0.0\n",
      "isd_og_mou_7          0.0\n",
      "isd_og_mou_8          0.0\n",
      "isd_og_mou_9          0.0\n",
      "spl_og_mou_6          0.0\n",
      "spl_og_mou_7          0.0\n",
      "spl_og_mou_8          0.0\n",
      "spl_og_mou_9          0.0\n",
      "og_others_6           0.0\n",
      "og_others_7           0.0\n",
      "og_others_8           0.0\n",
      "og_others_9           0.0\n",
      "total_og_mou_6        0.0\n",
      "total_og_mou_7        0.0\n",
      "total_og_mou_8        0.0\n",
      "total_og_mou_9        0.0\n",
      "loc_ic_t2t_mou_6      0.0\n",
      "loc_ic_t2t_mou_7      0.0\n",
      "loc_ic_t2t_mou_8      0.0\n",
      "loc_ic_t2t_mou_9      0.0\n",
      "loc_ic_t2m_mou_6      0.0\n",
      "loc_ic_t2m_mou_7      0.0\n",
      "loc_ic_t2m_mou_8      0.0\n",
      "loc_ic_t2m_mou_9      0.0\n",
      "loc_ic_t2f_mou_6      0.0\n",
      "loc_ic_t2f_mou_7      0.0\n",
      "loc_ic_t2f_mou_8      0.0\n",
      "loc_ic_t2f_mou_9      0.0\n",
      "loc_ic_mou_6          0.0\n",
      "loc_ic_mou_7          0.0\n",
      "loc_ic_mou_8          0.0\n",
      "loc_ic_mou_9          0.0\n",
      "std_ic_t2t_mou_6      0.0\n",
      "std_ic_t2t_mou_7      0.0\n",
      "std_ic_t2t_mou_8      0.0\n",
      "std_ic_t2t_mou_9      0.0\n",
      "std_ic_t2m_mou_6      0.0\n",
      "std_ic_t2m_mou_7      0.0\n",
      "std_ic_t2m_mou_8      0.0\n",
      "std_ic_t2m_mou_9      0.0\n",
      "std_ic_t2f_mou_6      0.0\n",
      "std_ic_t2f_mou_7      0.0\n",
      "std_ic_t2f_mou_8      0.0\n",
      "std_ic_t2f_mou_9      0.0\n",
      "std_ic_t2o_mou_6      0.0\n",
      "std_ic_t2o_mou_7      0.0\n",
      "std_ic_t2o_mou_8      0.0\n",
      "std_ic_t2o_mou_9      0.0\n",
      "std_ic_mou_6          0.0\n",
      "std_ic_mou_7          0.0\n",
      "std_ic_mou_8          0.0\n",
      "std_ic_mou_9          0.0\n",
      "total_ic_mou_6        0.0\n",
      "total_ic_mou_7        0.0\n",
      "total_ic_mou_8        0.0\n",
      "total_ic_mou_9        0.0\n",
      "spl_ic_mou_6          0.0\n",
      "spl_ic_mou_7          0.0\n",
      "spl_ic_mou_8          0.0\n",
      "spl_ic_mou_9          0.0\n",
      "isd_ic_mou_6          0.0\n",
      "isd_ic_mou_7          0.0\n",
      "isd_ic_mou_8          0.0\n",
      "isd_ic_mou_9          0.0\n",
      "ic_others_6           0.0\n",
      "ic_others_7           0.0\n",
      "ic_others_8           0.0\n",
      "ic_others_9           0.0\n",
      "total_rech_num_6      0.0\n",
      "total_rech_num_7      0.0\n",
      "total_rech_num_8      0.0\n",
      "total_rech_num_9      0.0\n",
      "total_rech_amt_6      0.0\n",
      "total_rech_amt_7      0.0\n",
      "total_rech_amt_8      0.0\n",
      "total_rech_amt_9      0.0\n",
      "max_rech_amt_6        0.0\n",
      "max_rech_amt_7        0.0\n",
      "max_rech_amt_8        0.0\n",
      "max_rech_amt_9        0.0\n",
      "last_day_rch_amt_6    0.0\n",
      "last_day_rch_amt_7    0.0\n",
      "last_day_rch_amt_8    0.0\n",
      "last_day_rch_amt_9    0.0\n",
      "total_rech_data_6     0.0\n",
      "total_rech_data_7     0.0\n",
      "total_rech_data_8     0.0\n",
      "total_rech_data_9     0.0\n",
      "max_rech_data_6       0.0\n",
      "max_rech_data_7       0.0\n",
      "max_rech_data_8       0.0\n",
      "max_rech_data_9       0.0\n",
      "av_rech_amt_data_6    0.0\n",
      "av_rech_amt_data_7    0.0\n",
      "av_rech_amt_data_8    0.0\n",
      "av_rech_amt_data_9    0.0\n",
      "vol_2g_mb_6           0.0\n",
      "vol_2g_mb_7           0.0\n",
      "vol_2g_mb_8           0.0\n",
      "vol_2g_mb_9           0.0\n",
      "vol_3g_mb_6           0.0\n",
      "vol_3g_mb_7           0.0\n",
      "vol_3g_mb_8           0.0\n",
      "vol_3g_mb_9           0.0\n",
      "night_pck_user_6      0.0\n",
      "night_pck_user_7      0.0\n",
      "night_pck_user_8      0.0\n",
      "night_pck_user_9      0.0\n",
      "monthly_2g_6          0.0\n",
      "monthly_2g_7          0.0\n",
      "monthly_2g_8          0.0\n",
      "monthly_2g_9          0.0\n",
      "sachet_2g_6           0.0\n",
      "sachet_2g_7           0.0\n",
      "sachet_2g_8           0.0\n",
      "sachet_2g_9           0.0\n",
      "monthly_3g_6          0.0\n",
      "monthly_3g_7          0.0\n",
      "monthly_3g_8          0.0\n",
      "monthly_3g_9          0.0\n",
      "sachet_3g_6           0.0\n",
      "sachet_3g_7           0.0\n",
      "sachet_3g_8           0.0\n",
      "sachet_3g_9           0.0\n",
      "fb_user_6             0.0\n",
      "fb_user_7             0.0\n",
      "fb_user_8             0.0\n",
      "fb_user_9             0.0\n",
      "aon                   0.0\n",
      "aug_vbc_3g            0.0\n",
      "jul_vbc_3g            0.0\n",
      "jun_vbc_3g            0.0\n",
      "sep_vbc_3g            0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# convert imputed numpy array to pandas dataframe\n",
    "churn = pd.DataFrame(churn, columns=churn_cols)\n",
    "print(churn.isnull().sum()*100/churn.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffpvc8NGIwhQ"
   },
   "source": [
    "You can now see that we have removed or filled all the missing values from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uxdyKLA_g2Y"
   },
   "source": [
    "### Checklist\n",
    "- Explored the data set by analyzing the summary statistics\n",
    "- Identified the types of features present in the data set\n",
    "- Computed the ratio of missing values in each of the features in the data set\n",
    "- Imputed missing values with zeroes wherever customer didn't recharge their number for any particular month\n",
    "- Replace missing values in the categorical variables with '-1' where '-1' is a new category\n",
    "- Removed the column variables that have more than 70% of its elements missing\n",
    "- Imputed the remaining  features with missing values using MICE technique\n",
    "- Retained the data set required for further analyses by dropping the irrelevant columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STA7mKD5_h7b"
   },
   "source": [
    "We will now proceed to feature engineering to further prepare the data for testing machine learning and deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0aju3lDd81i"
   },
   "source": [
    "# Task 3: Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWdfZMATQJKI"
   },
   "source": [
    "### Description\n",
    "\n",
    "In this task, you will extract, select, or create relevant features from your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX4iEYxM14xL"
   },
   "source": [
    "### Filter high-value customers\n",
    "High-value customers are those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months (the good phase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMm21PvOd81i"
   },
   "source": [
    "### Calculate total data recharge amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dd-oajkqd81i"
   },
   "outputs": [],
   "source": [
    "# calculate and store the total data recharge amount for June --> number of data recharges * average data recharge amount\n",
    "# You have to use the total recharge for data and the average recharge amount for data\n",
    "# June, July, August and September - The months are encoded as 6, 7, 8 and 9, respectively.\n",
    "\n",
    "churn['total_data_rech_6'] = churn.total_rech_data_6 * churn.av_rech_amt_data_6\n",
    "\n",
    "# calculate and store the total data recharge amount for July --> number of data recharges * average data recharge amount\n",
    "churn['total_data_rech_7'] = churn.total_rech_data_7 * churn.av_rech_amt_data_7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikMe4dp2d81j"
   },
   "source": [
    "Add total data recharge and call recharge to get total combined recharge amount for a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7mMlFJZ6d81j"
   },
   "outputs": [],
   "source": [
    "# calculate and store total recharge amount for call and internet data for June --> total call recharge amount + total data recharge amount\n",
    "\n",
    "churn['amt_data_6'] = churn.total_rech_amt_6 + churn.total_data_rech_6\n",
    "\n",
    "# calculate and store total recharge amount for call and internet data for July --> total call recharge amount + total data recharge amount\n",
    "churn['amt_data_7'] = churn.total_rech_amt_7 + churn.total_data_rech_7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoR5iX-bEqjQ"
   },
   "source": [
    "Compute the average recharge amount for customers in June and July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zK6nozryd81j"
   },
   "outputs": [],
   "source": [
    "# calculate average data recharge amount done by customer in June and July\n",
    "churn['av_amt_data_6_7'] = (churn.amt_data_6 + churn.amt_data_7)/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEEgM6fSE4lI"
   },
   "source": [
    "Find the 70th percentile for average data recharge amount for June and July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JFZVPQZad81j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recharge amount at 70th percentile: 478.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate and display the 70th percentile average data recharge amount of June and July\n",
    "print(\"Recharge amount at 70th percentile: {0}\".format(churn.av_amt_data_6_7.quantile(0.7)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpwlzK5cDoxb"
   },
   "source": [
    "**Checkpoint:** You must have obtained 478 as the recharge amount at 70th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mZTbYMqFFtO"
   },
   "source": [
    "Filter the data set for customers who have recharged their mobiles with more than or equal to 70th percentile amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "nFQ5xy7Ad81j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 201)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only those customers who have recharged their mobiles with more than or equal to 70th percentile amount\n",
    "# You have seen whether each customer row has the average data recharge amount more than the 70th percentile of the average data recharge amount\n",
    "churn_filtered = churn.loc[churn.av_amt_data_6_7 >= churn.av_amt_data_6_7.quantile(0.7), :]\n",
    "churn_filtered = churn_filtered.reset_index(drop=True)\n",
    "churn_filtered.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HE9aQoI1FO3m"
   },
   "source": [
    "Drop the variables which are no longer required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "uDYloA8Zd81j"
   },
   "outputs": [],
   "source": [
    "# delete variables created to filter high-value customers\n",
    "churn_filtered = churn_filtered.drop(['total_data_rech_6', 'total_data_rech_7',\n",
    "                                      'amt_data_6', 'amt_data_7', 'av_amt_data_6_7'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RWJWnBjZvGcD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 196)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of customers retained in the data set\n",
    "churn_filtered.shape \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ibc399AIFWt9"
   },
   "source": [
    "**Checkpoint:** Now you must have 30001 customers in the data set with 196 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLxHeovyd81j"
   },
   "source": [
    "### Derive churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQjCxXEFzDJh"
   },
   "source": [
    "### Tagging churners and removing the attributes of the churn phase\n",
    "Now tag the churned customers (churn=1, else 0) based on the fourth month as follows: those who have not made any calls (either incoming or outgoing) and have not used mobile internet even once in the churn phase. The attributes you must use to tag churners are as follows:\n",
    "\n",
    "total_ic_mou_9\n",
    "total_og_mou_9\n",
    "vol_2g_mb_9\n",
    "vol_3g_mb_9\n",
    "After tagging churners, remove all the attributes corresponding to the churn phase (all attributes having “_9”, etc. in their names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCZc0Tl5GHfq"
   },
   "source": [
    "Calculate total incoming and outgoing minutes of usage for the month of September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "UBQRZGlzd81j"
   },
   "outputs": [],
   "source": [
    "# Add total incoming and outgoing minutes of usage for the month of September\n",
    "churn_filtered['total_calls_mou_9'] = churn_filtered.total_ic_mou_9 + churn_filtered.total_og_mou_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBkYlJJRGSjW"
   },
   "source": [
    "Calculate the total volumn of 2g and 3g data consumption for the month of September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6rPBN3x_d81j"
   },
   "outputs": [],
   "source": [
    "# Add the total volumn of 2g and 3g data consumption for the month of September\n",
    "churn_filtered['total_internet_mb_9'] =  churn_filtered.vol_2g_mb_9 + churn_filtered.vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYptLOkfGakv"
   },
   "source": [
    "Create churn variable by tagging customers who have not used either calls or internet in the month of September as 0 - not churn and 1 - churn otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "gbNXqSJqd81j"
   },
   "outputs": [],
   "source": [
    "# create churn variable: those who have not used either calls or internet in the month of September are customers who have churned using the lambda function\n",
    "# Here 0 denotes not churn and 1 denotes churn\n",
    "churn_filtered['churn'] = churn_filtered.apply(lambda row: 1 if (row.total_calls_mou_9 == 0 and row.total_internet_mb_9 == 0) else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IP5MkdYYG3_U"
   },
   "source": [
    "Drop the derived variables which are no longer required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "CJysD9WGd81j"
   },
   "outputs": [],
   "source": [
    "# delete derived variables\n",
    "churn_filtered = churn_filtered.drop(['total_calls_mou_9', 'total_internet_mb_9'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBfvWtIfHI6b"
   },
   "source": [
    "Analyze the class ratio of churn column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-z-9hywed81k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Ratio:\n",
      "churn\n",
      "0    91.863605\n",
      "1     8.136395\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# change the 'churn' variable data type to 'category'\n",
    "churn_filtered.churn = churn_filtered.churn.astype(\"category\")\n",
    "\n",
    "\n",
    "# display the churn ratio\n",
    "print(\"Churn Ratio:\")\n",
    "print(churn_filtered.churn.value_counts()*100/churn_filtered.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB1Lknlid81k"
   },
   "source": [
    "### Calculate difference between 8th and previous months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQVfi5tJd81k"
   },
   "source": [
    "Let's derive some variables. The most important feature, in this situation, can be the difference between the 8th month and the previous months. The difference can be in patterns such as usage difference or recharge value difference. Let's calculate difference variable as the difference between 8th month and the average of 6th and 7th month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6qAeeSRvd81k"
   },
   "outputs": [],
   "source": [
    "cols =  ['arpu',\n",
    "         'onnet_mou',\n",
    "         'offnet_mou',\n",
    "         'roam_ic_mou',\n",
    "         'roam_og_mou',\n",
    "         'loc_og_mou',\n",
    "         'std_og_mou',\n",
    "         'isd_og_mou',\n",
    "         'spl_og_mou',\n",
    "         'total_og_mou',\n",
    "         'loc_ic_mou',\n",
    "         'std_ic_mou',\n",
    "         'isd_ic_mou',\n",
    "         'spl_ic_mou',\n",
    "         'total_ic_mou',\n",
    "         'total_rech_num',\n",
    "         'total_rech_amt',\n",
    "         'max_rech_amt',\n",
    "         'total_rech_data',\n",
    "         'max_rech_data',\n",
    "         'av_rech_amt_data',\n",
    "         'vol_2g_mb',\n",
    "         'vol_3g_mb'\n",
    "         ]\n",
    "\n",
    "# Create new columns that hold the value of the difference between the variable value\n",
    "# in the month of August and average of the variable values in the month of June and July\n",
    "for col in cols:\n",
    "    churn_filtered[f'{col}_diff'] = churn_filtered[f'{col}_8'] - ((churn_filtered[f'{col}_6'] + churn_filtered[f'{col}_7']) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "5RXeZq3rd81k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30001.000000\n",
       "mean       -67.437337\n",
       "std        502.630069\n",
       "min      -7213.410000\n",
       "25%       -168.025000\n",
       "50%        -14.625000\n",
       "75%         67.915000\n",
       "max      12768.705000\n",
       "Name: total_og_mou_diff, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at summary of one of the difference variables\n",
    "# The variable mentioned below is the total outgoing calls minutes of usage difference between the total OG MOU in August and average of the total OG MOU of June and July\n",
    "\n",
    "churn_filtered['total_og_mou_diff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWDxLdtLd81k"
   },
   "source": [
    "Delete columns that belong to the churn month (9th month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "x3sej5Gmd81k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 173)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete all variables relating to 9th month\n",
    "churn_filtered = churn_filtered.filter(regex='[^9]$', axis=1)\n",
    "churn_filtered.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "BTqWtPaNd81k"
   },
   "outputs": [],
   "source": [
    "# update num_cols and cat_cols column name list\n",
    "\n",
    "# extract all names that end with 9\n",
    "col_9_names = churn.filter(regex='9$', axis=1).columns\n",
    "\n",
    "\n",
    "# update cal_cols so that all the variables related to the month of September are removed\n",
    "cat_cols = [col for col in cat_cols if col not in col_9_names]\n",
    "cat_cols.append('churn')\n",
    "num_cols = [col for col in churn_filtered.columns if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAAjoEK4D4Ly"
   },
   "source": [
    "### Checklist:\n",
    "- Extracted high-value customers by filtering those customers who have recharged with an amount more than or equal to the 70th percentile of the average recharge amount in the first two months (the good phase).\n",
    "- Dropped the variables created to filter hight value customers\n",
    "- Created the churn variable by tagging customers who have not used either calls or internet in the month of September as 0 - not churn and 1 - churn otherwise\n",
    "- Derived new features by calculating the total outgoing calls minutes of usage difference between the total OG MOU in August and average of the total OG MOU of June and July\n",
    "- Removed the variables related to the churn phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b512tiEd81k"
   },
   "source": [
    "# Task 4: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjQM4OiBJEFB"
   },
   "source": [
    "### Description:\n",
    "In this task, you will visually represent and interpret patterns, trends, and relationships within the features in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwvevEaJRCtv"
   },
   "source": [
    "Check the data types of the numerical and categorical columns in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "E49BBqd5d81k"
   },
   "outputs": [],
   "source": [
    "# Ensure that all the numerical and categorical columns are of the correct data types\n",
    "churn_filtered[num_cols] = churn_filtered[num_cols].apply(pd.to_numeric)\n",
    "churn_filtered[cat_cols] = churn_filtered[cat_cols].apply(lambda column: column.astype(\"category\"), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVjt0kHMJL06"
   },
   "source": [
    "Create a function to do the univariate and bivariate analysis of the features present in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ZIZU7VEYd81k"
   },
   "outputs": [],
   "source": [
    "# create plotting functions\n",
    "def data_type(variable):\n",
    "    if variable.dtype == np.int64 or variable.dtype == np.float64:\n",
    "        return 'numerical'\n",
    "    elif variable.dtype == 'category':\n",
    "        return 'categorical'\n",
    "\n",
    "def univariate(variable, stats=True):\n",
    "\n",
    "    if data_type(variable) == 'numerical':\n",
    "        sns.distplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.describe())\n",
    "\n",
    "    elif data_type(variable) == 'categorical':\n",
    "        sns.countplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.value_counts())\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid variable passed: either pass a numeric variable or a categorical vairable.\")\n",
    "        \n",
    "def bivariate(var1, var2, dff):\n",
    "    if data_type(var1) == 'numerical' and data_type(var2) == 'numerical':\n",
    "        sns.regplot(x=var1, y=var2, data=dff)\n",
    "    elif (data_type(var1) == 'categorical' and data_type(var2) == 'numerical') or (data_type(var1) == 'numerical' and data_type(var2) == 'categorical'):\n",
    "        sns.boxplot(x=var1, y=var2, data=dff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR9shtqMd81l"
   },
   "source": [
    "## Univariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "uQBgBb0Md81l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99999.000000\n",
      "mean       282.987358\n",
      "std        328.439770\n",
      "min      -2258.709000\n",
      "25%         93.411500\n",
      "50%        197.704000\n",
      "75%        371.060000\n",
      "max      27731.088000\n",
      "Name: arpu_6, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the average revenue per user in June\n",
    "\n",
    "univariate(churn.arpu_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "CKn712mFd81l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99999.0\n",
      "mean         0.0\n",
      "std          0.0\n",
      "min          0.0\n",
      "25%          0.0\n",
      "50%          0.0\n",
      "75%          0.0\n",
      "max          0.0\n",
      "Name: loc_og_t2o_mou, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the minutes of usage of local (within same telecom circle) outgoing calls of Operator T to other operator fixed line\n",
    "\n",
    "univariate(churn.loc_og_t2o_mou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "LRF-ci9Rd81l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99999.0\n",
      "mean         0.0\n",
      "std          0.0\n",
      "min          0.0\n",
      "25%          0.0\n",
      "50%          0.0\n",
      "75%          0.0\n",
      "max          0.0\n",
      "Name: std_og_t2o_mou, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGxCAYAAACXwjeMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnp0lEQVR4nO3de3TU9Z3/8ddAkoFAMlsEZggEiBJA5KZYIFAbFIiCiwHaqhtPCIgubKQ1i8hFXAG3DcqRNLZc2roeLmcFWRXc9WzFpAKBbgC5CgJlqQaISIxoyISLAcnn9wc/ZhmTkGRIMvNJn49z5hzm8/3OzDvfA+bpd24OY4wRAACApZoFewAAAICbQcwAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsFpYsAdoaBUVFfriiy8UFRUlh8MR7HEAAEAtGGNUVlammJgYNWt243MvTT5mvvjiC8XGxgZ7DAAAEIDCwkJ16tTphvs0+ZiJioqSdPVgREdHB3kaAABQG16vV7Gxsb7f4zfS5GPm2lNL0dHRxAwAAJapzUtEeAEwAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArBbUmJk/f74cDoffxePx+LYbYzR//nzFxMSoZcuWGjZsmA4dOhTEiQEAQKgJ+pmZO+64Q6dPn/ZdDh486Nu2aNEiZWVlacmSJdq1a5c8Ho9GjhypsrKyIE4MAABCSdBjJiwsTB6Px3dp166dpKtnZbKzszV37lyNHz9evXv31qpVq3ThwgWtWbMmyFMDAIBQEfSYOXbsmGJiYhQXF6dHH31Un332mSSpoKBARUVFSkpK8u3rdDqVmJio/Pz8YI0LAABCTFgwH3zQoEFavXq1unfvri+//FK//OUvNWTIEB06dEhFRUWSJLfb7Xcbt9utEydOVHuf5eXlKi8v9133er0NMzwAAAgJQY2ZUaNG+f7cp08fJSQk6LbbbtOqVas0ePBgSZLD4fC7jTGm0tr1Fi5cqAULFjTMwABCzpqdJ2vcJ2VQ50aYBECwBP1ppuu1atVKffr00bFjx3zvarp2huaa4uLiSmdrrjdnzhyVlpb6LoWFhQ06MwAACK6Qipny8nIdOXJEHTp0UFxcnDwej3Jzc33bL126pLy8PA0ZMqTa+3A6nYqOjva7AACApiuoTzPNmDFDY8aMUefOnVVcXKxf/vKX8nq9SktLk8PhUEZGhjIzMxUfH6/4+HhlZmYqMjJSKSkpwRwbAACEkKDGzOeff65/+Id/0JkzZ9SuXTsNHjxYO3bsUJcuXSRJM2fO1MWLF5Wenq6SkhINGjRIOTk5ioqKCubYAAAghDiMMSbYQzQkr9crl8ul0tJSnnICmiBeAAw0TXX5/R1Sr5kBAACoK2IGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAVguZmFm4cKEcDocyMjJ8a8YYzZ8/XzExMWrZsqWGDRumQ4cOBW9IAAAQckIiZnbt2qU//OEP6tu3r9/6okWLlJWVpSVLlmjXrl3yeDwaOXKkysrKgjQpAAAINUGPmXPnzumxxx7Ta6+9ph/84Ae+dWOMsrOzNXfuXI0fP169e/fWqlWrdOHCBa1ZsyaIEwMAgFAS9Jh56qmn9OCDD2rEiBF+6wUFBSoqKlJSUpJvzel0KjExUfn5+Y09JgAACFFhwXzwN998U3v37tWuXbsqbSsqKpIkud1uv3W3260TJ05Ue5/l5eUqLy/3Xfd6vfU0LQAACEVBOzNTWFiop59+Wv/+7/+uFi1aVLufw+Hwu26MqbR2vYULF8rlcvkusbGx9TYzAAAIPUGLmT179qi4uFgDBgxQWFiYwsLClJeXp9/85jcKCwvznZG5dobmmuLi4kpna643Z84clZaW+i6FhYUN+nMAAIDgCtrTTMOHD9fBgwf91iZNmqSePXtq1qxZuvXWW+XxeJSbm6s777xTknTp0iXl5eXp5ZdfrvZ+nU6nnE5ng84OAABCR9BiJioqSr179/Zba9WqlW655RbfekZGhjIzMxUfH6/4+HhlZmYqMjJSKSkpwRgZAACEoKC+ALgmM2fO1MWLF5Wenq6SkhINGjRIOTk5ioqKCvZoAAAgRDiMMSbYQzQkr9crl8ul0tJSRUdHB3scAPVszc6TNe6TMqhzI0wCoD7V5fd30D9nBgAA4GYQMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKwW1JhZvny5+vbtq+joaEVHRyshIUHvv/++b7sxRvPnz1dMTIxatmypYcOG6dChQ0GcGAAAhJqgxkynTp300ksvaffu3dq9e7fuu+8+JScn+4Jl0aJFysrK0pIlS7Rr1y55PB6NHDlSZWVlwRwbAACEkKDGzJgxYzR69Gh1795d3bt3169+9Su1bt1aO3bskDFG2dnZmjt3rsaPH6/evXtr1apVunDhgtasWRPMsQEAQAgJmdfMXLlyRW+++abOnz+vhIQEFRQUqKioSElJSb59nE6nEhMTlZ+fX+39lJeXy+v1+l0AAEDTFfSYOXjwoFq3bi2n06mpU6dqw4YN6tWrl4qKiiRJbrfbb3+32+3bVpWFCxfK5XL5LrGxsQ06PwAACK6gx0yPHj20f/9+7dixQ//0T/+ktLQ0HT582Lfd4XD47W+MqbR2vTlz5qi0tNR3KSwsbLDZAQBA8IUFe4CIiAh169ZNknT33Xdr165devXVVzVr1ixJUlFRkTp06ODbv7i4uNLZmus5nU45nc6GHRoAAISMgM7MFBQU1PccPsYYlZeXKy4uTh6PR7m5ub5tly5dUl5enoYMGdJgjw8AAOwS0JmZbt266cc//rEmT56sn/70p2rRokVAD/7cc89p1KhRio2NVVlZmd58801t2bJFGzdulMPhUEZGhjIzMxUfH6/4+HhlZmYqMjJSKSkpAT0eAABoegI6M/Pxxx/rzjvv1DPPPCOPx6MpU6boo48+qvP9fPnll0pNTVWPHj00fPhw7dy5Uxs3btTIkSMlSTNnzlRGRobS09N1991369SpU8rJyVFUVFQgYwMAgCbIYYwxgd74u+++03vvvaeVK1fq/fffV3x8vCZPnqzU1FS1a9euPucMmNfrlcvlUmlpqaKjo4M9DoB6tmbnyRr3SRnUuREmAVCf6vL7+6bezRQWFqZx48bpP/7jP/Tyyy/r008/1YwZM9SpUydNmDBBp0+fvpm7BwAAqNFNxczu3buVnp6uDh06KCsrSzNmzNCnn36qTZs26dSpU0pOTq6vOQEAAKoU0AuAs7KytGLFCh09elSjR4/W6tWrNXr0aDVrdrWN4uLi9Pvf/149e/as12EBAAC+L6CYWb58uR5//HFNmjRJHo+nyn06d+6s119//aaGAwAAqElAMZObm6vOnTv7zsRcY4xRYWGhOnfurIiICKWlpdXLkAAAANUJ6DUzt912m86cOVNp/ZtvvlFcXNxNDwUAAFBbAcVMde/mPnfuXMAfoAcAABCIOj3NNH36dElXv/zxhRdeUGRkpG/blStXtHPnTvXv379eBwQAALiROsXMvn37JF09M3Pw4EFFRET4tkVERKhfv36aMWNG/U4IAABwA3WKmc2bN0uSJk2apFdffZVP1AUAAEEX0LuZVqxYUd9zAAAABKTWMTN+/HitXLlS0dHRGj9+/A33Xb9+/U0PBgAAUBu1jhmXyyWHw+H7MwAAQCiodcxc/9QSTzMBAIBQEdDnzFy8eFEXLlzwXT9x4oSys7OVk5NTb4MBAADURkAxk5ycrNWrV0uSzp49q4EDB2rx4sVKTk7W8uXL63VAAACAGwkoZvbu3at77rlHkvT222/L4/HoxIkTWr16tX7zm9/U64AAAAA3ElDMXLhwQVFRUZKknJwcjR8/Xs2aNdPgwYN14sSJeh0QAADgRgKKmW7duundd99VYWGhPvjgAyUlJUmSiouL+SA9AADQqAKKmRdeeEEzZsxQ165dNWjQICUkJEi6epbmzjvvrNcBAQAAbiSgTwD+6U9/qh/96Ec6ffq0+vXr51sfPny4xo0bV2/DAQAA1CSgmJEkj8cjj8fjtzZw4MCbHggAAKAuAoqZ8+fP66WXXtKHH36o4uJiVVRU+G3/7LPP6mU4AACAmgQUM0888YTy8vKUmpqqDh06+L7mAAAAoLEFFDPvv/++/vu//1tDhw6t73kAAADqJKB3M/3gBz9QmzZt6nsWAACAOgsoZv71X/9VL7zwgt/3MwEAAARDQE8zLV68WJ9++qncbre6du2q8PBwv+179+6tl+EAAABqElDMjB07tp7HAAAACExAMTNv3rz6ngMAACAgAb1mRpLOnj2rf/u3f9OcOXP0zTffSLr69NKpU6fqbTgAAICaBHRm5sCBAxoxYoRcLpeOHz+uJ598Um3atNGGDRt04sQJrV69ur7nBAAAqFJAZ2amT5+uiRMn6tixY2rRooVvfdSoUdq6dWu9DQcAAFCTgGJm165dmjJlSqX1jh07qqio6KaHAgAAqK2AYqZFixbyer2V1o8ePap27drd9FAAAAC1FVDMJCcn68UXX9Tly5clSQ6HQydPntTs2bP1k5/8pF4HBAAAuJGAYuaVV17RV199pfbt2+vixYtKTExUt27dFBUVpV/96lf1PSMAAEC1Ano3U3R0tP785z9r8+bN2rNnjyoqKnTXXXdpxIgR9T0fAADADdU5ZioqKrRy5UqtX79ex48fl8PhUFxcnDwej4wxcjgcDTEnAABAler0NJMxRg899JCeeOIJnTp1Sn369NEdd9yhEydOaOLEiRo3blxDzQkAAFClOp2ZWblypbZu3aoPP/xQ9957r9+2TZs2aezYsVq9erUmTJhQr0MCAABUp05nZtauXavnnnuuUshI0n333afZs2frjTfeqLfhAAAAalKnmDlw4IAeeOCBarePGjVKH3/88U0PBQAAUFt1iplvvvlGbre72u1ut1slJSU3PRQAAEBt1Slmrly5orCw6l9m07x5c3333Xc3PRQAAEBt1ekFwMYYTZw4UU6ns8rt5eXl9TIUAABAbdUpZtLS0mrch3cyAQCAxlSnmFmxYkVDzQEAABCQgL6bCQAAIFQQMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALBaUGNm4cKF+uEPf6ioqCi1b99eY8eO1dGjR/32McZo/vz5iomJUcuWLTVs2DAdOnQoSBMDAIBQE9SYycvL01NPPaUdO3YoNzdX3333nZKSknT+/HnfPosWLVJWVpaWLFmiXbt2yePxaOTIkSorKwvi5AAAIFQ4jDEm2ENc89VXX6l9+/bKy8vTj3/8YxljFBMTo4yMDM2aNUuSVF5eLrfbrZdffllTpkyp8T69Xq9cLpdKS0sVHR3d0D8CgEa2ZufJGvdJGdS5ESYBUJ/q8vs7pF4zU1paKklq06aNJKmgoEBFRUVKSkry7eN0OpWYmKj8/PygzAgAAEJLWLAHuMYYo+nTp+tHP/qRevfuLUkqKiqSJLndbr993W63Tpw4UeX9lJeXq7y83Hfd6/U20MQAACAUhMyZmWnTpunAgQNau3ZtpW0Oh8PvujGm0to1CxculMvl8l1iY2MbZF4AABAaQiJmfv7zn+u//uu/tHnzZnXq1Mm37vF4JP3fGZpriouLK52tuWbOnDkqLS31XQoLCxtucAAAEHRBjRljjKZNm6b169dr06ZNiouL89seFxcnj8ej3Nxc39qlS5eUl5enIUOGVHmfTqdT0dHRfhcAANB0BfU1M0899ZTWrFmj//zP/1RUVJTvDIzL5VLLli3lcDiUkZGhzMxMxcfHKz4+XpmZmYqMjFRKSkowRwcAACEiqDGzfPlySdKwYcP81lesWKGJEydKkmbOnKmLFy8qPT1dJSUlGjRokHJychQVFdXI0wIAgFAUUp8z0xD4nBmgaeNzZoCmydrPmQEAAKgrYgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDVghozW7du1ZgxYxQTEyOHw6F3333Xb7sxRvPnz1dMTIxatmypYcOG6dChQ8EZFgAAhKSgxsz58+fVr18/LVmypMrtixYtUlZWlpYsWaJdu3bJ4/Fo5MiRKisra+RJAQBAqAoL5oOPGjVKo0aNqnKbMUbZ2dmaO3euxo8fL0latWqV3G631qxZoylTpjTmqAAAIESF7GtmCgoKVFRUpKSkJN+a0+lUYmKi8vPzq71deXm5vF6v3wUAADRdIRszRUVFkiS32+237na7fduqsnDhQrlcLt8lNja2QecEAADBFbIxc43D4fC7boyptHa9OXPmqLS01HcpLCxs6BEBAEAQBfU1Mzfi8XgkXT1D06FDB996cXFxpbM113M6nXI6nQ0+HwAACA0he2YmLi5OHo9Hubm5vrVLly4pLy9PQ4YMCeJkAAAglAT1zMy5c+f017/+1Xe9oKBA+/fvV5s2bdS5c2dlZGQoMzNT8fHxio+PV2ZmpiIjI5WSkhLEqQEAQCgJaszs3r1b9957r+/69OnTJUlpaWlauXKlZs6cqYsXLyo9PV0lJSUaNGiQcnJyFBUVFayRAQBAiHEYY0ywh2hIXq9XLpdLpaWlio6ODvY4AOrZmp0na9wnZVDnRpgEQH2qy+/vkH3NDAAAQG0QMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALCaFTGzbNkyxcXFqUWLFhowYIC2bdsW7JEAAECICPmYWbdunTIyMjR37lzt27dP99xzj0aNGqWTJ08GezQAABACQj5msrKyNHnyZD3xxBO6/fbblZ2drdjYWC1fvjzYowEAgBAQ0jFz6dIl7dmzR0lJSX7rSUlJys/PD9JUAAAglIQFe4AbOXPmjK5cuSK32+237na7VVRUVOVtysvLVV5e7rteWloqSfJ6vQ03KICguXC+rMZ9+PcP2Ofav1tjTI37hnTMXONwOPyuG2MqrV2zcOFCLViwoNJ6bGxsg8wGIPQ9GewBAASsrKxMLpfrhvuEdMy0bdtWzZs3r3QWpri4uNLZmmvmzJmj6dOn+65XVFTom2++0S233FJtAP0t8Xq9io2NVWFhoaKjo4M9TpPFcW4cHOfGwXFuHBxnf8YYlZWVKSYmpsZ9QzpmIiIiNGDAAOXm5mrcuHG+9dzcXCUnJ1d5G6fTKafT6bf2d3/3dw05ppWio6P5x9IIOM6Ng+PcODjOjYPj/H9qOiNzTUjHjCRNnz5dqampuvvuu5WQkKA//OEPOnnypKZOnRrs0QAAQAgI+Zh55JFH9PXXX+vFF1/U6dOn1bt3b/3xj39Uly5dgj0aAAAIASEfM5KUnp6u9PT0YI/RJDidTs2bN6/SU3GoXxznxsFxbhwc58bBcQ6cw9TmPU8AAAAhKqQ/NA8AAKAmxAwAALAaMQMAAKxGzDRxJSUlSk1NlcvlksvlUmpqqs6ePVvr20+ZMkUOh0PZ2dkNNmNTUNfjfPnyZc2aNUt9+vRRq1atFBMTowkTJuiLL75ovKEtsWzZMsXFxalFixYaMGCAtm3bdsP98/LyNGDAALVo0UK33nqrfve73zXSpHary3Fev369Ro4cqXbt2ik6OloJCQn64IMPGnFae9X17/M1//M//6OwsDD179+/YQe0FDHTxKWkpGj//v3auHGjNm7cqP379ys1NbVWt3333Xe1c+fOWn364t+6uh7nCxcuaO/evfqXf/kX7d27V+vXr9f//u//6qGHHmrEqUPfunXrlJGRoblz52rfvn265557NGrUKJ08ebLK/QsKCjR69Gjdc8892rdvn5577jn94he/0DvvvNPIk9ulrsd569atGjlypP74xz9qz549uvfeezVmzBjt27evkSe3S12P8zWlpaWaMGGChg8f3kiTWsigyTp8+LCRZHbs2OFb2759u5Fk/vKXv9zwtp9//rnp2LGj+eSTT0yXLl3Mr3/96wae1l43c5yv99FHHxlJ5sSJEw0xppUGDhxopk6d6rfWs2dPM3v27Cr3nzlzpunZs6ff2pQpU8zgwYMbbMamoK7HuSq9evUyCxYsqO/RmpRAj/Mjjzxinn/+eTNv3jzTr1+/BpzQXpyZacK2b98ul8ulQYMG+dYGDx4sl8ul/Pz8am9XUVGh1NRUPfvss7rjjjsaY1SrBXqcv6+0tFQOh4Ov3/j/Ll26pD179igpKclvPSkpqdrjun379kr733///dq9e7cuX77cYLPaLJDj/H0VFRUqKytTmzZtGmLEJiHQ47xixQp9+umnmjdvXkOPaDUrPjQPgSkqKlL79u0rrbdv377Sl3de7+WXX1ZYWJh+8YtfNOR4TUagx/l63377rWbPnq2UlBS+k+X/O3PmjK5cuVLpS2Xdbne1x7WoqKjK/b/77judOXNGHTp0aLB5bRXIcf6+xYsX6/z583r44YcbYsQmIZDjfOzYMc2ePVvbtm1TWBi/rm+EMzMWmj9/vhwOxw0vu3fvlqQqvyncGFPtN4jv2bNHr776qlauXPk3/y3jDXmcr3f58mU9+uijqqio0LJly+r957Dd949hTce1qv2rWoe/uh7na9auXav58+dr3bp1VUY9/NX2OF+5ckUpKSlasGCBunfv3ljjWYvUs9C0adP06KOP3nCfrl276sCBA/ryyy8rbfvqq68q/d/BNdu2bVNxcbE6d+7sW7ty5YqeeeYZZWdn6/jx4zc1u00a8jhfc/nyZT388MMqKCjQpk2bOCtznbZt26p58+aV/q+1uLi42uPq8Xiq3D8sLEy33HJLg81qs0CO8zXr1q3T5MmT9dZbb2nEiBENOab16nqcy8rKtHv3bu3bt0/Tpk2TdPXpPGOMwsLClJOTo/vuu69RZrcBMWOhtm3bqm3btjXul5CQoNLSUn300UcaOHCgJGnnzp0qLS3VkCFDqrxNampqpf8o3X///UpNTdWkSZNufniLNORxlv4vZI4dO6bNmzfzy/Z7IiIiNGDAAOXm5mrcuHG+9dzcXCUnJ1d5m4SEBL333nt+azk5Obr77rsVHh7eoPPaKpDjLF09I/P4449r7dq1evDBBxtjVKvV9ThHR0fr4MGDfmvLli3Tpk2b9PbbbysuLq7BZ7ZKEF98jEbwwAMPmL59+5rt27eb7du3mz59+pi///u/99unR48eZv369dXeB+9mqlldj/Ply5fNQw89ZDp16mT2799vTp8+7buUl5cH40cISW+++aYJDw83r7/+ujl8+LDJyMgwrVq1MsePHzfGGDN79myTmprq2/+zzz4zkZGR5p//+Z/N4cOHzeuvv27Cw8PN22+/HawfwQp1Pc5r1qwxYWFhZunSpX5/d8+ePRusH8EKdT3O38e7mapHzDRxX3/9tXnsscdMVFSUiYqKMo899pgpKSnx20eSWbFiRbX3QczUrK7HuaCgwEiq8rJ58+ZGnz+ULV261HTp0sVERESYu+66y+Tl5fm2paWlmcTERL/9t2zZYu68804TERFhunbtapYvX97IE9upLsc5MTGxyr+7aWlpjT+4Zer69/l6xEz1+NZsAABgNd7NBAAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQOgRsePH5fD4dD+/fuDPQoAVELMAH/DJk6cqLFjxwZ7jDrr2rWrsrOz/da2bNmi5ORkdejQQa1atVL//v31xhtvBGdAAI2KmAHQJOTn56tv37565513dODAAT3++OOaMGFCpW/RBtAEBfvLoQA0vLfeesv07t3btGjRwrRp08YMHz7czJgxo9ovudy5c6fp37+/cTqdZsCAAWb9+vVGktm3b1+tHm/Lli3mhz/8oYmIiDAej8fMmjXLXL582bfd6/WalJQUExkZaTwej8nKyjKJiYnm6aefrvG+q/qSw+qMHj3aTJo0yW9t2bJl5tZbbzXh4eGme/fuZvXq1bX6mYy5+mWhv/vd78yDDz5oWrZsaXr27Gny8/PNsWPHTGJioomMjDSDBw82f/3rX2v9mNe+dPT6Y1tSUsKXjgJ1QMwATdwXX3xhwsLCTFZWlikoKDAHDhwwS5cuNWVlZebhhx82DzzwgDl9+rQ5ffq0KS8vN+fOnTPt2rUzjzzyiPnkk0/Me++9Z2699dZax8znn39uIiMjTXp6ujly5IjZsGGDadu2rZk3b55vnyeeeMJ06dLF/OlPfzIHDx4048aNM1FRUbWKma+//tp06tTJvPjii765qzN06FDzzDPP+K6vX7/ehIeHm6VLl5qjR4+axYsXm+bNm5tNmzbV+LjGXI2Zjh07mnXr1pmjR4+asWPHmq5du5r77rvPbNy40Rw+fNgMHjzYPPDAA7V+TGIGuHnEDNDE7dmzx0gyx48fr7QtLS3NJCcn+639/ve/N23atDHnz5/3rS1fvrzWMfPcc8+ZHj16mIqKCt/a0qVLTevWrc2VK1eM1+s14eHh5q233vJtP3v2rImMjKxVzBhjTJcuXcyvf/3rG+7z1ltvmYiICPPJJ5/41oYMGWKefPJJv/1+9rOfmdGjR9fqcSWZ559/3nd9+/btRpJ5/fXXfWtr1641LVq0qPVjEjPAzeM1M0AT169fPw0fPlx9+vTRz372M7322msqKSmpdv8jR46oX79+ioyM9K0lJCTU+vGOHDmihIQEORwO39rQoUN17tw5ff755/rss890+fJlDRw40Lfd5XKpR48edfzJqrdlyxZNnDhRr732mu644w6/2YYOHeq379ChQ3XkyJFa33ffvn19f3a73ZKkPn36+K19++238nq99faYAG6MmAGauObNmys3N1fvv/++evXqpd/+9rfq0aOHCgoKqtzfGHNTj2eM8QuZ6+/T4XD4/bk+H/eavLw8jRkzRllZWZowYUKl7VU97vfXbiQ8PLzSfVW1VlFRUavHbNasmW/tmsuXL9d6HgDEDPA3weFwaOjQoVqwYIH27duniIgIbdiwQREREbpy5Yrfvr169dLHH3+sixcv+tZ27NhR68fq1auX8vPz/X455+fnKyoqSh07dtRtt92m8PBwffTRR77tXq9Xx44dq/VjVDW3dPWMzIMPPqiXXnpJ//iP/1hp++23364///nPfmv5+fm6/fbba/3YdVXTY7Zr106SdPr0ad92Ps8HqJuwYA8AoGHt3LlTH374oZKSktS+fXvt3LlTX331lW6//XZ9++23+uCDD3T06FHdcsstcrlcSklJ0dy5czV58mQ9//zzOn78uF555ZVaP156erqys7P185//XNOmTdPRo0c1b948TZ8+Xc2aNVNUVJTS0tL07LPPqk2bNmrfvr3mzZunZs2a1foMSdeuXbV161Y9+uijcjqdatu2rS9knn76af3kJz9RUVGRpKvh06ZNG0nSs88+q4cfflh33XWXhg8frvfee0/r16/Xn/70p7of2Fqq6TFbtmypwYMH66WXXlLXrl115swZPf/88w02D9AkBe3VOgAaxeHDh839999v2rVrZ5xOp+nevbv57W9/a4wxpri42IwcOdK0bt3a7wWn27dvN/369TMRERGmf//+5p133mnwt2YPHDjQzJ49u1b3v337dtO3b1/jdDp9b81OS0ur9JZtSSYxMdHvtjf71uwNGzb4rlf14t3NmzcbSaakpKTWj3ntXVAtW7Y0/fv3Nzk5ObwAGKgDhzH19EQ1AATo/Pnz6tixoxYvXqzJkycHexwAluFpJgCNbt++ffrLX/6igQMHqrS0VC+++KIkKTk5OciTAbARLwAGUCdTp05V69atq7xMnTq11vfzyiuvqF+/fhoxYoTOnz+vbdu2qW3bttq2bVu199+6desG+7neeOONah/z+rd3Awg9PM0EoE6Ki4t9n6HyfdHR0Wrfvv1N3f/Fixd16tSpard369btpu6/OmVlZfryyy+r3BYeHq4uXbo0yOMCuHnEDAAAsBpPMwEAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACs9v8Anfr2n8RLV1YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the minutes of usage of STD (outside the calling circle) outgoing calls of Operator T to other operator fixed line\n",
    "\n",
    "univariate(churn.std_og_t2o_mou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_oYZd8eod81l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99999.000000\n",
      "mean       -46.218508\n",
      "std        809.660058\n",
      "min      -3655.342939\n",
      "25%          4.090000\n",
      "50%         28.040000\n",
      "75%        106.740000\n",
      "max      10752.560000\n",
      "Name: onnet_mou_8, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the minutes of usage of all kind of calls within the same operator network for the month of August\n",
    "\n",
    "univariate(churn.onnet_mou_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "iuTcpbgwd81l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99999.000000\n",
      "mean       259.155904\n",
      "std        387.977034\n",
      "min          0.000000\n",
      "25%         31.230000\n",
      "50%        101.290000\n",
      "75%        289.895000\n",
      "max      10310.760000\n",
      "Name: offnet_mou_9, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the minutes of usage of all kind of calls outside the operator T network for the month of September\n",
    "\n",
    "univariate(churn.offnet_mou_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWIWHFJpd81l"
   },
   "source": [
    "## Bivariate EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYUT0Vr7JjQj"
   },
   "source": [
    "Now visualize and analyse the relationship between different features in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "riv0S-gvd81l"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the relationship between different variables present in the data set\n",
    "\n",
    "bivariate(churn_filtered.churn, churn_filtered.aon, churn_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above boxplot it can be concluded that there are outliers which need to be capped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrPWcHw-d81m"
   },
   "source": [
    "### Cap outliers in all numeric variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNN_oFqJJtti"
   },
   "source": [
    "Create a function to deal with outliers using the IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Hka8SDhOd81m"
   },
   "outputs": [],
   "source": [
    "# function for capping outliers\n",
    "def cap_outliers(array):\n",
    "\n",
    "    # Get the 75% quantile of the array\n",
    "    q3 = np.percentile(array, 75)\n",
    "    \n",
    "    # Get the 25% quantile of the array\n",
    "    q1 = np.percentile(array, 25)\n",
    "    \n",
    "    # Get the interquartile range (IQR) (q3 - q1)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calculate the upper limit - 75% quartile + 1.5*IQR\n",
    "    upper_limit = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Calculate the lower limit - 25% quartile - 1.5*IQR\n",
    "    lower_limit = q1 - 1.5 * iqr\n",
    "    \n",
    "    # Perform outlier capping\n",
    "    # Set all the values in the array above the upper limit to be equal to the upper limit\n",
    "    array[array > upper_limit] = upper_limit\n",
    "    \n",
    "    # Set all the values in the array below the lower limit to be equal to the lower limit\n",
    "    array[array < lower_limit] = lower_limit\n",
    "\n",
    "   \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByUhk0o_J8qW"
   },
   "source": [
    "The following is an example to help you understand how capping is done to treat outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dJeeN7dNd81m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array after capping outliers: \n",
      " [-49   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98 148]\n"
     ]
    }
   ],
   "source": [
    "# example of capping\n",
    "sample_array = list(range(100))\n",
    "\n",
    "# add outliers to the data\n",
    "sample_array[0] = -9999\n",
    "sample_array[99] = 9999\n",
    "\n",
    "# cap outliers\n",
    "sample_array = np.array(sample_array)\n",
    "print(\"Array after capping outliers: \\n\", cap_outliers(sample_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DxeBxniKKFN"
   },
   "source": [
    "Use the outlier capping function to cap the outliers present in all the numeric columns in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "uT1T-mVEd81m"
   },
   "outputs": [],
   "source": [
    "# cap outliers in all the numeric columns using your outlier capping function\n",
    "churn_filtered[num_cols] = churn_filtered[num_cols].apply(cap_outliers, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuC6kkIOKYzd"
   },
   "source": [
    "**Checklist:**\n",
    "- Created functions to carry out univariate and bivariate analysis of the columns in the data set\n",
    "- Capped outliers by creating a function and applying it on all the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLNDQNUEd81m"
   },
   "source": [
    "# Task 5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHebzvrdQs9z"
   },
   "source": [
    "### Description:\n",
    "In this task, you will train and evaluate predictive models using your prepared dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTAIxBWMd81m"
   },
   "source": [
    "## i) Importing necessary libraries for machine learning and deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "l-io0IBMd81m"
   },
   "outputs": [],
   "source": [
    "#algorithms for sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#baseline linear model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#modules for hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#modules for model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, r2_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "# Import methods for building neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC73FFRid81m"
   },
   "source": [
    "## ii) Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "sVJ6idKud81m"
   },
   "outputs": [],
   "source": [
    "# change churn to numeric\n",
    "churn_filtered['churn'] = pd.to_numeric(churn_filtered['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "NoLvPspud81m"
   },
   "outputs": [],
   "source": [
    "# Extract input and output data\n",
    "X = churn_filtered.drop(\"churn\", axis = 1)\n",
    "y = churn_filtered.churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2gS3MOkRXjQ"
   },
   "source": [
    "Create dummy variables for the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "uPjpQffFvMvJ"
   },
   "outputs": [],
   "source": [
    "# Use dummy variables for categorical variables\n",
    "X = pd.get_dummies(X, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbkDXbbnd81m"
   },
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "g6y3azekd81m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 178)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7501, 178)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7501,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide data into train and test\n",
    "# Note: Set the 'random_state' parameter to '4'\n",
    "# Note: Set the 'test_size' parameter to '0.25'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4, stratify = y)\n",
    "\n",
    "# print shapes of train and test sets\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94Q6uP2tRuhj"
   },
   "source": [
    "**Checkpoint:** You must have obtained 22500 observations in the train set and 7501 observations in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4dv9lxqeL_dE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    13780\n",
       "1     1221\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X.to_numpy()\n",
    "\n",
    "#train-test split using stratified K fold\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X_new,y)\n",
    "\n",
    "for train_index, test_index in skf.split(X_new,y):\n",
    "  X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print('\\n')\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHZ49AfLSUxg"
   },
   "source": [
    "### Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KByoUELzKEaj"
   },
   "source": [
    "Classification tasks often involve datasets with class imbalances, where the number of samples in one class significantly outweighs the other(s). Class imbalance can pose significant challenges to the learning algorithms, as they tend to favor the majority class and struggle to accurately predict the minority class. Data augmentation is one such technique that you have studied earlier, however, in this case study we will be exploring class imbalance techniques as an alternative or complementary approach.\n",
    "\n",
    "While data augmentation has proven to be a valuable tool in addressing class imbalance, recent research highlights the advantages of leveraging class imbalance techniques as a primary approach or in conjunction with augmentation methods. By explicitly addressing the class imbalance issue, these techniques ensure that the learning algorithm better captures the nuances of all classes, resulting in improved classification performance.\n",
    "\n",
    "In this capstone, observe that the dataset is imbalanced. You should get the number of entries with output '1' approximately 1/10th of the number of entries with output '0'. This means that if we run a simple machine learning model, it should already show 90% accuracy.\n",
    "\n",
    "It is the most important for the model to predict which customer will churn as this will decide how their business is performing. We have to create a model that will predict the output '1' accurately. But its corresponding number of entries are very less.\n",
    "\n",
    "Hence, we will be doing some sampling methods to make the data set balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM8MHjnJKu2p"
   },
   "source": [
    "1) **Random Under-Sampling**: This method basically consists of removing data in order to have a more balanced dataset and thus avoiding our models to overfitting.\n",
    "\n",
    "We have seen how imbalanced the data set is. With random under-sampling, we have a sub-sample of our dataframe with a 50/50 ratio with regards to our classes. This means that if there are 1221 '0' class data entries, then there will be 1221 '1' class data entries by removing the rest.\n",
    "\n",
    "Note: The main issue with \"Random Under-Sampling\" is that we run the risk that our classification models will not perform as accurate as we would like to since there is a great deal of information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "3Hpgqwib_0_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    1221\n",
       "1    1221\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random under sampling using imblearn\n",
    "# Use the RandomUnderSampler (RUS) function to produce new X and y from X_train and y_train\n",
    "# Use random_state as 1 for reproducibility\n",
    "\n",
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "y_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7NHvHUCT_1nt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "1    977\n",
       "0    976\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus, test_size=0.2, random_state=42, stratify=y_rus)\n",
    "y_train_rus.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5sjXpfDMrYM"
   },
   "source": [
    "1) **Random Over-Sampling**: This method basically consists of adding data in order to have a more balanced dataset and thus avoiding our models to overfitting.\n",
    "\n",
    "We have seen how imbalanced the data set is. With random over-sampling, we have a sub-sample of our dataframe with a 50/50 ratio with regards to our classes. This means that if there are 13780 '1' class data entries, then there will be 13780 '0' class data entries by removing the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "JH3RugzjCwfE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "1    13780\n",
       "0    13780\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random over sampling with imblearn\n",
    "# Use the RandomOverSampler (ROS) function to produce new X and y from X_train and y_train\n",
    "# Use random_state as 1 for reproducibility\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "y_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "b_lyHu2WCmhM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    11024\n",
       "1    11024\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train Test split\n",
    "X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros, test_size=0.2, stratify=y_ros, random_state=42)\n",
    "y_train_ros.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcfKik7VM7Dv"
   },
   "source": [
    "Now, let's test different machine learning models over the three data sets, namely, the original cleaned data set, the under-sampled data set and the over-sampled data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTWkCTv8E4Qv"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3TTeW1kXbIi"
   },
   "source": [
    "Build a logistic regression model without applying any techniques to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "u0owJrjCsX1o"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=None, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(penalty=None, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty=None, random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.93003</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model Name  Training Score  Testing Score  \\\n",
       "0  Logistic Regression - without balancing        0.940071       0.937133   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0   0.93003   0.686406  0.418033  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the logistic regression model and fit it on the normal X_train and y_train\n",
    "# 'penalty' is set to 'none'\n",
    "# 'solver' is set to 'lbfgs'\n",
    "# 'random_state' is set to 0\n",
    "# 'max_iter' is set to 100\n",
    "# You can change these values or use GridSearchCV to perform hyperparameter tuning to find the optimal performing model\n",
    "model_name = 'Logistic Regression - without balancing'\n",
    "logistic_model = LogisticRegression( penalty = None , solver='lbfgs', random_state=0, max_iter=100)\n",
    "\n",
    "# Fitting the model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred = logistic_model.predict(X_train)\n",
    "y_test_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "log_train_acc = accuracy_score(y_train, y_train_pred)\n",
    "log_test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score = f1_score(y_test, y_test_pred, average = 'weighted')\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "# creating a dataframe to compare the performance of different models\n",
    "model_eval_data = [[model_name, log_train_acc, log_test_acc, f_score, precision, recall]]\n",
    "evaluate_df = pd.DataFrame(model_eval_data, columns=['Model Name', 'Training Score', 'Testing Score',\n",
    "                                        'F1 Score', 'Precision', 'Recall'])\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WggEH7KuXjGD"
   },
   "source": [
    "Train a logistic regression model on a balanced data set achieved through random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "lvz959sUD_vp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=None, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(penalty=None, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty=None, random_state=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # Defining the logistic regression model and fit it on the random under sampled X_train_rus and y_train_rus\n",
    "# 'penalty' is set to 'none'\n",
    "# 'solver' is set to 'lbfgs'\n",
    "# 'random_state' is set to 0\n",
    "# 'max_iter' is set to 100\n",
    "model_name = 'Logistic Regression - Random Undersampling'\n",
    "logistic_model= LogisticRegression( penalty = None ,solver='lbfgs', random_state=0, max_iter=100)\n",
    "\n",
    "# Fitting the model\n",
    "logistic_model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_rus = logistic_model.predict(X_train_rus)\n",
    "y_test_pred_rus = logistic_model.predict(X_test_rus)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "log_train_acc_rus = accuracy_score(y_train_rus, y_train_pred_rus)\n",
    "log_test_acc_rus = accuracy_score(y_test_rus, y_test_pred_rus)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f1_score_rus = f1_score(y_test_rus, y_test_pred_rus, average = 'weighted')\n",
    "precision_rus = precision_score(y_test_rus, y_test_pred_rus)\n",
    "recall_rus = recall_score(y_test_rus, y_test_pred_rus)\n",
    "\n",
    "\n",
    "\n",
    "model_eval_data = [[model_name, log_train_acc_rus, log_test_acc_rus, f1_score_rus, precision_rus, recall_rus]]\n",
    "model_eval_df = pd.DataFrame(model_eval_data, columns=['Model Name', 'Training Score', 'Testing Score', 'F1 Score', 'Precision', 'Recall'])\n",
    "evaluate_df = pd.concat([evaluate_df, model_eval_df], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3zo32thX5Jk"
   },
   "source": [
    "Train a logistic regression model on a balanced dataset achieved through random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "TCv-6xFgEoka"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=None, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(penalty=None, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty=None, random_state=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the logistic regression model and fit it on the random over sampled X_train_ros and y_train_ros\n",
    "# 'penalty' is set to 'none'\n",
    "# 'solver' is set to 'lbfgs'\n",
    "# 'random_state' is set to 0\n",
    "# 'max_iter' is set to 100\n",
    "model_name = 'Logistic Regression - Random Oversampling'\n",
    "\n",
    "logistic_model = LogisticRegression( penalty = None ,solver='lbfgs', random_state=0, max_iter=100)\n",
    "\n",
    "# Fitting the model\n",
    "logistic_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_ros = logistic_model.predict(X_train_ros)\n",
    "y_test_pred_ros = logistic_model.predict(X_test_ros)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "log_train_acc_ros = accuracy_score(y_train_ros, y_train_pred_ros)\n",
    "log_test_acc_ros = accuracy_score(y_test_ros, y_test_pred_ros)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f1_score_ros = f1_score(y_test_ros, y_test_pred_ros, average = 'weighted')\n",
    "precision_ros = precision_score(y_test_ros, y_test_pred_ros)\n",
    "recall_ros = recall_score(y_test_ros, y_test_pred_ros)\n",
    "\n",
    "\n",
    "model_eval_data = [[model_name, log_train_acc_ros, log_test_acc_ros, f1_score_ros, precision_ros, recall_ros]]\n",
    "model_eval_df = pd.DataFrame(model_eval_data, columns=['Model Name', 'Training Score', 'Testing Score', 'F1 Score', 'Precision', 'Recall'])\n",
    "evaluate_df = pd.concat([evaluate_df, model_eval_df], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoQgEN5IE-Rn"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaD-snwsX9Mk"
   },
   "source": [
    "Build a decision tree model without applying any techniques to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "46sqkVkOrk-n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=50, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=50, random_state=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the decision tree model and fit it on the normal X_train and y_train\n",
    "# 'max_depth' is set to 50\n",
    "# 'random_state' is set to 0\n",
    "# You can change these values or use GridSearchCV to perform hyperparameter tuning to find the optimal performing model\n",
    "model_name = 'Decision Tree - without balancing'\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=50, random_state=0)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_tree = decision_tree_model.predict(X_train)\n",
    "y_test_pred_tree = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "tree_train_acc = accuracy_score(y_train, y_train_pred_tree)\n",
    "tree_test_acc = accuracy_score(y_test, y_test_pred_tree)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score = f1_score(y_test, y_test_pred_tree, average = 'weighted')\n",
    "precision = precision_score(y_test, y_test_pred_tree)\n",
    "recall = recall_score(y_test, y_test_pred_tree)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, tree_train_acc, tree_test_acc, f_score, precision, recall]\n",
    "model_eval_dict = {evaluate_df.columns[i]: model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJP0sJDNYCHe"
   },
   "source": [
    "Train a decision tree model on a balanced dataset achieved through random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "v71WidfMFwob"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=50, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=50, random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "4        Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  \n",
       "4  0.773000   0.769231  0.778689  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the decision tree model and fit it on the random under sampled X_train_rus and y_train_rus\n",
    "# 'max_depth' is set to 50\n",
    "# 'random_state' is set to 0\n",
    "model_name = 'Decision Tree - Random Undersampling'\n",
    "decision_tree_model= DecisionTreeClassifier(max_depth=50, random_state=0)\n",
    "decision_tree_model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_tree_rus = decision_tree_model.predict(X_train_rus)\n",
    "y_test_pred_tree_rus = decision_tree_model.predict(X_test_rus)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "tree_train_acc_rus = accuracy_score(y_train_rus, y_train_pred_tree_rus)\n",
    "tree_test_acc_rus = accuracy_score(y_test_rus, y_test_pred_tree_rus)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score_rus = f1_score(y_test_rus, y_test_pred_tree_rus, average = 'weighted')\n",
    "precision_rus = precision_score(y_test_rus, y_test_pred_tree_rus)\n",
    "recall_rus = recall_score(y_test_rus, y_test_pred_tree_rus)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, tree_train_acc_rus, tree_test_acc_rus, f_score_rus, precision_rus, recall_rus]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgTmdfUmYJHg"
   },
   "source": [
    "Train a decision tree model on a balanced dataset achieved through random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ZYzQ7QSGFw9j"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=50, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=50, random_state=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "4        Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5         Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  \n",
       "4  0.773000   0.769231  0.778689  \n",
       "5  0.973494   0.949690  1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the decision tree model and fit it on the random over sampled X_train_ros and y_train_ros\n",
    "# 'max_depth' is set to 50\n",
    "# 'random_state' is set to 0\n",
    "model_name = 'Decision Tree - Random Oversampling'\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=50, random_state=0)\n",
    "decision_tree_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_tree_ros = decision_tree_model.predict(X_train_ros)\n",
    "y_test_pred_tree_ros = decision_tree_model.predict(X_test_ros)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "tree_train_acc_ros = accuracy_score(y_train_ros, y_train_pred_tree_ros)\n",
    "tree_test_acc_ros = accuracy_score(y_test_ros, y_test_pred_tree_ros)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score_ros = f1_score(y_test_ros, y_test_pred_tree_ros, average = 'weighted')\n",
    "precision_ros = precision_score(y_test_ros, y_test_pred_tree_ros)\n",
    "recall_ros = recall_score(y_test_ros, y_test_pred_tree_ros)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, tree_train_acc_rus, tree_test_acc_ros, f_score_ros, precision_ros, recall_ros]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh_R_oUOFBie"
   },
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ao2yNA5YLPt"
   },
   "source": [
    "Build a KNN model without applying any techniques to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "LcsoLa3frlZ_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=14)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=14)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=14)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "4        Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5         Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "6                     kNN - without balancing        0.936338       0.932867   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  \n",
       "4  0.773000   0.769231  0.778689  \n",
       "5  0.973494   0.949690  1.000000  \n",
       "6  0.918666   0.730022  0.277049  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the kNN model and fit it on the normal X_train and y_train\n",
    "# 'n_neighbors' is set to 14\n",
    "# You can change these values or use GridSearchCV to perform hyperparameter tuning to find the optimal performing model\n",
    "model_name = 'kNN - without balancing'\n",
    "knn_model = KNeighborsClassifier(n_neighbors=14)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_knn = knn_model.predict(X_train)\n",
    "y_test_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "knn_train_acc = accuracy_score(y_train, y_train_pred_knn)\n",
    "knn_test_acc = accuracy_score(y_test, y_test_pred_knn)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score = f1_score(y_test, y_test_pred_knn, average = 'weighted')\n",
    "precision = precision_score(y_test, y_test_pred_knn)\n",
    "recall = recall_score(y_test, y_test_pred_knn)\n",
    "\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, knn_train_acc, knn_test_acc, f_score, precision, recall]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W84kN63MZdSt"
   },
   "source": [
    "Train a KNN model on a balanced dataset achieved through random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "rQeM6F8WGsUH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=14)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=14)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN - Random Undersampling</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.741803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "4        Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5         Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "6                     kNN - without balancing        0.936338       0.932867   \n",
       "7                  kNN - Random Undersampling        0.826421       0.809816   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  \n",
       "4  0.773000   0.769231  0.778689  \n",
       "5  0.973494   0.949690  1.000000  \n",
       "6  0.918666   0.730022  0.277049  \n",
       "7  0.808919   0.857820  0.741803  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the kNN model and fit it on the random under sampled X_train_rus and y_train_rus\n",
    "# 'n_neighbors' is set to 14\n",
    "model_name = 'kNN - Random Undersampling'\n",
    "knn_model = KNeighborsClassifier(n_neighbors=14)\n",
    "knn_model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_knn_rus = knn_model.predict(X_train_rus)\n",
    "y_test_pred_knn_rus = knn_model.predict(X_test_rus)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "knn_train_acc_rus = accuracy_score(y_train_rus, y_train_pred_knn_rus)\n",
    "knn_test_acc_rus = accuracy_score(y_test_rus, y_test_pred_knn_rus)\n",
    "\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score_rus = f1_score(y_test_rus, y_test_pred_knn_rus, average = 'weighted')\n",
    "precision_rus = precision_score(y_test_rus, y_test_pred_knn_rus)\n",
    "recall_rus = recall_score(y_test_rus, y_test_pred_knn_rus)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, knn_train_acc_rus, knn_test_acc_rus, f_score_rus, precision_rus, recall_rus]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K05hPfrXZlmf"
   },
   "source": [
    "Train a KNN model on a balanced dataset achieved through random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "zr7T95KCG2wV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=14)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=14)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=14)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN - Random Undersampling</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.741803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN - Random Oversampling</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.877903</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.844070</td>\n",
       "      <td>0.927068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "4        Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5         Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "6                     kNN - without balancing        0.936338       0.932867   \n",
       "7                  kNN - Random Undersampling        0.826421       0.809816   \n",
       "8                   kNN - Random Oversampling        0.895682       0.877903   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  \n",
       "4  0.773000   0.769231  0.778689  \n",
       "5  0.973494   0.949690  1.000000  \n",
       "6  0.918666   0.730022  0.277049  \n",
       "7  0.808919   0.857820  0.741803  \n",
       "8  0.877607   0.844070  0.927068  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the kNN model and fit it on the random over sampled X_train_ros and y_train_ros\n",
    "# 'n_neighbors' is set to 14\n",
    "model_name = 'kNN - Random Oversampling'\n",
    "knn_model = KNeighborsClassifier(n_neighbors=14)\n",
    "knn_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_knn_ros = knn_model.predict(X_train_ros)\n",
    "y_test_pred_knn_ros = knn_model.predict(X_test_ros)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "knn_train_acc_ros = accuracy_score(y_train_ros, y_train_pred_knn_ros)\n",
    "knn_test_acc_ros = accuracy_score(y_test_ros, y_test_pred_knn_ros)\n",
    "\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score_ros = f1_score(y_test_ros, y_test_pred_knn_ros, average = 'weighted')\n",
    "precision_ros = precision_score(y_test_ros, y_test_pred_knn_ros)\n",
    "recall_ros = recall_score(y_test_ros, y_test_pred_knn_ros)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, knn_train_acc_ros, knn_test_acc_ros, f_score_ros, precision_ros, recall_ros]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx4zM-tJFEkR"
   },
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpr5Gf8WZ4Lu"
   },
   "source": [
    "Build a random forest model without applying any techniques to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "zxXdLPWl3z0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=200,\n",
       "                       random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=200,\n",
       "                       random_state=123)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=200,\n",
       "                       random_state=123)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN - Random Undersampling</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.741803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN - Random Oversampling</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.877903</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.844070</td>\n",
       "      <td>0.927068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest - without balancing</td>\n",
       "      <td>0.911339</td>\n",
       "      <td>0.898467</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.428165</td>\n",
       "      <td>0.740164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name  Training Score  Testing Score  \\\n",
       "0     Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1  Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2   Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3           Decision Tree - without balancing        1.000000       0.908867   \n",
       "4        Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5         Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "6                     kNN - without balancing        0.936338       0.932867   \n",
       "7                  kNN - Random Undersampling        0.826421       0.809816   \n",
       "8                   kNN - Random Oversampling        0.895682       0.877903   \n",
       "9           Random Forest - without balancing        0.911339       0.898467   \n",
       "\n",
       "   F1 Score  Precision    Recall  \n",
       "0  0.930030   0.686406  0.418033  \n",
       "1  0.838442   0.834008  0.844262  \n",
       "2  0.844884   0.844259  0.845791  \n",
       "3  0.912170   0.448709  0.527049  \n",
       "4  0.773000   0.769231  0.778689  \n",
       "5  0.973494   0.949690  1.000000  \n",
       "6  0.918666   0.730022  0.277049  \n",
       "7  0.808919   0.857820  0.741803  \n",
       "8  0.877607   0.844070  0.927068  \n",
       "9  0.910332   0.428165  0.740164  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the Random Forest Classifier model and fit it on the normal X_train and y_train\n",
    "# 'n_estimators' is set to 200\n",
    "# 'max_depth' is set to 5\n",
    "# 'class_weight' is set to 'balanced'\n",
    "# 'random_state' is set to 123\n",
    "# You can change these values or use GridSearchCV to perform hyperparameter tuning to find the optimal performing model\n",
    "model_name = 'Random Forest - without balancing'\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=5, class_weight='balanced', random_state=123)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "rf_train_acc = accuracy_score(y_train, y_train_pred_rf)\n",
    "rf_test_acc = accuracy_score(y_test, y_test_pred_rf)\n",
    "\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score = f1_score(y_test, y_test_pred_rf, average = 'weighted')\n",
    "precision = precision_score(y_test, y_test_pred_rf)\n",
    "recall = recall_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, rf_train_acc, rf_test_acc, f_score, precision, recall]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBKoN5J0ZxvI"
   },
   "source": [
    "Train a random forest model on a balanced dataset achieved through random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "lNBgzLvEHqgs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=200,\n",
       "                       random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=200,\n",
       "                       random_state=123)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=200,\n",
       "                       random_state=123)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN - Random Undersampling</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.741803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN - Random Oversampling</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.877903</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.844070</td>\n",
       "      <td>0.927068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest - without balancing</td>\n",
       "      <td>0.911339</td>\n",
       "      <td>0.898467</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.428165</td>\n",
       "      <td>0.740164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest - Random Undersampling</td>\n",
       "      <td>0.876088</td>\n",
       "      <td>0.852761</td>\n",
       "      <td>0.852108</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.786885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model Name  Training Score  Testing Score  \\\n",
       "0      Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1   Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2    Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3            Decision Tree - without balancing        1.000000       0.908867   \n",
       "4         Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5          Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "6                      kNN - without balancing        0.936338       0.932867   \n",
       "7                   kNN - Random Undersampling        0.826421       0.809816   \n",
       "8                    kNN - Random Oversampling        0.895682       0.877903   \n",
       "9            Random Forest - without balancing        0.911339       0.898467   \n",
       "10        Random Forest - Random Undersampling        0.876088       0.852761   \n",
       "\n",
       "    F1 Score  Precision    Recall  \n",
       "0   0.930030   0.686406  0.418033  \n",
       "1   0.838442   0.834008  0.844262  \n",
       "2   0.844884   0.844259  0.845791  \n",
       "3   0.912170   0.448709  0.527049  \n",
       "4   0.773000   0.769231  0.778689  \n",
       "5   0.973494   0.949690  1.000000  \n",
       "6   0.918666   0.730022  0.277049  \n",
       "7   0.808919   0.857820  0.741803  \n",
       "8   0.877607   0.844070  0.927068  \n",
       "9   0.910332   0.428165  0.740164  \n",
       "10  0.852108   0.905660  0.786885  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the Random Forest Classifier model and fit it on the random under sampled X_train_rus and y_train_rus\n",
    "# 'n_estimators' is set to 200\n",
    "# 'max_depth' is set to 5\n",
    "# 'class_weight' is set to 'balanced'\n",
    "# 'random_state' is set to 123\n",
    "model_name = 'Random Forest - Random Undersampling'\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=5, class_weight='balanced', random_state=123)\n",
    "rf_model.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_rf_rus = rf_model.predict(X_train_rus)\n",
    "y_test_pred_rf_rus = rf_model.predict(X_test_rus)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "rf_train_acc_rus = accuracy_score(y_train_rus, y_train_pred_rf_rus)\n",
    "rf_test_acc_rus = accuracy_score(y_test_rus, y_test_pred_rf_rus)\n",
    "\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score_rus = f1_score(y_test_rus, y_test_pred_rf_rus, average = 'weighted')\n",
    "precision_rus = precision_score(y_test_rus, y_test_pred_rf_rus)\n",
    "recall_rus = recall_score(y_test_rus, y_test_pred_rf_rus)\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, rf_train_acc_rus, rf_test_acc_rus, f_score_rus, precision_rus, recall_rus]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ61ESz0ZrKo"
   },
   "source": [
    "Train a random forest model on a balanced dataset achieved through random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "fbQVjASQHq-o"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=200,\n",
       "                       random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, n_estimators=200,\n",
       "                       random_state=123)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=200,\n",
       "                       random_state=123)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN - Random Undersampling</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.741803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN - Random Oversampling</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.877903</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.844070</td>\n",
       "      <td>0.927068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest - without balancing</td>\n",
       "      <td>0.911339</td>\n",
       "      <td>0.898467</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.428165</td>\n",
       "      <td>0.740164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest - Random Undersampling</td>\n",
       "      <td>0.876088</td>\n",
       "      <td>0.852761</td>\n",
       "      <td>0.852108</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.786885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest - Random Oversampling</td>\n",
       "      <td>0.868197</td>\n",
       "      <td>0.868106</td>\n",
       "      <td>0.867819</td>\n",
       "      <td>0.905962</td>\n",
       "      <td>0.821480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model Name  Training Score  Testing Score  \\\n",
       "0      Logistic Regression - without balancing        0.940071       0.937133   \n",
       "1   Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "2    Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "3            Decision Tree - without balancing        1.000000       0.908867   \n",
       "4         Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "5          Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "6                      kNN - without balancing        0.936338       0.932867   \n",
       "7                   kNN - Random Undersampling        0.826421       0.809816   \n",
       "8                    kNN - Random Oversampling        0.895682       0.877903   \n",
       "9            Random Forest - without balancing        0.911339       0.898467   \n",
       "10        Random Forest - Random Undersampling        0.876088       0.852761   \n",
       "11         Random Forest - Random Oversampling        0.868197       0.868106   \n",
       "\n",
       "    F1 Score  Precision    Recall  \n",
       "0   0.930030   0.686406  0.418033  \n",
       "1   0.838442   0.834008  0.844262  \n",
       "2   0.844884   0.844259  0.845791  \n",
       "3   0.912170   0.448709  0.527049  \n",
       "4   0.773000   0.769231  0.778689  \n",
       "5   0.973494   0.949690  1.000000  \n",
       "6   0.918666   0.730022  0.277049  \n",
       "7   0.808919   0.857820  0.741803  \n",
       "8   0.877607   0.844070  0.927068  \n",
       "9   0.910332   0.428165  0.740164  \n",
       "10  0.852108   0.905660  0.786885  \n",
       "11  0.867819   0.905962  0.821480  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the Random Forest Classifier model and fit it on the random over sampled X_train_ros and y_train_ros\n",
    "# 'n_estimators' is set to 200\n",
    "# 'max_depth' is set to 5\n",
    "# 'class_weight' is set to 'balanced'\n",
    "# 'random_state' is set to 123\n",
    "model_name = 'Random Forest - Random Oversampling'\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=5, class_weight='balanced', random_state=123)\n",
    "rf_model.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predicting on training and validation sets\n",
    "y_train_pred_rf_ros = rf_model.predict(X_train_ros)\n",
    "y_test_pred_rf_ros = rf_model.predict(X_test_ros)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "rf_train_acc_ros = accuracy_score(y_train_ros, y_train_pred_rf_ros)\n",
    "rf_test_acc_ros = accuracy_score(y_test_ros, y_test_pred_rf_ros)\n",
    "\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "f_score_ros = f1_score(y_test_ros, y_test_pred_rf_ros, average = 'weighted')\n",
    "precision_ros = precision_score(y_test_ros, y_test_pred_rf_ros)\n",
    "recall_ros = recall_score(y_test_ros, y_test_pred_rf_ros)\n",
    "\n",
    "\n",
    "# adding calculations to dataframe\n",
    "model_eval_data = [model_name, rf_train_acc_ros, rf_test_acc_ros, f_score_ros, precision_ros, recall_ros]\n",
    "model_eval_dict = {evaluate_df.columns[i]:model_eval_data[i] for i in range(len(model_eval_data))}\n",
    "evaluate_df = pd.concat([evaluate_df, pd.DataFrame([model_eval_dict])], ignore_index=True)\n",
    "\n",
    "# Display the evaluation DataFrame\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2alt53XWaGnB"
   },
   "source": [
    "Compare the performances of the different predictive models that you built above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_sorted = evaluate_df.sort_values(by=['Recall', 'Precision', 'Testing Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "JuRWiDJTIHc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN - Random Oversampling</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.877903</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.844070</td>\n",
       "      <td>0.927068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression - Random Oversampling</td>\n",
       "      <td>0.837310</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.844259</td>\n",
       "      <td>0.845791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - Random Undersampling</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.844262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest - Random Oversampling</td>\n",
       "      <td>0.868197</td>\n",
       "      <td>0.868106</td>\n",
       "      <td>0.867819</td>\n",
       "      <td>0.905962</td>\n",
       "      <td>0.821480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest - Random Undersampling</td>\n",
       "      <td>0.876088</td>\n",
       "      <td>0.852761</td>\n",
       "      <td>0.852108</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.786885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree - Random Undersampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN - Random Undersampling</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.741803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest - without balancing</td>\n",
       "      <td>0.911339</td>\n",
       "      <td>0.898467</td>\n",
       "      <td>0.910332</td>\n",
       "      <td>0.428165</td>\n",
       "      <td>0.740164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - without balancing</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.527049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression - without balancing</td>\n",
       "      <td>0.940071</td>\n",
       "      <td>0.937133</td>\n",
       "      <td>0.930030</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.418033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN - without balancing</td>\n",
       "      <td>0.936338</td>\n",
       "      <td>0.932867</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.730022</td>\n",
       "      <td>0.277049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model Name  Training Score  Testing Score  \\\n",
       "5          Decision Tree - Random Oversampling        1.000000       0.973512   \n",
       "8                    kNN - Random Oversampling        0.895682       0.877903   \n",
       "2    Logistic Regression - Random Oversampling        0.837310       0.844884   \n",
       "1   Logistic Regression - Random Undersampling        0.840758       0.838446   \n",
       "11         Random Forest - Random Oversampling        0.868197       0.868106   \n",
       "10        Random Forest - Random Undersampling        0.876088       0.852761   \n",
       "4         Decision Tree - Random Undersampling        1.000000       0.773006   \n",
       "7                   kNN - Random Undersampling        0.826421       0.809816   \n",
       "9            Random Forest - without balancing        0.911339       0.898467   \n",
       "3            Decision Tree - without balancing        1.000000       0.908867   \n",
       "0      Logistic Regression - without balancing        0.940071       0.937133   \n",
       "6                      kNN - without balancing        0.936338       0.932867   \n",
       "\n",
       "    F1 Score  Precision    Recall  \n",
       "5   0.973494   0.949690  1.000000  \n",
       "8   0.877607   0.844070  0.927068  \n",
       "2   0.844884   0.844259  0.845791  \n",
       "1   0.838442   0.834008  0.844262  \n",
       "11  0.867819   0.905962  0.821480  \n",
       "10  0.852108   0.905660  0.786885  \n",
       "4   0.773000   0.769231  0.778689  \n",
       "7   0.808919   0.857820  0.741803  \n",
       "9   0.910332   0.428165  0.740164  \n",
       "3   0.912170   0.448709  0.527049  \n",
       "0   0.930030   0.686406  0.418033  \n",
       "6   0.918666   0.730022  0.277049  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = evaluate_df_sorted.iloc[0].values[0]\n",
    "best_model_precision = evaluate_df_sorted.iloc[0].values[-2]\n",
    "best_model_recall = evaluate_df_sorted.iloc[0].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model `Decision Tree - Random Oversampling` has best parameters for solving Type 2 problem.\n",
      "\n",
      "Parameters of the model are:\n",
      "\n",
      "---------------------------------------\n",
      "Precision: 94.97\n",
      "Recall: 100.00\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model `{best_model_name}` has best parameters for solving Type 2 problem.\\n\")\n",
    "print(f\"Parameters of the model are:\\n\")\n",
    "print(f\"---------------------------------------\")\n",
    "print(f\"Precision: {best_model_precision*100:.2f}\")\n",
    "print(f\"Recall: {best_model_recall*100:.2f}\")\n",
    "print(f\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHf4ErJAwNtC"
   },
   "source": [
    "In this case study, the most important factor in the prediction performance of a machine learning model is that it should be able to predict the positive class as accurately as possible. This means that the false negatives and false positives are supposed to be as minimal as possible. This further means that precision and recall should be as high as possible.\n",
    "\n",
    "There is another factor to consider. The most important factor which can lead to a company loss is the false negatives. This is because if we predict that a customer did not churn but in reality, the customer did, the company will miss out on the data of churned customers. Hence, observing the recall factor is much more important than precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YI4KLGtIQZc"
   },
   "source": [
    "## Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdiNcSWjdjjv"
   },
   "source": [
    "Choose the model that performs in a robust manner with good accuracy, precision and recall. Especially look out for the recall value because a good recall value means that it is able to accurately classify the data examples of the customers who churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "MLnOBgQ180S7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters found:  {'max_depth': 30}\n"
     ]
    }
   ],
   "source": [
    "# Define your model and parameter grid\n",
    "# Make sure to use random_state value as 0\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "# Define the parameter grid\n",
    "param_grid = {'max_depth': np.arange(5,105, 5)} # Parameter range\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', return_train_score = True , verbose=1)\n",
    "grid_search = grid.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "\n",
    "# Display the best combination of parameters obtained from GridSearchCV\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O8giBEXeV5_"
   },
   "source": [
    "Retrain your model on the combination of parameters obtained from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "9gmbyuJIl8kB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-15 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-15 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-15 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-15 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-15 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-15 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=30, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=30, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=30, random_state=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9981857764876633\n",
      "Testing  Accuracy: 0.9735123367198839\n",
      "Test F1 Score: 0.9734937400257991\n",
      "Test Precision: 0.9496898690558235\n",
      "Test Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Re-fit your model with the combination of parameters obtained from GridSearchCV\n",
    "# Make sure to use random_state value as 0\n",
    "# Retrieve the best parameters\n",
    "best_params_ = 30 # Found while performing GridSearchCv\n",
    "\n",
    "# Refit the model with the best parameters\n",
    "best_model = DecisionTreeClassifier( max_depth = best_params_, random_state = 0)\n",
    "best_model.fit(X_train_ros, y_train_ros)\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "# Predict on training and validation sets\n",
    "y_train_predd = best_model.predict(X_train_ros)\n",
    "y_test_predd = best_model.predict(X_test_ros)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_ros, y_train_predd)\n",
    "test_accuracy = accuracy_score(y_test_ros, y_test_predd)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "test_f1 = f1_score(y_test_ros, y_test_predd, average = 'weighted')\n",
    "test_precision = precision_score(y_test_ros, y_test_predd)\n",
    "test_recall = recall_score(y_test_ros, y_test_predd)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing  Accuracy: {test_accuracy}\")\n",
    "print(f\"Test F1 Score: {test_f1}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "qvpby7ZAe4A3"
   },
   "outputs": [],
   "source": [
    "# Find the importance of all the features according to the optimal model defined above\n",
    "feature_importances = best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMuxE4C1K3zC"
   },
   "source": [
    "Create a dataframe with the feature importance in descending order so that the highest important features are shown at the start of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the feature importance in descending order\n",
    "X_train_ros_df = pd.DataFrame(X_train_ros)\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_ros_df.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "eWSbwbYxfI1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  Importance\n",
      "89        89    0.374411\n",
      "152      152    0.060182\n",
      "119      119    0.041411\n",
      "110      110    0.027337\n",
      "32        32    0.017973\n",
      "158      158    0.016240\n",
      "157      157    0.014985\n",
      "65        65    0.014406\n",
      "153      153    0.011655\n",
      "87        87    0.011565\n",
      "149      149    0.011506\n",
      "122      122    0.011258\n",
      "11        11    0.010608\n",
      "143      143    0.010593\n",
      "138      138    0.009760\n",
      "77        77    0.009660\n",
      "3          3    0.009481\n",
      "102      102    0.009060\n",
      "160      160    0.009047\n",
      "4          4    0.008762\n",
      "20        20    0.008417\n",
      "103      103    0.007847\n",
      "86        86    0.007826\n",
      "10        10    0.007679\n",
      "62        62    0.007619\n",
      "88        88    0.007566\n",
      "163      163    0.007534\n",
      "144      144    0.006925\n",
      "60        60    0.006844\n",
      "125      125    0.006801\n",
      "71        71    0.006375\n",
      "99        99    0.006214\n",
      "75        75    0.006181\n",
      "145      145    0.006030\n",
      "159      159    0.005734\n",
      "105      105    0.005656\n",
      "70        70    0.005234\n",
      "164      164    0.005208\n",
      "63        63    0.005135\n",
      "85        85    0.005107\n",
      "61        61    0.005078\n",
      "118      118    0.005066\n",
      "30        30    0.004957\n",
      "21        21    0.004834\n",
      "51        51    0.004829\n",
      "148      148    0.004795\n",
      "5          5    0.004680\n",
      "45        45    0.004385\n",
      "101      101    0.004327\n",
      "151      151    0.004270\n",
      "100      100    0.004250\n",
      "6          6    0.004197\n",
      "141      141    0.004192\n",
      "76        76    0.003757\n",
      "59        59    0.003751\n",
      "154      154    0.003690\n",
      "64        64    0.003662\n",
      "117      117    0.003541\n",
      "47        47    0.003525\n",
      "69        69    0.003515\n",
      "113      113    0.003486\n",
      "23        23    0.003429\n",
      "26        26    0.003385\n",
      "24        24    0.003257\n",
      "31        31    0.003246\n",
      "52        52    0.003208\n",
      "72        72    0.003042\n",
      "104      104    0.003021\n",
      "115      115    0.002903\n",
      "58        58    0.002693\n",
      "8          8    0.002618\n",
      "37        37    0.002592\n",
      "36        36    0.002571\n",
      "140      140    0.002545\n",
      "33        33    0.002522\n",
      "80        80    0.002400\n",
      "68        68    0.002361\n",
      "19        19    0.002285\n",
      "9          9    0.002252\n",
      "78        78    0.002245\n",
      "73        73    0.002239\n",
      "114      114    0.002161\n",
      "107      107    0.002037\n",
      "53        53    0.001938\n",
      "108      108    0.001926\n",
      "109      109    0.001883\n",
      "22        22    0.001881\n",
      "66        66    0.001833\n",
      "174      174    0.001648\n",
      "35        35    0.001560\n",
      "129      129    0.001557\n",
      "169      169    0.001173\n",
      "106      106    0.001106\n",
      "172      172    0.001040\n",
      "177      177    0.001030\n",
      "97        97    0.000993\n",
      "46        46    0.000956\n",
      "38        38    0.000956\n",
      "96        96    0.000946\n",
      "18        18    0.000909\n",
      "98        98    0.000899\n",
      "124      124    0.000660\n",
      "121      121    0.000646\n",
      "165      165    0.000643\n",
      "161      161    0.000629\n",
      "111      111    0.000499\n",
      "7          7    0.000492\n",
      "139      139    0.000444\n",
      "74        74    0.000364\n",
      "79        79    0.000339\n",
      "123      123    0.000322\n",
      "112      112    0.000292\n",
      "57        57    0.000261\n",
      "162      162    0.000177\n",
      "84        84    0.000172\n",
      "167      167    0.000165\n",
      "34        34    0.000033\n",
      "28        28    0.000000\n",
      "29        29    0.000000\n",
      "27        27    0.000000\n",
      "25        25    0.000000\n",
      "155      155    0.000000\n",
      "150      150    0.000000\n",
      "147      147    0.000000\n",
      "146      146    0.000000\n",
      "156      156    0.000000\n",
      "95        95    0.000000\n",
      "17        17    0.000000\n",
      "16        16    0.000000\n",
      "15        15    0.000000\n",
      "40        40    0.000000\n",
      "14        14    0.000000\n",
      "13        13    0.000000\n",
      "166      166    0.000000\n",
      "168      168    0.000000\n",
      "12        12    0.000000\n",
      "170      170    0.000000\n",
      "171      171    0.000000\n",
      "173      173    0.000000\n",
      "2          2    0.000000\n",
      "175      175    0.000000\n",
      "176      176    0.000000\n",
      "39        39    0.000000\n",
      "136      136    0.000000\n",
      "41        41    0.000000\n",
      "82        82    0.000000\n",
      "54        54    0.000000\n",
      "55        55    0.000000\n",
      "116      116    0.000000\n",
      "56        56    0.000000\n",
      "67        67    0.000000\n",
      "81        81    0.000000\n",
      "83        83    0.000000\n",
      "142      142    0.000000\n",
      "1          1    0.000000\n",
      "90        90    0.000000\n",
      "91        91    0.000000\n",
      "92        92    0.000000\n",
      "93        93    0.000000\n",
      "94        94    0.000000\n",
      "50        50    0.000000\n",
      "120      120    0.000000\n",
      "49        49    0.000000\n",
      "48        48    0.000000\n",
      "126      126    0.000000\n",
      "127      127    0.000000\n",
      "128      128    0.000000\n",
      "130      130    0.000000\n",
      "131      131    0.000000\n",
      "132      132    0.000000\n",
      "133      133    0.000000\n",
      "134      134    0.000000\n",
      "135      135    0.000000\n",
      "137      137    0.000000\n",
      "44        44    0.000000\n",
      "43        43    0.000000\n",
      "42        42    0.000000\n",
      "0          0    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Display the dataframe obtained\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_ic_mou_8           0.374411\n",
       "total_og_mou_diff        0.060182\n",
       "av_rech_amt_data_8       0.041411\n",
       "last_day_rch_amt_8       0.027337\n",
       "loc_og_mou_8             0.017973\n",
       "total_rech_num_diff      0.016240\n",
       "total_ic_mou_diff        0.014985\n",
       "loc_ic_t2m_mou_8         0.014406\n",
       "loc_ic_mou_diff          0.011655\n",
       "total_ic_mou_6           0.011565\n",
       "std_og_mou_diff          0.011506\n",
       "vol_2g_mb_8              0.011258\n",
       "offnet_mou_8             0.010608\n",
       "arpu_diff                0.010593\n",
       "aon                      0.009760\n",
       "std_ic_t2m_mou_8         0.009660\n",
       "arpu_6                   0.009481\n",
       "total_rech_amt_6         0.009060\n",
       "max_rech_amt_diff        0.009047\n",
       "arpu_7                   0.008762\n",
       "loc_og_t2t_mou_8         0.008417\n",
       "total_rech_amt_7         0.007847\n",
       "std_ic_mou_8             0.007826\n",
       "offnet_mou_7             0.007679\n",
       "loc_ic_t2t_mou_8         0.007619\n",
       "total_ic_mou_7           0.007566\n",
       "av_rech_amt_data_diff    0.007534\n",
       "onnet_mou_diff           0.006925\n",
       "loc_ic_t2t_mou_6         0.006844\n",
       "vol_3g_mb_8              0.006801\n",
       "loc_ic_mou_8             0.006375\n",
       "total_rech_num_6         0.006214\n",
       "std_ic_t2m_mou_6         0.006181\n",
       "offnet_mou_diff          0.006030\n",
       "total_rech_amt_diff      0.005734\n",
       "max_rech_amt_6           0.005656\n",
       "loc_ic_mou_7             0.005234\n",
       "vol_2g_mb_diff           0.005208\n",
       "loc_ic_t2m_mou_6         0.005135\n",
       "std_ic_mou_7             0.005107\n",
       "loc_ic_t2t_mou_7         0.005078\n",
       "av_rech_amt_data_7       0.005066\n",
       "loc_og_mou_6             0.004957\n",
       "loc_og_t2m_mou_6         0.004834\n",
       "spl_og_mou_6             0.004829\n",
       "loc_og_mou_diff          0.004795\n",
       "arpu_8                   0.004680\n",
       "std_og_mou_6             0.004385\n",
       "total_rech_num_8         0.004327\n",
       "spl_og_mou_diff          0.004270\n",
       "total_rech_num_7         0.004250\n",
       "onnet_mou_6              0.004197\n",
       "jun_vbc_3g               0.004192\n",
       "std_ic_t2m_mou_7         0.003757\n",
       "total_og_mou_8           0.003751\n",
       "std_ic_mou_diff          0.003690\n",
       "loc_ic_t2m_mou_7         0.003662\n",
       "av_rech_amt_data_6       0.003541\n",
       "std_og_mou_8             0.003525\n",
       "loc_ic_mou_6             0.003515\n",
       "total_rech_data_8        0.003486\n",
       "loc_og_t2m_mou_8         0.003429\n",
       "loc_og_t2f_mou_8         0.003385\n",
       "loc_og_t2f_mou_6         0.003257\n",
       "loc_og_mou_7             0.003246\n",
       "spl_og_mou_7             0.003208\n",
       "std_ic_t2t_mou_6         0.003042\n",
       "total_rech_amt_8         0.003021\n",
       "max_rech_data_7          0.002903\n",
       "total_og_mou_7           0.002693\n",
       "onnet_mou_8              0.002618\n",
       "std_og_t2m_mou_7         0.002592\n",
       "std_og_t2m_mou_6         0.002571\n",
       "jul_vbc_3g               0.002545\n",
       "std_og_t2t_mou_6         0.002522\n",
       "std_ic_t2f_mou_8         0.002400\n",
       "loc_ic_t2f_mou_8         0.002361\n",
       "loc_og_t2t_mou_7         0.002285\n",
       "offnet_mou_6             0.002252\n",
       "std_ic_t2f_mou_6         0.002245\n",
       "std_ic_t2t_mou_7         0.002239\n",
       "max_rech_data_6          0.002161\n",
       "max_rech_amt_8           0.002037\n",
       "spl_og_mou_8             0.001938\n",
       "last_day_rch_amt_6       0.001926\n",
       "last_day_rch_amt_7       0.001883\n",
       "loc_og_t2m_mou_7         0.001881\n",
       "loc_ic_t2f_mou_6         0.001833\n",
       "fb_user_7_0.0            0.001648\n",
       "std_og_t2t_mou_8         0.001560\n",
       "sachet_2g_6              0.001557\n",
       "night_pck_user_7_1.0     0.001173\n",
       "max_rech_amt_7           0.001106\n",
       "fb_user_6_0.0            0.001040\n",
       "fb_user_8_1.0            0.001030\n",
       "ic_others_7              0.000993\n",
       "std_og_mou_7             0.000956\n",
       "std_og_t2m_mou_8         0.000956\n",
       "ic_others_6              0.000946\n",
       "loc_og_t2t_mou_6         0.000909\n",
       "ic_others_8              0.000899\n",
       "vol_3g_mb_7              0.000660\n",
       "vol_2g_mb_7              0.000646\n",
       "vol_3g_mb_diff           0.000643\n",
       "total_rech_data_diff     0.000629\n",
       "total_rech_data_6        0.000499\n",
       "onnet_mou_7              0.000492\n",
       "aug_vbc_3g               0.000444\n",
       "std_ic_t2t_mou_8         0.000364\n",
       "std_ic_t2f_mou_7         0.000339\n",
       "vol_3g_mb_6              0.000322\n",
       "total_rech_data_7        0.000292\n",
       "total_og_mou_6           0.000261\n",
       "max_rech_data_diff       0.000177\n",
       "std_ic_mou_6             0.000172\n",
       "night_pck_user_6_1.0     0.000165\n",
       "std_og_t2t_mou_7         0.000033\n",
       "loc_og_t2c_mou_7         0.000000\n",
       "loc_og_t2c_mou_8         0.000000\n",
       "loc_og_t2c_mou_6         0.000000\n",
       "loc_og_t2f_mou_7         0.000000\n",
       "isd_ic_mou_diff          0.000000\n",
       "isd_og_mou_diff          0.000000\n",
       "roam_og_mou_diff         0.000000\n",
       "roam_ic_mou_diff         0.000000\n",
       "spl_ic_mou_diff          0.000000\n",
       "isd_ic_mou_8             0.000000\n",
       "roam_og_mou_8            0.000000\n",
       "roam_og_mou_7            0.000000\n",
       "roam_og_mou_6            0.000000\n",
       "std_og_t2f_mou_7         0.000000\n",
       "roam_ic_mou_8            0.000000\n",
       "roam_ic_mou_7            0.000000\n",
       "night_pck_user_6_0.0     0.000000\n",
       "night_pck_user_7_0.0     0.000000\n",
       "roam_ic_mou_6            0.000000\n",
       "night_pck_user_8_0.0     0.000000\n",
       "night_pck_user_8_1.0     0.000000\n",
       "fb_user_6_1.0            0.000000\n",
       "loc_ic_t2o_mou           0.000000\n",
       "fb_user_7_1.0            0.000000\n",
       "fb_user_8_0.0            0.000000\n",
       "std_og_t2f_mou_6         0.000000\n",
       "sachet_3g_7              0.000000\n",
       "std_og_t2f_mou_8         0.000000\n",
       "std_ic_t2o_mou_7         0.000000\n",
       "og_others_6              0.000000\n",
       "og_others_7              0.000000\n",
       "max_rech_data_8          0.000000\n",
       "og_others_8              0.000000\n",
       "loc_ic_t2f_mou_7         0.000000\n",
       "std_ic_t2o_mou_6         0.000000\n",
       "std_ic_t2o_mou_8         0.000000\n",
       "sep_vbc_3g               0.000000\n",
       "std_og_t2o_mou           0.000000\n",
       "spl_ic_mou_6             0.000000\n",
       "spl_ic_mou_7             0.000000\n",
       "spl_ic_mou_8             0.000000\n",
       "isd_ic_mou_6             0.000000\n",
       "isd_ic_mou_7             0.000000\n",
       "isd_og_mou_8             0.000000\n",
       "vol_2g_mb_6              0.000000\n",
       "isd_og_mou_7             0.000000\n",
       "isd_og_mou_6             0.000000\n",
       "monthly_2g_6             0.000000\n",
       "monthly_2g_7             0.000000\n",
       "monthly_2g_8             0.000000\n",
       "sachet_2g_7              0.000000\n",
       "sachet_2g_8              0.000000\n",
       "monthly_3g_6             0.000000\n",
       "monthly_3g_7             0.000000\n",
       "monthly_3g_8             0.000000\n",
       "sachet_3g_6              0.000000\n",
       "sachet_3g_8              0.000000\n",
       "std_og_t2c_mou_8         0.000000\n",
       "std_og_t2c_mou_7         0.000000\n",
       "std_og_t2c_mou_6         0.000000\n",
       "loc_og_t2o_mou           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores = pd.Series(best_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_ic_mou_8         0.374411\n",
       "total_og_mou_diff      0.060182\n",
       "av_rech_amt_data_8     0.041411\n",
       "last_day_rch_amt_8     0.027337\n",
       "loc_og_mou_8           0.017973\n",
       "total_rech_num_diff    0.016240\n",
       "total_ic_mou_diff      0.014985\n",
       "loc_ic_t2m_mou_8       0.014406\n",
       "loc_ic_mou_diff        0.011655\n",
       "total_ic_mou_6         0.011565\n",
       "dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 features\n",
    "top_10_features = feature_scores.head(10)\n",
    "top_10_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top 10 Features by Importance')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Importance Score')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create horizontal bar plot\n",
    "plt.barh(top_10_features.index, top_10_features.values, color='Orange')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Top 10 Features by Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Display the plot\n",
    "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p8wifC80OWs"
   },
   "source": [
    "Assess the performance of your model on different evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix on the training dataset:\n",
      " [[10984    40]\n",
      " [    0 11024]]\n",
      "\n",
      " Confusion matrix on the validation dataset:\n",
      " [[2610  146]\n",
      " [   0 2756]]\n",
      "\n",
      " ROC AUC on the training dataset: \n",
      " 0.9981857764876633\n",
      "\n",
      " ROC AUC on the validation dataset: \n",
      " 0.9735123367198839\n",
      "\n",
      " Accuracy on the training dataset: \n",
      " 0.9981857764876633\n",
      "\n",
      " Accuracy on the validation dataset:\n",
      " 0.9735123367198839\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and validation sets using accuracy, confusion metrics and AUC of ROC\n",
    "print('\\n Confusion matrix on the training dataset:\\n', confusion_matrix(y_train_ros,y_train_predd)) \n",
    "print('\\n Confusion matrix on the validation dataset:\\n', confusion_matrix(y_test_ros, y_test_predd)) \n",
    "print('\\n ROC AUC on the training dataset: \\n', roc_auc_score(y_train_ros, y_train_predd)) \n",
    "print('\\n ROC AUC on the validation dataset: \\n', roc_auc_score(y_test_ros, y_test_predd)) \n",
    "print('\\n Accuracy on the training dataset: \\n', accuracy_score(y_train_ros, y_train_predd)) \n",
    "print('\\n Accuracy on the validation dataset:\\n', accuracy_score(y_test_ros, y_test_predd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELCx6CvkIc8K"
   },
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbKuJBFlLMjc"
   },
   "source": [
    "Create a neural network model with the defined set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "r7K_6w5161bs"
   },
   "outputs": [],
   "source": [
    "# Define a function to create a neural network model and specify default values for variable hyperparameters\n",
    "# Note: The number of hidden layers is fixed at 2\n",
    "# Note: The number of neurons in the second hidden layer is fixed at 64\n",
    "# Note: The output layer activation function is fixed as 'sigmoid'\n",
    "\n",
    "# You can change the hyperparameters mentioned as arguments in the create_nn function\n",
    "# So that you can use them in GridSearchCV hyperparameter tuning\n",
    "# Feel free to modify the model too and test the model performance\n",
    "# You can add more types of layers like Dropout, Batch normalization etc.\n",
    "\n",
    "# Note: The variable hyperparameters list is the activation functions of the hidden layers and number of neurons in the first hidden layer\n",
    "def create_nn(activation_function = 'relu',\n",
    "              hidden1_neurons = 256):\n",
    "\n",
    "    # Declare an instance of an artificial neural network model using the 'Sequential()' method\n",
    "    nn = Sequential()\n",
    "\n",
    "    # keras.Input is the input layer of the neural network\n",
    "    nn.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "    # Add a hidden layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 'hidden1_neurons'  - This specifies the number of neurons in the hidden layer\n",
    "    # Note: Set the 'activation' parameter to 'activation_function' - This specifies the activation function parameter defined in the custom function\n",
    "    nn.add(Dense(units=hidden1_neurons, activation=activation_function))\n",
    "\n",
    "    # Add a hidden layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 64  - This specifies the number of neurons in the hidden layer\n",
    "    # Note: Set the 'activation' parameter to 'activation_function' - This specifies the activation function parameter defined in the custom function\n",
    "    nn.add(Dense(units=64, activation=activation_function))\n",
    "\n",
    "    # Add the output layer using the 'add()' and 'Dense()' methods\n",
    "    # Note: Set the 'units' parameter to 1 - Binary classification\n",
    "    # Note: Set the 'activation' parameter to 'sigmoid' - The sigmoid activation function is used for output layer neurons in binary classification tasks\n",
    "    nn.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model using the 'compile()' method\n",
    "    # Note: Set the 'loss' parameter to 'binary_crossentropy' - The binary crossentropy loss function is commonly used for binary classification tasks\n",
    "    # Note: Set the 'metrics' parameter to 'accuracy' - This records the accuracy of the model along with the loss during training\n",
    "    # Note: Set the 'optimizer' parameter to 'RMSprop' and set its 'learning_rate' parameter to 'learning_rate_value' - This specifies the learning rate value defined in the custom function\n",
    "    nn.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=RMSprop(learning_rate=0.001))\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "zhFTIqPT6-2M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">45,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m45,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,337</span> (243.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,337\u001b[0m (243.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,337</span> (243.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,337\u001b[0m (243.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 5.0118 - val_accuracy: 0.9343 - val_loss: 0.2098\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.2257 - val_accuracy: 0.9361 - val_loss: 0.2348\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.2530 - val_accuracy: 0.9349 - val_loss: 0.3246\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2225 - val_accuracy: 0.9371 - val_loss: 0.2010\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.2324 - val_accuracy: 0.9381 - val_loss: 0.2257\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.2563 - val_accuracy: 0.9359 - val_loss: 0.1994\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.2381 - val_accuracy: 0.9345 - val_loss: 0.1967\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.2291 - val_accuracy: 0.9389 - val_loss: 0.2285\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.2245 - val_accuracy: 0.9389 - val_loss: 0.2036\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.2182 - val_accuracy: 0.9381 - val_loss: 0.8061\n"
     ]
    }
   ],
   "source": [
    "# Create a default neural network using the 'create_nn' function and train it on the training data\n",
    "nn1 = create_nn()\n",
    "# Ensure y_train and y_test are of type float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "# Capture the training history of the model using the 'fit()' method\n",
    "\n",
    "# Note: Set the 'validation_data' parameter to (X_val, y_val)\n",
    "# Note: Set the 'epochs' parameter to 10 - This specifies the scope of loss computations and parameter updates\n",
    "nn1.summary()\n",
    "print('\\n')\n",
    "nn1_history =nn1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "-wDL8mOz7i_g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.907473</td>\n",
       "      <td>1.880255</td>\n",
       "      <td>0.934267</td>\n",
       "      <td>0.209761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932338</td>\n",
       "      <td>0.223424</td>\n",
       "      <td>0.936133</td>\n",
       "      <td>0.234840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936871</td>\n",
       "      <td>0.234422</td>\n",
       "      <td>0.934867</td>\n",
       "      <td>0.324643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.935871</td>\n",
       "      <td>0.221587</td>\n",
       "      <td>0.937067</td>\n",
       "      <td>0.200982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.939871</td>\n",
       "      <td>0.229442</td>\n",
       "      <td>0.938067</td>\n",
       "      <td>0.225687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.939404</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.935933</td>\n",
       "      <td>0.199389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.939004</td>\n",
       "      <td>0.224048</td>\n",
       "      <td>0.934533</td>\n",
       "      <td>0.196693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.940337</td>\n",
       "      <td>0.226778</td>\n",
       "      <td>0.938933</td>\n",
       "      <td>0.228453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.941004</td>\n",
       "      <td>0.212312</td>\n",
       "      <td>0.938867</td>\n",
       "      <td>0.203645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.940137</td>\n",
       "      <td>0.217520</td>\n",
       "      <td>0.938133</td>\n",
       "      <td>0.806105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy      loss  val_accuracy  val_loss\n",
       "epoch                                            \n",
       "1      0.907473  1.880255      0.934267  0.209761\n",
       "2      0.932338  0.223424      0.936133  0.234840\n",
       "3      0.936871  0.234422      0.934867  0.324643\n",
       "4      0.935871  0.221587      0.937067  0.200982\n",
       "5      0.939871  0.229442      0.938067  0.225687\n",
       "6      0.939404  0.244529      0.935933  0.199389\n",
       "7      0.939004  0.224048      0.934533  0.196693\n",
       "8      0.940337  0.226778      0.938933  0.228453\n",
       "9      0.941004  0.212312      0.938867  0.203645\n",
       "10     0.940137  0.217520      0.938133  0.806105"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the neural network history object into a data frame to view its specifics\n",
    "import pandas as pd\n",
    "hist = pd.DataFrame(nn1_history.history)\n",
    "hist['epoch'] = nn1_history.epoch\n",
    "hist['epoch'] = hist['epoch'].apply(lambda x: x + 1)\n",
    "hist.set_index('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxObHnu916zY"
   },
   "source": [
    "Plot the training and validation accuracies for different values of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "OU3nlVwg7zyq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJYAAAGHCAYAAADiJdjqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5kklEQVR4nO3dd1yW9f7H8ffNHgKiKOLEUe4yx3FlajkyZ2mOU46ydRonf9bJlTmT0jQrxzlprsqRZWZHG2ZZlhVqWa4cpeIAEVRQUUC4fn9chxtultwIXIzX8/G4Hlxc83PfzPt9f4fNMAxDAAAAAAAAgJNcrC4AAAAAAAAAJRPBEgAAAAAAAPKFYAkAAAAAAAD5QrAEAAAAAACAfCFYAgAAAAAAQL4QLAEAAAAAACBfCJYAAAAAAACQLwRLAAAAAAAAyBeCJQAAAAAAAOQLwRIAAMXcm2++KZvNpiZNmlhdCgrQsmXLZLPZsl2ef/55S2tbuXKl5s6dm+0+m82myZMnF2k9ztqyZYtatmwpX19f2Ww2rV+/Ptvjjh07luPXoLg8ztDQUPXq1cvqMgAAyJGb1QUAAIDcLVmyRJK0b98+/fzzz2rdurXFFaEgLV26VA0aNHDYVrVqVYuqMa1cuVJ79+7VqFGjsuz78ccfVb169aIvKo8Mw9DAgQN18803a8OGDfL19VX9+vVzPeeZZ57R3//+9yzbi/PjBACguCBYAgCgGNu5c6d+++039ezZUxs3btQ777xTbIOlhIQE+fj4WF1GidOkSRO1bNnS6jLyrE2bNlaXkKvTp0/r3Llzuvfee3XXXXfl6ZyaNWsW+8cFAEBxRVc4AACKsXfeeUeS9Morr6hdu3ZavXq1EhISshx36tQpPfbYY6pRo4Y8PDxUtWpVDRgwQGfOnLEfc+HCBT333HOqU6eOPD09VblyZd1zzz36448/JElbt26VzWbT1q1bHa6d1l1o2bJl9m0jRoxQuXLltGfPHnXr1k1+fn72F/GbN29W3759Vb16dXl5ealevXp6/PHHFRMTk6XuP/74Q0OGDFFwcLA8PT1Vs2ZNDRs2TImJiTp27Jjc3NwUFhaW5bzvvvtONptNa9euzfG5u3r1qp577jk1a9ZMAQEBqlChgtq2batPPvkky7Fr165V69atFRAQIB8fH9WpU0cPP/xwjtdOM3/+fN1xxx2qXLmyfH191bRpU82cOVPJycnXPTcvcuqOFRoaqhEjRtg/T+tW98033+gf//iHgoKCVLFiRd133306ffp0lvNXrlyptm3bqly5cipXrpyaNWtm/17r1KmTNm7cqOPHjzt0C8utpr1796pv374KDAyUl5eXmjVrpuXLlzsck/b9tWrVKk2YMEFVq1aVv7+/unTpooMHD+bp+fj+++911113yc/PTz4+PmrXrp02btxo3z958mR7K6MxY8bIZrMpNDQ0T9e+nk6dOqlJkybatm2b2rRpI29vb1WrVk0TJ05USkqKw7Hnzp3Tk08+qWrVqsnDw0N16tTRhAkTlJiY6HBcamqq3nrrLTVr1kze3t4qX7682rRpow0bNmS5/+eff67mzZvL29tbDRo0sLdkBADAarRYAgCgmLpy5YpWrVqlVq1aqUmTJnr44Yf1yCOPaO3atRo+fLj9uFOnTqlVq1ZKTk7W+PHjdcsttyg2NlZffPGFzp8/r+DgYF28eFG33367jh07pjFjxqh169a6dOmSvvvuO0VGRmbpipUXSUlJ6tOnjx5//HGNHTtW165dkyT9+eefatu2rR555BEFBATo2LFjmjNnjm6//Xbt2bNH7u7ukqTffvtNt99+u4KCgjR16lTddNNNioyM1IYNG5SUlKTQ0FD16dNH//73v/XCCy/I1dXVfu958+apatWquvfee3OsLzExUefOndPzzz+vatWqKSkpSV999ZXuu+8+LV26VMOGDZNkdu0aNGiQBg0apMmTJ8vLy0vHjx/X119/fd3n4M8//9Tf//531a5dWx4eHvrtt9/08ssv648//sjzC/+UlBT7c5fGzS1//6I98sgj6tmzp1auXKkTJ07oX//6lx588EGHx/LSSy9p2rRpuu+++/Tcc88pICBAe/fu1fHjxyVJCxYs0GOPPaY///xTH3/88XXvefDgQbVr106VK1fWm2++qYoVK+q9997TiBEjdObMGb3wwgsOx48fP17t27fX4sWLFR8frzFjxqh37946cOCAw9c4s2+//VZdu3bVLbfconfeeUeenp5asGCBevfurVWrVmnQoEF65JFHdOutt+q+++6zd2/z9PS87mNITU3N8jWQsn4doqKiNHjwYI0dO1ZTp07Vxo0bNX36dJ0/f17z5s2TZAaanTt31p9//qkpU6bolltu0bZt2xQWFqbdu3c7BGEjRozQe++9p5EjR2rq1Kny8PDQL7/8omPHjjnc97ffftNzzz2nsWPHKjg4WIsXL9bIkSNVr1493XHHHdd9fAAAFCoDAAAUSytWrDAkGf/+978NwzCMixcvGuXKlTM6dOjgcNzDDz9suLu7G/v378/xWlOnTjUkGZs3b87xmG+++caQZHzzzTcO248ePWpIMpYuXWrfNnz4cEOSsWTJklwfQ2pqqpGcnGwcP37ckGR88skn9n133nmnUb58eSM6Ovq6NX388cf2badOnTLc3NyMKVOm5HrvzK5du2YkJycbI0eONG677Tb79tdee82QZFy4cMGp62WWkpJiJCcnGytWrDBcXV2Nc+fO5Xr80qVLDUnZLsnJyYZhGIYkY9KkSVnOrVWrljF8+PAs13ryyScdjps5c6YhyYiMjDQMwzD++usvw9XV1XjggQdyra1nz55GrVq1st2XuabBgwcbnp6eRkREhMNxPXr0MHx8fOzPa9rX8p577nE47oMPPjAkGT/++GOuNbVp08aoXLmycfHiRfu2a9euGU2aNDGqV69upKamGoaR/v06a9asXK+X8diclm3bttmP7dixY5bvYcMwjEcffdRwcXExjh8/bhiGYfz73/82JBkffPCBw3GvvvqqIcn48ssvDcMwjO+++86QZEyYMCHXGmvVqmV4eXnZr28YhnHlyhWjQoUKxuOPP37dxwgAQGGjKxwAAMXUO++8I29vbw0ePFiSVK5cOd1///3atm2bDh8+bD/us88+U+fOndWwYcMcr/XZZ5/p5ptvVpcuXQq0xv79+2fZFh0drSeeeEI1atSQm5ub3N3dVatWLUnSgQMHJJnjMX377bcaOHCgKlWqlOP1O3XqpFtvvVXz58+3b/v3v/8tm82mxx577Lr1rV27Vu3bt1e5cuXstbzzzjv2OiSpVatWkqSBAwfqgw8+0KlTp/L24CX9+uuv6tOnjypWrChXV1e5u7tr2LBhSklJ0aFDh/J0jRUrVmjHjh0OS35bLPXp08fh81tuuUWS7K2RNm/erJSUFD311FP5un52vv76a911112qUaOGw/YRI0YoISFBP/74o1M1Zufy5cv6+eefNWDAAJUrV86+3dXVVUOHDtXJkyfz3J0uO88++2yWr8GOHTvUrFkzh+P8/Pyy1P/3v/9dqamp+u677ySZz4evr68GDBjgcFxa18UtW7ZIMn8mJeXpa9GsWTPVrFnT/rmXl5duvvnmXJ8zAACKCsESAADF0JEjR/Tdd9+pZ8+eMgxDFy5c0IULF+wvVjN2szp79ux1Z6/KyzHO8vHxkb+/v8O21NRUdevWTevWrdMLL7ygLVu2KDw8XD/99JMks3ufJJ0/f14pKSl5qumf//yntmzZooMHDyo5OVmLFi3SgAEDVKVKlVzPW7dunQYOHKhq1arpvffe048//qgdO3bo4Ycf1tWrV+3H3XHHHVq/fr2uXbumYcOGqXr16mrSpIlWrVqV6/UjIiLUoUMHnTp1Sm+88Ya2bdumHTt22EOwtMd6PQ0bNlTLli0dlvyqWLGiw+dp3cDSajl79qykgp3tLDY2ViEhIVm2p81sFxsb61SN2Tl//rwMw3DqPs6oXr16lq9By5YtHUIsSQoODs5ybtr3Ydr9Y2NjVaVKFYdxqSSpcuXKcnNzsx939uxZubq6Xvf7WMr6nEnm85bX7zEAAAoTYywBAFAMLVmyRIZh6MMPP9SHH36YZf/y5cs1ffp0ubq6qlKlSjp58mSu18vLMV5eXpKUZYDh7AbdlpTlhbNkDuL822+/admyZQ7jQB05csThuAoVKsjV1fW6NUlmi5AxY8Zo/vz5atOmjaKiovLUyuO9995T7dq1tWbNGodaMz8+Serbt6/69u2rxMRE/fTTTwoLC9Pf//53hYaGqm3bttlef/369bp8+bLWrVtnb5ElSbt3775ubXnl6emZbb35DVHSWoedPHkySwuj/KpYsaIiIyOzbE8bNDwoKOiG7xEYGCgXF5dCv8/1ZBwMP01UVJSk9PCnYsWK+vnnn2UYhsP3XXR0tK5du2avs1KlSkpJSVFUVFS2gRkAACUFLZYAAChmUlJStHz5ctWtW1fffPNNluW5555TZGSkvStNjx499M033+TaFahHjx46dOhQrgNSp82e9fvvvztsz26GqpykvZDOPGDyf/7zH4fPvb291bFjR61duzbH4CqNl5eXHnvsMS1fvlxz5sxRs2bN1L59+zzV4uHh4fDiPioqKttZ4dJ4enqqY8eOevXVVyWZXd1yu37aOWkMw9CiRYuuW1tehYaGZvl6fP3117p06VK+rtetWze5urpq4cKFuR7nTGuYu+66S19//XWW2edWrFghHx8ftWnTJl+1ZuTr66vWrVtr3bp1DnWlpqbqvffeU/Xq1XXzzTff8H2u5+LFi1l+HlauXCkXFxf7INp33XWXLl26pPXr1zsct2LFCvt+yfyZlHTdrwUAAMUdLZYAAChmPvvsM50+fVqvvvqqOnXqlGV/kyZNNG/ePL3zzjvq1auXpk6dqs8++0x33HGHxo8fr6ZNm+rChQv6/PPPNXr0aDVo0ECjRo3SmjVr1LdvX40dO1Z/+9vfdOXKFX377bfq1auXOnfurCpVqqhLly4KCwtTYGCgatWqpS1btmjdunV5rr1BgwaqW7euxo4dK8MwVKFCBX366afavHlzlmPTZopr3bq1xo4dq3r16unMmTPasGGD/vOf/8jPz89+7JNPPqmZM2dq165dWrx4cZ5q6dWrl9atW6cnn3xSAwYM0IkTJzRt2jSFhIQ4jFH10ksv6eTJk7rrrrtUvXp1XbhwQW+88Ybc3d3VsWPHHK/ftWtXeXh4aMiQIXrhhRd09epVLVy4UOfPn8/z83U9Q4cO1cSJE/XSSy+pY8eO2r9/v+bNm6eAgIB8XS80NFTjx4/XtGnTdOXKFQ0ZMkQBAQHav3+/YmJiNGXKFElS06ZNtW7dOi1cuFAtWrSQi4tLjl30Jk2apP/+97/q3LmzXnrpJVWoUEHvv/++Nm7cqJkzZ+a71szCwsLUtWtXde7cWc8//7w8PDy0YMEC7d27V6tWrcq2BV1eRURE2LtrZlSpUiXVrVvX/nnFihX1j3/8QxEREbr55pu1adMmLVq0SP/4xz/sYyANGzZM8+fP1/Dhw3Xs2DE1bdpU33//vWbMmKF77rnHPs5Zhw4dNHToUE2fPl1nzpxRr1695OnpqV9//VU+Pj565pln8v14AAAoUlaOHA4AALLq16+f4eHhketsaYMHDzbc3NyMqKgowzAM48SJE8bDDz9sVKlSxXB3dzeqVq1qDBw40Dhz5oz9nPPnzxvPPvusUbNmTcPd3d2oXLmy0bNnT+OPP/6wHxMZGWkMGDDAqFChghEQEGA8+OCDxs6dO7OdFc7X1zfb2vbv32907drV8PPzMwIDA43777/fiIiIyHaGs/379xv333+/UbFiRcPDw8OoWbOmMWLECOPq1atZrtupUyejQoUKRkJCQl6eRsMwDOOVV14xQkNDDU9PT6Nhw4bGokWLjEmTJhkZ/wX673//a/To0cOoVq2a4eHhYVSuXNm45557HGYEy8mnn35q3HrrrYaXl5dRrVo141//+pfx2WefZTu7XmZpM7nt2LEjx2MSExONF154wahRo4bh7e1tdOzY0di9e3eOs8JlvlZOM/2tWLHCaNWqleHl5WWUK1fOuO222xy+vufOnTMGDBhglC9f3rDZbA7PV3Zfxz179hi9e/c2AgICDA8PD+PWW291uF7GWtauXeuwPbtZB3Oybds248477zR8fX0Nb29vo02bNsann36a7fUKYla4jLPndezY0WjcuLGxdetWo2XLloanp6cREhJijB8/3j6LX5rY2FjjiSeeMEJCQgw3NzejVq1axrhx47J8X6ekpBivv/660aRJE8PDw8MICAgw2rZt6/CYatWqZfTs2TNL7R07djQ6dux43ccIAEBhsxmGYRRxlgUAAOCU6Oho1apVS88884xmzpxpdTkogzp16qSYmBjt3bvX6lIAAChW6AoHAACKrZMnT+qvv/7SrFmz5OLiomeffdbqkgAAAJABg3cDAIBia/HixerUqZP27dun999/X9WqVbO6JAAAAGRAVzgAAAAAAADkCy2WAAAAAAAAkC8ESwAAAAAAAMgXgiUAAAAAAADkC7PC5VNqaqpOnz4tPz8/2Ww2q8sBAAAAAAAoEIZh6OLFi6patapcXHJvk0SwlE+nT59WjRo1rC4DAAAAAACgUJw4cULVq1fP9RiCpXzy8/OTZD7J/v7+FlcDAAAAAABQMOLj41WjRg179pEbgqV8Suv+5u/vT7AEAAAAAABKnbwM/cPg3QAAAAAAAMgXgiUAAAAAAADkC8ESAAAAAAAA8oUxlgqRYRi6du2aUlJSrC4FBcDV1VVubm556mMKAAAAAEBZQLBUSJKSkhQZGamEhASrS0EB8vHxUUhIiDw8PKwuBQAAAAAAyxEsFYLU1FQdPXpUrq6uqlq1qjw8PGjlUsIZhqGkpCSdPXtWR48e1U033SQXF3qSAgAAAADKNoKlQpCUlKTU1FTVqFFDPj4+VpeDAuLt7S13d3cdP35cSUlJ8vLysrokAAAAAAAsRZOLQkSLltKHrykAAAAAAOl4lQwAAAAAAIB8oSscAAAAAABWMgwpMVG6eDHrkpwslS8vBQamLz4+EuP4opggWEKh69Spk5o1a6a5c+fm6fhjx46pdu3a+vXXX9WsWbNCrQ0AAAAA8uXateyDoPwu167l/d7u7o5BU+bgKaelfHnJz49QCgWKYAl215u5bvjw4Vq2bJnT1123bp3c3d3zfHyNGjUUGRmpoKAgp+8FAAAAANlKTZUuXy64IOjq1cKp09fXDH/SFldXKS5OOn/eXK5dM1sxRUebi7NcXa8fROW0399fYtxZZEKwBLvIyEj7+po1a/TSSy/p4MGD9m3e3t4OxycnJ+cpMKpQoYJTdbi6uqpKlSpOnQMAAACglDEMM7wpqCDo0qXCqdPDwzEIym3x9899v6+vGfzk9pxcvpweMmVeLlzIed/581JSkpSSIsXGmouzXFykgID8tZYKCMj9saHEIlgqKoYhJSQU/X2d6HubMcwJCAiQzWazbzt27JhCQkK0Zs0aLViwQD/99JMWLlyoPn366Omnn9a2bdt07tw51a1bV+PHj9eQIUPs18rcFS40NFSPPfaYjhw5orVr1yowMFAvvviiHnvsMfu9MnaF27p1qzp37qyvvvpKY8aM0f79+9WsWTMtXbpU9evXt99n+vTpevPNN3XlyhUNGjRIQUFB+vzzz7V79+4bfBIBAAAA5ElycsF2D0tJKfgaXVzyHgTlZfHwKPgac2KzSeXKmUuNGs6daxjSlSt5D6EyH3flitnqK217fvj75627XnbbnOgFg6JFsFRUEhLMH/6idumSmXoXkDFjxmj27NlaunSpPD09dfXqVbVo0UJjxoyRv7+/Nm7cqKFDh6pOnTpq3bp1jteZPXu2pk2bpvHjx+vDDz/UP/7xD91xxx1q0KBBjudMmDBBs2fPVqVKlfTEE0/o4Ycf1g8//CBJev/99/Xyyy9rwYIFat++vVavXq3Zs2erdu3aBfbYAQAAgFInNdV8zVBQQVBiYuHUmbl72I0s3t5lc4whm81seODjI1Wr5vz5iYl5C6CyWy5fNq8RH28ux487f/9y5fLeZS/zUpThXxlkebC0YMECzZo1S5GRkWrcuLHmzp2rDh065Hj8/PnzNW/ePB07dkw1a9bUhAkTNGzYsGyPXb16tYYMGaK+fftq/fr1N3RfmEaNGqX77rvPYdvzzz9vX3/mmWf0+eefa+3atbkGS/fcc4+efPJJSWZY9frrr2vr1q25Bksvv/yyOnbsKEkaO3asevbsqatXr8rLy0tvvfWWRo4cqYceekiS9NJLL+nLL7/UpcJq7goAAAAURwkJUmSkdPp01iUy0hyrJ2MQlPaCv6B5ehZcEFSuHOP6FAeenlKVKubirKSk9OApry2l0o6NjzevcemSuZw44fz9vb3zPrh55m2ZhoRBVpYGS2vWrNGoUaPsrUz+85//qEePHtq/f79q1qyZ5fiFCxdq3LhxWrRokVq1aqXw8HA9+uijCgwMVO/evR2OPX78uJ5//vlswyJn71sgfHwKr0/v9e5bgFq2bOnweUpKil555RWtWbNGp06dUmJiohITE+V7nVZSt9xyi309rctd9HUGnst4TkhIiCQpOjpaNWvW1MGDB+1BVZq//e1v+vrrr/P0uAAAAIBiLTFRiorKPjDKuFy4kL/ru7oWbPcwui0hIw8PqXJlc3HWtWuOg5c701oqLi69C+CVK+bPiLM8PfPfUqoAew8VZ5YGS3PmzNHIkSP1yCOPSJLmzp2rL774QgsXLlRYWFiW49999109/vjjGjRokCSpTp06+umnn/Tqq686BEspKSl64IEHNGXKFG3btk0XMv1ydfa+BcJmKxXfVJkDo9mzZ+v111/X3Llz1bRpU/n6+mrUqFFKSkrK9TqZB/222WxKTU3N8zlpM9hlPCfzrHaGYeR6PQAAAMBy165JZ85cPzCKicn7Nb29za5OVas6LiEh6dPNZ168vMpm9zAUf25uUsWK5uKs1FTHUMrZcaVSU9ND3ago5+4dHOz8OSWUZcFSUlKSdu3apbFjxzps79atm7Zv357tOYmJifLy8nLY5u3trfDwcIcZyqZOnapKlSpp5MiR2rZt2w3fN+3eiRn6C8enNccr47Zt26a+ffvqwQcflGQGPYcPH1bDhg2LtI769esrPDxcQ4cOtW/buXNnkdYAAAAA2KWmSmfPXj8wOnPGbFGRFx4eWcOi7BZ/f0IiQDK7UKa1HnKWYZjdRfMaQmVe8nPPEsqyYCkmJkYpKSkKDg522B4cHKyoHFK97t27a/HixerXr5+aN2+uXbt2acmSJUpOTlZMTIxCQkL0ww8/6J133slxJrD83FeSwsLCNGXKFOceZBlQr149ffTRR9q+fbsCAwM1Z84cRUVFFXmw9Mwzz+jRRx9Vy5Yt1a5dO61Zs0a///676tSpU6R1AAAsYBjS7t3Shg3SZ5+ZYzF4e+e++Pjk/xi6dwBlm2FI585dPzCKijJbI+WFq6vZmuh6gVGFCgRGQFGx2cyQ1t9fqlXLuXMNQ7p6tXDqKoYsH7w7u+5LmbelmThxoqKiotSmTRsZhqHg4GCNGDFCM2fOlKurqy5evKgHH3xQixYtUlBQUIHdV5LGjRun0aNH2z+Pj49XDWendyyFJk6cqKNHj6p79+7y8fHRY489pn79+ikuLq5I63jggQf0119/6fnnn9fVq1c1cOBAjRgxQuHh4UVaBwCgiCQmSlu3mmHSp5/mbyDP/HJ1LbiQKq9BFi8kgcJnGGYwfb3AKDIy7zOf2Wxmd5jrBUZBQebvFgClg81Wpgb9thkWDUSTlJQkHx8frV27Vvfee699+7PPPqvdu3fr22+/zfHc5ORknTlzRiEhIXr77bc1ZswYXbhwQb///rtuu+02uWb4pZw2Bo+Li4sOHjyoGjVq5Pu+GcXHxysgIEBxcXHy9/d32Hf16lUdPXpUtWvXztJ1D0Wna9euqlKlit59990CuyZfWwCwUGystGmTGSZ9/rnjpBje3lK3blLv3lKdOumDdOa2JCTk/Rgr33V0cSmcICun4zw8CLJQ+ly+fP3A6PRp82c+r4KCrh8YBQeb48MAQAmTW+aRmWW/5Tw8PNSiRQtt3rzZIeDZvHmz+vbtm+u57u7uql69uiRp9erV6tWrl1xcXNSgQQPt2bPH4dgXX3xRFy9e1BtvvKEaNWrc0H1RfCUkJOjf//63unfvLldXV61atUpfffWVNm/ebHVpAIAbcfiw2SLpk0+k7783xyxJU6WKGST16SPddVfhvjOY1qT9RkIqZ49Lk5pqvigurCnBM0t7l7WogixPT4Is5F9iYt4CI2fGRy1f/vqBUZUq5vcuAMDarnCjR4/W0KFD1bJlS7Vt21Zvv/22IiIi9MQTT0gyu5+dOnVKK1askCQdOnRI4eHhat26tc6fP685c+Zo7969Wr58uSTJy8tLTZo0cbhH+fLlJclh+/Xui5LHZrNp06ZNmj59uhITE1W/fn199NFH6tKli9WlAQCckZIi/fyz2SppwwbpwAHH/U2bmkFSnz5Sy5Zma56ikDFsKQqGYb5gLqiQKi/HpYV2hmGe40zLjRths5mzUWW3eHpef1tejrneNlqUFD/JyXmbKS02Nu/X9PXNfqa0zLOm+fgU3uMCgFLI0r+igwYNUmxsrKZOnarIyEg1adJEmzZtUq3/DYwVGRmpiIgI+/EpKSmaPXu2Dh48KHd3d3Xu3Fnbt29XaGhogd4XJY+3t7e++uorq8sAAOTH5cvS5s1mkPTf/5qzKKVxc5M6djSDpN69pdq1rauzKGUMW4piVhnDkJKSCr4LYW5LSkr6vdO2WcXVtWCDqvyEY2VlfJ2UlLzNlBYdnfeZ0jw9rx8YVa0q+fkV7mMDgDLKsjGWSjrGWCqb+NoCQAE5fdoMkTZskL76ynEg3IAA6Z57zDDp7rvNbikofZKTHQOoxESzu+HVq47rhbUtr7N1FRU3N+tabKWt30gLQMMwWw/lZaa0tFAxL8/J9cKiqlXN3xF0pwSAAlUixlgCAABliGFIe/akd3HbscNxf2io1LevGSZ16GDOhIbSzd3dDBEDAqy5f0pK1sApuwCqsIKujN0PJTPounTJcVD6oubh4VwodfWq40xpSUl5u4+LizlG0fUCo4oVi667axlx7Zr5re/iYmZxmRcAyA+CJQAAUDiSkqTvvksPk44fd9zfunX6eEmNG/OqBkXL1dUcS8fK8XSuXSvaVlrZbcvYeSEpyVwuXsz/Y6pc+fqBUeXKZafrXzFw4YI5/8EHH5i9jpOTcz7WZnMMnTIHUPnZV9KuURzrdXeX/P3NJSAgfT3j5wwVByvx7QcAAArO+fPSZ5+ZQdJnnznOxOTlJXXtagZJPXuag+QCZZmbm1SunLlYwTAcwy1nQ6nMYxsFB5utnmC5uLj0MOnLL3MPkzIyjLz3VETx4u3tGDrltH69fWS+yA+CJQAAcGP++iu9VdJ33zm+Kqlc2Rx0u08fqUsXZlsCipO0phDu7gxsXQrEx5u/hj/4QPriC8eeiY0bSwMHSgMGmFmgYZhLamr267nty+txBXGN4n5cUd0rrSFhfLwZGsbHp6+nzXuQNlxdVNSNfR/5+joXRmV3XLlyBFRlDcESAABwTmqqFB6eHibt2+e4v3Hj9C5uf/sbY6QAQCGJj5c+/TQ9TMo4D0LDhtKgQdL990uNGllXIwpXcrIZOmUOnNLWswujslu/etW83uXL5hIZeWN1lSt34y2oypXjX4iSgmAJBapTp05q1qyZ5s6dK0kKDQ3VqFGjNGrUqBzPsdls+vjjj9WvX78bundBXQcAkI2EBHP2tg0bzNnczpxJ3+fqKt1xhxkk9e4t1a1rXZ0AUMpdvGj+Gv7gA7PHccYwqUEDs2XSwIFmxo/Sz91dqlDBXG5EUlLewqjrBVVpLeXS5iI4dSr/NdlsZmNKZ1pNZRda+foyjGNhI1iCXe/evXXlyhV99dVXWfb9+OOPateunXbt2qXmzZvn+Zo7duyQr69vQZapyZMna/369dq9e7fD9sjISAUGBhbovQCgTIuKMl+9bNhgjvia9namZP631qOHGSb16CHx+xcACs2lS45hUsZfxzffnN4yqUkTXkAjfzw8pKAgc7kRiYnOtZTKbl9cnDn8m2Gkb78RLi5mQJWfVlMZ1318+PnKCcES7EaOHKn77rtPx48fV61atRz2LVmyRM2aNXMqVJKkSpUqFWSJuapSpUqR3QsASiXDMLu1pXVx+/lnx/01a0p9+5ph0h13MEgvABSiy5eljRvNMGnjRscw6aab0lsmNW3Ki10UH56eUqVK5pJfhmEGVDfavS8uzhz2MTU1PbC6Ea6uzoVRQUHmXCVlAcFSETEMsxdBUXMmVe3Vq5cqV66sZcuWadKkSfbtCQkJWrNmjZ577jkNGTJE27Zt07lz51S3bl2NHz9eQ4YMyfGambvCHT58WCNHjlR4eLjq1KmjN954I8s5Y8aM0ccff6yTJ0+qSpUqeuCBB/TSSy/J3d1dy5Yt05QpUySZXd8kaenSpRoxYkSWrnB79uzRs88+qx9//FE+Pj7q37+/5syZo3L/m3llxIgRunDhgm6//XbNnj1bSUlJGjx4sObOnSt3d/e8PWkAUNIlJ0vbtqWHSUePOu5v1Sp9vCQLX71cuyadOyfFxkoxMTl/PHdOKl/eHE+kYcP0j/7+lpQNAE65fFnatCk9TEobmFmS6tVLD5NuuYUwCaWXzWZOJOvlZU42mV+GYf4M3Wj3vvh4M5xKSTEnvz1/Pm/3r15dOnEi//WXJARLRSQhwZqZZC9dMvuU5oWbm5uGDRumZcuW6aWXXrIHN2vXrlVSUpIeeeQRrVq1SmPGjJG/v782btyooUOHqk6dOmrduvV1r5+amqr77rtPQUFB+umnnxQfH5/t2Et+fn5atmyZqlatqj179ujRRx+Vn5+fXnjhBQ0aNEh79+7V559/bu+yFxAQkOUaCQkJuvvuu9WmTRvt2LFD0dHReuSRR/T0009r2bJl9uO++eYbhYSE6JtvvtGRI0c0aNAgNWvWTI8++mjenjQAKIkuXJA+/9wMkjZtcnwLz9NTuusuM0jq1cucPqiAJSdfPyDK/PHCBefusXGj4+fVqjmGTWnrN9rkHwBuVEKC2b3tgw/M7m4Z34yuUyc9TGrWjDAJcIbNZja08PGRbqRzS1ojEWfDqBsd96okIViCg4cfflizZs3S1q1b1blzZ0lmN7j77rtP1apV0/PPP28/9plnntHnn3+utWvX5ilY+uqrr3TgwAEdO3ZM1atXlyTNmDFDPXr0cDjuxRdftK+Hhobqueee05o1a/TCCy/I29tb5cqVk5ubW65d395//31duXJFK1assI/xNG/ePPXu3Vuvvvqqgv8XfQcGBmrevHlydXVVgwYN1LNnT23ZsoVgCUDpc+xYequkb781mwClqVTJDJF695a6dnXqnZCrV83wx5mg6EbGSggMNMOgihWz/1ihgnT2rLR/v7kcOCCdPm0OHnrqlDlUVEaVKmVt3dSokRQSwgs4AIXnyhXHMOny5fR9tWunh0m33cbvIsBqNpvZWMPXV6pa1epqiieCpSLi42O2HrLivs5o0KCB2rVrpyVLlqhz5876888/tW3bNn355ZdKSUnRK6+8ojVr1ujUqVNKTExUYmJingfnPnDggGrWrGkPlSSpbdu2WY778MMPNXfuXB05ckSXLl3StWvX5O9kH4YDBw7o1ltvdaitffv2Sk1N1cGDB+3BUuPGjeXq6mo/JiQkRHv27HHqXgBQLKWmSjt3podJmX+3NWyY3sWtdWvJ1VUJCf8LgA7nPSjK+GLIGTabGQblFBBl9zEwUHLLx38uFy6YAdOBA+lh0/79ZtZ29qyZs337reM5AQFZw6ZGjcxhppj6GEB+XL1qNhb94APp008dXxuEhpqDbw8cKLVoQZgEoGQhWCoiaSlnSTBy5Eg9/fTTmj9/vpYuXapatWrprrvu0qxZs/T6669r7ty5atq0qXx9fTVq1Cglpc0peR2GYWTZZsv0V/Onn37S4MGDNWXKFHXv3l0BAQFavXq1Zs+e7dRjMAwjy7Wzu2fmsZRsNptSU1OduhcAFBtXrkhffy3jkw26vGGLYs8kK0ZBilUVxdhuUWzdVoqp/TfFVm6omGvlFbtLivkiPSTKOJaHM1xdnQuJgoLMcZCKKqApX15q29ZcMrp8WTp40LF10/790p9/ms3Yf/rJXDLy8TGn887cpa5u3fyFXgBKt6tXpS++MMOkDRscw6SaNdNbJrVsSZgEoOTiXyBkMXDgQD377LNauXKlli9frkcffVQ2m03btm1T37599eCDD0oyx0w6fPiwGjZsmKfrNmrUSBERETp9+rSq/q8N4Y8//uhwzA8//KBatWppwoQJ9m3Hjx93OMbDw0MpKSnXvdfy5ct1+fJle6ulH374QS4uLrr55pvzVC8AFAeGIV28mEuroRMJit13RjHHLpmfG80Uq7uUKK9MF5J05H9LLtzdnWtFFBRkDoxdElvx+PpKzZubS0aJidLhw45h0/790qFD5hgLv/xiLhl5eJizNGUMmxo1MqcB9/QsuscEwHqJidKXX5ph0iefmL/D09SoYQZJ998v/e1vhEkASgeCJWRRrlw5DRo0SOPHj1dcXJxGjBghSapXr54++ugjbd++XYGBgZozZ46ioqLyHCx16dJF9evX17BhwzR79mzFx8c7BEhp94iIiNDq1avVqlUrbdy4UR9//LHDMaGhoTp69Kh2796t6tWry8/PT56Z/mt/4IEHNGnSJA0fPlyTJ0/W2bNn9cwzz2jo0KH2bnAAUNTSprt1Zjyi2FhzsOuc+Uiqne0eT09DQUE2p4IiPz9e6Hh6Sk2amEtG165Jf/3lGDaldbFLSJD27TOXjFxczNZMmbvUNWhQcloyA7i+xERzDLe0MCnjWHLVq6d3c/vb30pmEA8AuSFYQrZGjhypd955R926dVPNmjUlSRMnTtTRo0fVvXt3+fj46LHHHlO/fv0Ul3E2oVy4uLjo448/1siRI/W3v/1NoaGhevPNN3X33Xfbj+nbt6/+7//+T08//bQSExPVs2dPTZw4UZMnT7Yf079/f61bt06dO3fWhQsXtHTpUnv4lcbHx0dffPGFnn32WbVq1Uo+Pj7q37+/5syZc8PPDQBIZkh0/rxzM5udO2dOVZsf3p4pCvKIV8XESAUlnVJFxSpIMebH6t6q+Le6CrrrVvNjJZuCgiQfH1uZD4kKkpub2QLp5pulvn3Tt6emmtMJZ+5St3+/GSQePmwun3zieL1atbJ2qWvY0BxLCkDxl5QkffWVGSatX+84wWa1amaYdP/9Ups2hEkASjebkd3AN7iu+Ph4BQQEKC4uLsvA0levXtXRo0dVu3ZteXl55XAFlER8bYHSLznZDAH27TNbp+QUFJ07Z3ZTy49y5fLQesjrsoIO/aCKP25UxW8+lM+F0+kX8PCQ7rzTHHi7d2/z7XAUO4YhRUU5hk1pH6Ojcz6vSpWsXeoaNTJnsCMoBKyVlCRt2ZIeJl24kL4vJCS9ZVLbtoRJAEq23DKPzGixBAAok5KTpSNHzBf5aV2Y9u0zx9HJveuZI39/58YjqlgxlzF3IiLMqYKWbJC++caxkIoVpZ49zTCpWzezzxqKNZvNfKEZEiLddZfjvtjYrF3q9u+XTp40w6ioKOnrrx3PqVAha9jUsKGZKxI4AYUnOdkMk9aulT7+2GytmqZKlfSWSe3bEyYBKJsIlgCgMB07Jq1eLW3aZP63mZfkISCAV4kF6No1c5avjOHRvn3mbGA5BUjlyqUPvFy5cs5frgoVzMZD+WYY5ijQGzaYy+7djvtvusnsc9Wnj/n2N9OOlRoVK0q3324uGcXHS3/8kbVL3dGjZiu57783l4z8/MwxmzK3cgoNNWfsA+C85GQz3//gAzNMOncufV9wsDRggNkyqX17fs4AgP9QAaCgRUaa/4muXp11rvK8cHbu9ooVzUFZyvjbpCkp6QFSxlZIf/xhdl3Ijq+v+QK8ceP0j40bm1NAF1q2d/Wq+WplwwazddKpU+n7XFykdu3MIKlPH6l+/UIqAsWVv785uO/f/ua4/coVMwzN3Mrp8GFzxqkdO8wlIy8v81socyunevXM2f8AOLp2zfz1vHattG6d2bIwTeXKZph0//1Shw6ESQCQEcESABSE2Fjpo4/MMGnr1vTBd2w2qXNn823N8uWvP8LzpUtmQhIdnfsgLJm5uJjhkjN9sgIDS2QLmJQUs/VG5hZIf/xhzsqTHR8f84V1WnCUMUAqkjwuJkbauNEMk774Qrp8OX2fr6/UvbsZJN1zjzmQDpCJt7fUrJm5ZJSUZAaqmbvU/fGHmWH+9pu5ZOTmZjaGy9ylrn598z5AWXLtmvTtt+b7QevWmb+u01SqJPXvb/4Jv+MOwiQAyEnJe0VRgjAueunD1xQOLl40p3latUr68kvzv9M0bdtKQ4aYb2+GhOT9momJ6UFTXqcbi483p6VKm5veGYGBzrWMqlixyJo6pKamB0gZWyAdOGC+YM6Ot7djgJTWCik01IIGXQcPpndx277dfEBpqlZNb5XUubPZtATIBw+P9Nnk+vdP356SYvbEzdyl7sABM78+cMBc1q1LP8dmk2rXztqlrmFDhvRC6ZKSYoZJa9ea7wmdPZu+LyjI/Fm6/36pY8cS+f4LABQ5ZoXLp9xGSE9JSdGhQ4dUuXJlVaxY0aIKURhiY2MVHR2tm2++Wa68bVU2Xblijpe0erX03/86JhzNmkmDB0uDBplJRlFJSjIHf3Bm3vuM09g4q0BHqzbzluPHs7ZAOnDAfLqz4+VljimTuQWSpWPKpKSYAVJamHTokOP+Zs3Sw6TmzRlHC5YwDHOA8OwGDs84hkxm1atnDZsaNTJ/vIGSICVF2rbNbJn00UeOjYIrVpTuu89smdSpE2ESAEjOzQpHsJRP13uSIyMjdeHCBVWuXFk+Pj6y8QKiRDMMQwkJCYqOjlb58uUV4kwLFJR8ycnS5s1mmLR+vdlSKc3NN5stkwYPNpOOkuLaNfNVZF6DqNhY8/j8/skoV06pFYIU4d9E+9ybaZ/RSPuv1tG++Oo6EFNZl5OybwXl6ZkeIGUcA6lOnWLSJeHSJbO12iefmF3dMrYYc3c3WyP16SP17m32uwOKKcMwW21kDpv27zdnqMtJ5cpZu9Q1amTOlMW/PrBaSoo52P3atdKHH0pnzqTvq1DBDJPuv9/8Vc24YwDgiGCpCFzvSTYMQ1FRUbpwI60CUOyUL19eVapUKdKgMCnJ7A50+LA5NfqRI2YrjipVzB5WaR/TFsbHKCBpb22uWmX+N5rxrfyaNc0gafBgsxVKWXn1lJJitnS6TgBlnI3RiSh37TtbWfsu1tA+o5H2qbH2q5Euq1y2l/ZQourroBprX/ri9ZfqBMXLrZIT3fV8fAr/63HypNlabcMGc/7pjCODBwZKPXuaYVL37mbrLqCEO38+vetcxuDp+PGczwkIyL5LXZGNa4YyKzVV+uEHs2XShx86BqOBgdK995otk+68kzAJAHJDsFQE8vokp6SkKDmn+axRori7uxda97fERMfwKGOIdPy449As1+Pvnx4yZQ6dMn4eGFh28pA8MwwpPNxsmbRmjTm7W5rKlc3/RIcMkdq04ZWR0rvUZOy+lvaiM2Ojrozc3VJVv0qcGgedUWO/E2rseUSNbAdU7+peuZ2LTg+pMo5X5QxPT+e76fn55f7DYBjm6MdpXdx27XLcX7eu1LevGSa1b08fCpQZly6Zg4SnBU5pH//8M+e/W2kD6WfuUlenDj86yL/UVLMn8tq15pLxz3f58o5hkoeHZWUCQIlCsFQEnHmSAckciie78OjwYSkiIvceRuXKmdND16tnzuTj42O+AxcVZf7zlLbkNKBxdjw8HIOmnNaDg0v5P/uGIe3ZY4ZJq1ebX6Q05cubI3gOGVKmR/A0DOn06axjIO3fb44bnh03N7OXYOYxkPI0zblhmBd2ppteTIxjyyFnuLvnHDxduCB9+ql04kT68TabOTh72nhJDRqQ0gIZXL1q/m3L3KXu0CGzZ3F23N3NMe2rVTPHc6pWLet61aq5DteGMiY1Vfrpp/SWSadOpe8LCJD69TPDpC5dCJMAID8IlooAwRKyc/Wq+U5tWmujjOHRiRPXD49uuslcMoZI9eqZ4c71XremvRZPC5kyh04ZPz9/Pu+PyWYzX1/npRWUr2/er2u5w4fNIGnVKvOVTxpfX7P1yZAhUrduZeq/UcMwvz+yC5Di4rI/x9U1a4DUqJH5vVukT51hSJcvOxdExcTkPY318TG/H/r0Mbu6Va5cuI8HKIWuXTP/RmbuUpfbQP2ZVaqUfeiUcT0ggKy3tEpNlX7+Ob1l0smT6fv8/R3DJEJIALgxBEtFgGCp7LpyJefw6OTJ3MMjP7+cw6PKlYvuH+HERMegKaf1M2fMYXXyys8v55ZPGT+vWNGif/pPnDC7uK1e7didydNTuucec8ykXr3MEKEUMwzza5s5QNq3L+fJ4lxdze/TzC2Qbr65hGdvCQm5B1CSOVbSnXcygBlQSFJTzb+fp06lf8y8fuqU+bcrL3x9sw+cMn4eHFxMJgDAdaX1Uv/gAzNMytiA1M/PfC9o4EAz+ydMAoCCQ7BUBAiWSreEhPTwKON4R2nhUW78/R3Do4whUqVKJetd1NRU8/X19QKoyEjzOcsrd3fzn/rrBVDBwQUQWkRHm23kV60yp4ZJ4+pqvqU5ZIj5FmdAwA3eqPgxDPPhZ9cCKadpxV1ccg6Q+IcdgFUMw8x6swudMq7ntUWuq6v5d+Z6rZ/Ik61hGNKOHWaQ9MEH5pABacqVcwyTvLysqxMASjOCpSJAsFTyXb6cNTxK+5ixn352AgKyD49uusnC1jgWMgxzENe8dMPLOBt7XlSsmHPXu4zrfn4ZTrpwQfr4YzNM2rIlfRRZm03q0MEMk/r3N5O+UiI62gyMModIOT3fNps55nTmAKl+ff5JB1ByJSQ4tnLKLoCKjMz7pBiBgTmHTmnrFSqUvb/7hcEwzMbEaS2Tjh1L3+fra/ZEHjjQbERK4AcAha9EBUsLFizQrFmzFBkZqcaNG2vu3Lnq0KFDjsfPnz9f8+bN07Fjx1SzZk1NmDBBw4YNs+9ft26dZsyYoSNHjig5OVk33XSTnnvuOQ0dOtR+zOTJkzVlyhSH6wYHBysq43yk10GwVDJcupRzeHT6dO7nBgZm32Xtppv4J/JGJCWZ3bCu1woqKsq5icF8fQ1VKXdJIcknFHJhv6qknlaIIs3lZn9V6d1SIQ92UdAtVUv0hG4xMdl3YYuJyf54m82cbSm7AIl/zAGURdeumX+HrhdA5bUlrpdX9t3tMn5epQpT22fHMKRffkkPkzLOn+HrK/XubYZJd9/N3ywAKGrOZB6WTnG0Zs0ajRo1SgsWLFD79u31n//8Rz169ND+/ftVs2bNLMcvXLhQ48aN06JFi9SqVSuFh4fr0UcfVWBgoHr37i1JqlChgiZMmKAGDRrIw8ND//3vf/XQQw+pcuXK6t69u/1ajRs31ldffWX/vLCmkUfhu3jRDI8yd1k7csRxutnsVKiQe3iEgufhIdWoYS65SU01u2vlGkCdTlXkyVRduuqmy5dt+vOyn/5UI0mNHC92SNJsc3F1deyGl1MrqCpVrO36FRubfQuk6Ojsj7fZpNq1zYGzMwZIDRqU+iGjAMApbm7poU9ODMOctCC3bncnT6bPAfDnn+aSE5vN/NtzvdZP5coV/OMtbgxD2r3bDJM++ED666/0fT4+5lCHAwdKPXrw9wsASgpLWyy1bt1azZs318KFC+3bGjZsqH79+iksLCzL8e3atVP79u01a9Ys+7ZRo0Zp586d+j7j2CmZNG/eXD179tS0adMkmS2W1q9fr927d+e7dlosFa2LF7NvdXTkiBky5KZixezHO6pXj/CoRLp2TfrmG7Ob27p1UlycLslXUaqiyJAWimrbT5E3d1SkqmYJpM6ede5WFSrkbTByf//8t2A7fz77FkhnzuR8Tmho1hZIDRqUsFn5AKAUSEw0W0BnHmg88+d5bYHr75/7mE/Vq5sztZa0lreGIf32W3rLpCNH0vd5ezuGSfwtA4DioUS0WEpKStKuXbs0duxYh+3dunXT9u3bsz0nMTFRXpkG//D29lZ4eLiSk5PlnqmNsWEY+vrrr3Xw4EG9+uqrDvsOHz6sqlWrytPTU61bt9aMGTNUp06dHOtNTExUYobpSOLj4/P0OJF38fHZh0eHD+fcSiNNUFDO4VFgYNHUj0KUmipt326GSWvXOiZE1aqp3KBBqjd4sOq1bJlrwpOcbH4v5aUbXlKS2WLq3Dmz5VBuvL1zDp3S1oOCzMFHM7dCyq1VXa1aWVsgNWxYNt7RBoCSwNPTbC1au3bOx6Smmn+2sgucMn4eH5++HDiQ8/Xc3aWqVXMOn6pVM/dbPeGCYUh79qS3TDp8OH2fl5fUs6cZJvXsSZgEACWdZcFSTEyMUlJSFBwc7LA9t7GOunfvrsWLF6tfv35q3ry5du3apSVLlig5OVkxMTEKCQmRJMXFxalatWpKTEyUq6urFixYoK5du9qv07p1a61YsUI333yzzpw5o+nTp6tdu3bat2+fKlasmO29w8LCsozLBOfFxWXfZe3w4eu3JqlUKfvBsuvWlcqXL5LyUZTSBl5YvVpas8ZxfuGKFaX77zcH4b799jy/devufv3uD2m3Pn8+b7PhxcdLV66Y40JkHBvCGTVqZG2B1LBhpgHJAQAlkouL2Q0uOFhq3jzn4y5ezLnFU9rnZ86Yb5IcP24uualU6fqtn26kxW12DEPauze9ZdLBg+n7vLyke+5JD5N4kwQASg9Lx1iSJFumv2aGYWTZlmbixImKiopSmzZtZBiGgoODNWLECM2cOdNhjCQ/Pz/t3r1bly5d0pYtWzR69GjVqVNHnTp1kiT16NHDfmzTpk3Vtm1b1a1bV8uXL9fo0aOzvfe4ceMc9sXHx6vG9QaJKaMuXMi+y9rhwzkPMJwmODj78Y7q1i2Vs8EjOwcOmC2TVq92fHvT31+6914zTLrzzkIdBdVmM7vBVahghjy5SUhID5tyC6DOnjXfQc7cAqlRI/OhAQDKNj8/s1tzgwY5H5OcbP5NuV4AlZho/t05e9Yczygnvr65j/lUrZr5v9n1hiLdty+9ZdIff6Rv9/Q0u7cNHGh2d+MNEwAonSwLloKCguTq6pqldVJ0dHSWVkxpvL29tWTJEv3nP//RmTNnFBISorffflt+fn4KCgqyH+fi4qJ69epJkpo1a6YDBw4oLCzMHixl5uvrq6ZNm+pwxhexmXh6esrT6jbFxcj589l3WTty5PrTyVepknN4xAvsMuroUTNIWr1a+v339O3e3uaUMIMHm/+ZZuoKWxz4+JizruXSk1aS+S4uMwkCAG6Eu7tUs6a55MQwzG7cuQ06fuqU+b/c5cvSoUPmkhNXV7Nbd3Zd7g4fNsOkjF33PDwcwyT+twOA0s+yYMnDw0MtWrTQ5s2bde+999q3b968WX379s31XHd3d1WvXl2StHr1avXq1UsuuXSFMQzDYXykzBITE3XgwAF16NDByUdRusXGZt9l7cgR8x+W3ISEZB3vKC084t0qSDJHO1271myd9PPP6dvd3c15hQcPlvr0KTVt5QmVAABFwWYze4xXrCjdemvOxyUkZB14PPN6VJSUkmKunzzp+Oc6Iw8PqXt3M0zq3ZtW5gBQ1ljaFW706NEaOnSoWrZsqbZt2+rtt99WRESEnnjiCUlm97NTp05pxYoVkqRDhw4pPDxcrVu31vnz5zVnzhzt3btXy5cvt18zLCxMLVu2VN26dZWUlKRNmzZpxYoVDjPPPf/88+rdu7dq1qyp6OhoTZ8+XfHx8Ro+fHjRPgEWM4z08Ci7cY/On8/9/KpVs7Y6qlfPDI9KSRaAghYbK330kRkmffut+U0omQNQdO5sdnO7916m6wMAoJD5+KS/+ZeTlBRzXKecWj35+0v9+5vvAxEmAUDZZWmwNGjQIMXGxmrq1KmKjIxUkyZNtGnTJtWqVUuSFBkZqYiICPvxKSkpmj17tg4ePCh3d3d17txZ27dvV2hoqP2Yy5cv68knn9TJkyfl7e2tBg0a6L333tOgQYPsx5w8eVJDhgxRTEyMKlWqpDZt2uinn36y37esePhhadmy3I+pVi3n8IgZPJAn8fHSJ5+Y3dy+/NJxzuV27cyWSfffb/aRBAAAxYarq/lGYtWqUqtWVlcDACiubIaR1mQAzoiPj1dAQIDi4uLkX0I7j0+cKE2fbvaXzyk88vGxukqUSFeuSBs3mmHSxo3S1avp+267zQyTBg2SyliYCwAAAAAlgTOZB8FSPpWGYCkuzuwT7+1tdSUoFZKTpc2bzW5u69dLly6l76tf3+zmNniwuQ4AAAAAKLacyTws7QoHa9EXHjcsJUX67juzZdKHHzqO6l6rlhkkDR5sjh7K6NUAAAAAUOoQLAFwjmGY08KsXm3OMRwZmb4vONicEmbIEKlNG8IkAAAAACjlCJYAXJ9hSL//boZJq1dLx46l7wsMNKeEGTJE6tjRHOkTAAAAAFAmECwByNmhQ+lh0oED6dt9faV+/cxubt26mYN1AQAAAADKHIIlAI4iIswubqtWSb/8kr7d01Pq2dMMk3r2ZMpAAAAAAADBEgBJZ86Yg2+vWiX98EP6dldXs0XS4MFS376M+A4AAAAAcECwBJRVFy5I69aZ3dy2bJFSU83tNpt0xx3mmEn9+0tBQZaWCQAAAAAovgiWgLLk8mVpwwYzTPr8cykpKX3f3/5mtkwaOFCqVs26GgEAAAAAJQbBElDaJSaaIdKqVdKnn0oJCen7mjY1w6TBg6U6dayrEQAAAABQIhEsAaXRtWvS11+bYdLHH0txcen76tY1u7kNHiw1bmxdjQAAAACAEo9gCSgtUlPNgbdXr5bWrpXOnk3fV61aesukFi3McZQAAAAAALhBBEtASWYY0q5dZpi0Zo108mT6vqAg6f77zdZJ7dtLLi7W1QkAAAAAKJUIloCSaP9+s5vb6tXSkSPp2/39pfvuM1sm3XWX5MaPOAAAAACg8PCqEyhJUlPNVkjr1qVv8/aW+vQxw6S775a8vKyrDwAAAABQphAsASXJRx+ZoZKbm9Sjh9nNrXdvqVw5qysDAAAAAJRBBEtASXHtmvTii+b6hAnS5MmWlgMAAAAAAKP5AiXFsmXSoUNSxYrS6NFWVwMAAAAAAMESUCJcvSpNmWKujx9vDtINAAAAAIDFCJaAkmDBAunkSal6denJJ62uBgAAAAAASQRLQPEXHy/NmGGuT57MrG8AAAAAgGKDYAko7ubMkWJjpfr1peHDra4GAAAAAAA7giWgODt7Vpo921yfNk1yYyJHAAAAAEDxQbAEFGdhYdKlS1Lz5lL//lZXAwAAAACAA4IloLiKiDAH7ZbMMZZc+HEFAAAAABQvvFIFiqspU6TERKljR6lbN6urAQAAAAAgC4IloDj64w9p2TJzPSxMstksLQcAAAAAgOwQLAHF0cSJUmqq1Lu31Lat1dUAAAAAAJAtgiWguNm1S/rwQ7OV0ssvW10NAAAAAAA5IlgCipvx482PDzwgNW1qbS0AAAAAAOSCYAkoTrZulb78UnJzMwfvBgAAAACgGLM8WFqwYIFq164tLy8vtWjRQtu2bcv1+Pnz56thw4by9vZW/fr1tWLFCof969atU8uWLVW+fHn5+vqqWbNmevfdd2/4vkChMwxp3Dhz/bHHpDp1rK0HAAAAAIDrsDRYWrNmjUaNGqUJEybo119/VYcOHdSjRw9FRERke/zChQs1btw4TZ48Wfv27dOUKVP01FNP6dNPP7UfU6FCBU2YMEE//vijfv/9dz300EN66KGH9MUXX+T7vkCR+PRT6aefJG9v6cUXra4GAAAAAIDrshmGYVh189atW6t58+ZauHChfVvDhg3Vr18/hYWFZTm+Xbt2at++vWbNmmXfNmrUKO3cuVPff/99jvdp3ry5evbsqWnTpuXrvtmJj49XQECA4uLi5O/vn6dzgBylpEi33irt2yeNHSvl8fsQAAAAAICC5kzmYVmLpaSkJO3atUvdunVz2N6tWzdt374923MSExPl5eXlsM3b21vh4eFKTk7OcrxhGNqyZYsOHjyoO+64I9/3Tbt3fHy8wwIUmJUrzVCpfHnphResrgYAAAAAgDyxLFiKiYlRSkqKgoODHbYHBwcrKioq23O6d++uxYsXa9euXTIMQzt37tSSJUuUnJysmJgY+3FxcXEqV66cPDw81LNnT7311lvq2rVrvu8rSWFhYQoICLAvNWrUyO9DBxwlJUmTJpnrL7wgBQZaWw8AAAAAAHlk+eDdNpvN4XPDMLJsSzNx4kT16NFDbdq0kbu7u/r27asRI0ZIklxdXe3H+fn5affu3dqxY4defvlljR49Wlu3bs33fSVp3LhxiouLsy8nTpxw4lECuVi0SDp6VKpSRfrnP62uBgAAAACAPLMsWAoKCpKrq2uWVkLR0dFZWhOl8fb21pIlS5SQkKBjx44pIiJCoaGh8vPzU1BQkP04FxcX1atXT82aNdNzzz2nAQMG2MdOys99JcnT01P+/v4OC3DDLl+W/jf2lyZOlHx9ra0HAAAAAAAnWBYseXh4qEWLFtq8ebPD9s2bN6tdu3a5nuvu7q7q1avL1dVVq1evVq9eveTikvNDMQxDiYmJN3xfoMC9+aZ05oxUu7b0yCNWVwMAAAAAgFPcrLz56NGjNXToULVs2VJt27bV22+/rYiICD3xxBOSzO5np06d0ooVKyRJhw4dUnh4uFq3bq3z589rzpw52rt3r5YvX26/ZlhYmFq2bKm6desqKSlJmzZt0ooVKxxmgLvefYEicf68NHOmuT51quThYW09AAAAAAA4ydJgadCgQYqNjdXUqVMVGRmpJk2aaNOmTapVq5YkKTIyUhEREfbjU1JSNHv2bB08eFDu7u7q3Lmztm/frtDQUPsxly9f1pNPPqmTJ0/K29tbDRo00HvvvadBgwbl+b5AkZg5U7pwQWrSRBoyxOpqAAAAAABwms0wDMPqIkqi+Ph4BQQEKC4ujvGW4LzISKluXenKFemTT6Q+fayuCAAAAAAASc5lHpbPCgeUSdOmmaFS27ZS795WVwMAAAAAQL4QLAFF7c8/pUWLzPUZMySbzdp6AAAAAADIJ4IloKhNmiRduyZ17y516mR1NQAAAAAA5BvBElCU9uyRVq4012fMsLYWAAAAAABuEMESUJQmTJAMQ7r/fql5c6urAQAAAADghhAsAUVl+3bp008lV1dz8G4AAAAAAEo4giWgKBiGNG6cuT5ihFS/vqXlAAAAAABQEAiWgKLwxRfSd99Jnp7m4N0AAAAAAJQCBEtAYUtNlcaPN9effFKqUcPaegAAAAAAKCAES0Bh+/BD6ddfpXLl0rvDAQAAAABQChAsAYXp2jVp4kRz/fnnpUqVrK0HAAAAAIACRLAEFKZly6RDh6SgIGn0aKurAQAAAACgQDkdLIWGhmrq1KmKiIgojHqA0uPqVWnKFHN9/HjJz8/aegAAAAAAKGBOB0vPPfecPvnkE9WpU0ddu3bV6tWrlZiYWBi1ASXbggXSyZPmYN3/+IfV1QAAAAAAUOCcDpaeeeYZ7dq1S7t27VKjRo30z3/+UyEhIXr66af1yy+/FEaNQMkTHy/NmGGuT5okeXlZWw8AAAAAAIUg32Ms3XrrrXrjjTd06tQpTZo0SYsXL1arVq106623asmSJTIMoyDrBEqW2bOl2Fipfn1p+HCrqwEAAAAAoFC45ffE5ORkffzxx1q6dKk2b96sNm3aaOTIkTp9+rQmTJigr776SitXrizIWoGS4exZac4cc33aNMkt3z9mAAAAAAAUa06/4v3ll1+0dOlSrVq1Sq6urho6dKhef/11NWjQwH5Mt27ddMcddxRooUCJMWOGdOmS1Ly51L+/1dUAAAAAAFBonA6WWrVqpa5du2rhwoXq16+f3N3dsxzTqFEjDR48uEAKBEqUiAhz0G5JCguTXPLd2xQAAAAAgGLP6WDpr7/+Uq1atXI9xtfXV0uXLs13UUCJNWWKlJQkdeokde1qdTUAAAAAABQqp5tTREdH6+eff86y/eeff9bOnTsLpCigRPrjD2nZMnM9LEyy2SwtBwAAAACAwuZ0sPTUU0/pxIkTWbafOnVKTz31VIEUBZRIEydKqalSnz5SmzZWVwMAAAAAQKFzOljav3+/mjdvnmX7bbfdpv379xdIUUCJs3On9OGHZiull1+2uhoAAAAAAIqE08GSp6enzpw5k2V7ZGSk3JhWHWXV+PHmxwcekJo0sbYWAAAAAACKiNPBUteuXTVu3DjFxcXZt124cEHjx49XVwYrRln0zTfS5s2Sm5s5eDcAAAAAAGWE002MZs+erTvuuEO1atXSbbfdJknavXu3goOD9e677xZ4gUCxZhjSuHHm+mOPSXXqWFsPAAAAAABFyGYYhuHsSZcvX9b777+v3377Td7e3rrllls0ZMgQubu7F0aNxVJ8fLwCAgIUFxcnf39/q8uBVT75ROrXT/LxkY4ckUJCrK4IAAAAAIAb4kzmka9BkXx9ffXYY4/lqzig1EhJkSZMMNeffZZQCQAAAABQ5uR7tO39+/crIiJCSUlJDtv79Olzw0UBJcLKldK+fVL58tK//mV1NQAAAAAAFDmng6W//vpL9957r/bs2SObzaa0nnQ2m02SlJKSUrAVAsVRUpI0aZK5PmaMFBhobT0AAAAAAFjA6Vnhnn32WdWuXVtnzpyRj4+P9u3bp++++04tW7bU1q1bnS5gwYIFql27try8vNSiRQtt27Yt1+Pnz5+vhg0bytvbW/Xr19eKFSsc9i9atEgdOnRQYGCgAgMD1aVLF4WHhzscM3nyZNlsNoelSpUqTteOMmzRIunoUalKFemf/7S6GgAAAAAALOF0sPTjjz9q6tSpqlSpklxcXOTi4qLbb79dYWFh+qeTL7DXrFmjUaNGacKECfr111/VoUMH9ejRQxEREdkev3DhQo0bN06TJ0/Wvn37NGXKFD311FP69NNP7cds3bpVQ4YM0TfffKMff/xRNWvWVLdu3XTq1CmHazVu3FiRkZH2Zc+ePc4+FSirLl+Wpk0z1ydONAfuBgAAAACgDHI6WEpJSVG5cuUkSUFBQTp9+rQkqVatWjp48KBT15ozZ45GjhypRx55RA0bNtTcuXNVo0YNLVy4MNvj3333XT3++OMaNGiQ6tSpo8GDB2vkyJF69dVX7ce8//77evLJJ9WsWTM1aNBAixYtUmpqqrZs2eJwLTc3N1WpUsW+VKpUyanaUYa98YZ05oxUu7b0yCNWVwMAAAAAgGWcDpaaNGmi33//XZLUunVrzZw5Uz/88IOmTp2qOnXq5Pk6SUlJ2rVrl7p16+awvVu3btq+fXu25yQmJsrLy8thm7e3t8LDw5WcnJztOQkJCUpOTlaFChUcth8+fFhVq1ZV7dq1NXjwYP3111+51puYmKj4+HiHBWXQuXPSzJnm+tSpkoeHtfUAAAAAAGAhp4OlF198UampqZKk6dOn6/jx4+rQoYM2bdqkN998M8/XiYmJUUpKioKDgx22BwcHKyoqKttzunfvrsWLF2vXrl0yDEM7d+7UkiVLlJycrJiYmGzPGTt2rKpVq6YuXbrYt7Vu3VorVqzQF198oUWLFikqKkrt2rVTbGxsjvWGhYUpICDAvtSoUSPPjxWlyMyZUlyc1LSpNGSI1dUAAAAAAGApp2eF6969u329Tp062r9/v86dO6fAwED7zHDOyHyOYRg5XmfixImKiopSmzZtZBiGgoODNWLECM2cOVOurq5Zjp85c6ZWrVqlrVu3OrR06tGjh329adOmatu2rerWravly5dr9OjR2d573LhxDvvi4+MJl8qayEgpLTx9+WUpm+85AAAAAADKEqdaLF27dk1ubm7au3evw/YKFSo4HSoFBQXJ1dU1S+uk6OjoLK2Y0nh7e2vJkiVKSEjQsWPHFBERodDQUPn5+SkoKMjh2Ndee00zZszQl19+qVtuuSXXWnx9fdW0aVMdPnw4x2M8PT3l7+/vsKCMmTZNunJFattW6tXL6moAAAAAALCcU8GSm5ubatWqpZSUlBu+sYeHh1q0aKHNmzc7bN+8ebPatWuX67nu7u6qXr26XF1dtXr1avXq1UsuLukPZdasWZo2bZo+//xztWzZ8rq1JCYm6sCBAwoJCcnfg0Hp9+ef0qJF5npYmJSP1nkAAAAAAJQ2+Rpjady4cTp37twN33z06NFavHixlixZogMHDuj//u//FBERoSeeeEKS2f1s2LBh9uMPHTqk9957T4cPH1Z4eLgGDx6svXv3asaMGfZjZs6cqRdffFFLlixRaGiooqKiFBUVpUuXLtmPef755/Xtt9/q6NGj+vnnnzVgwADFx8dr+PDhN/yYUEpNmiRduyZ17y517Gh1NQAAAAAAFAtOj7H05ptv6siRI6patapq1aolX19fh/2//PJLnq81aNAgxcbGaurUqYqMjFSTJk20adMm1apVS5IUGRmpiIgI+/EpKSmaPXu2Dh48KHd3d3Xu3Fnbt29XaGio/ZgFCxYoKSlJAwYMcLjXpEmTNHnyZEnSyZMnNWTIEMXExKhSpUpq06aNfvrpJ/t9AQe//y6tXGmuZwgxAQAAAAAo62yGYRjOnDBlypRc90+aNOmGCiop4uPjFRAQoLi4OMZbKu1695b++1/p/vulDz6wuhoAAAAAAAqVM5mH08ESTARLZcQPP0i3327OALdvn1S/vtUVAQAAAABQqJzJPJweYwkoMwxDGj/eXH/oIUIlAAAAAAAycXqMJRcXF9lymRGrIGaMA4qFL76QvvtO8vQ0B+8GAAAAAAAOnA6WPv74Y4fPk5OT9euvv2r58uXXHX8JKDFSU9NbKz31lFS9urX1AAAAAABQDBXYGEsrV67UmjVr9MknnxTE5Yo9xlgq5T74QBo0SPLzk/76SwoKsroiAAAAAACKhCVjLLVu3VpfffVVQV0OsE5ysvTii+b6c88RKgEAAAAAkIMCCZauXLmit956S9XpLoTSYNky6fBhM1AaPdrqagAAAAAAKLacHmMpMDDQYfBuwzB08eJF+fj46L333ivQ4oAid+WKlDZW2PjxZlc4AAAAAACQLaeDpddff90hWHJxcVGlSpXUunVrBQYGFmhxQJFbsEA6dUqqUUP6xz+srgYAAAAAgGLN6WBpxIgRhVAGUAzEx0thYeb65MmSl5el5QAAAAAAUNw5PcbS0qVLtXbt2izb165dq+XLlxdIUYAlZs+WYmOlBg2kYcOsrgYAAAAAgGLP6WDplVdeUVA2s2RVrlxZM2bMKJCigCJ39qw0Z465Pm2a5OZ0Yz4AAAAAAMocp4Ol48ePq3bt2lm216pVSxEREQVSFFDkZsyQLl2SWrSQ+ve3uhoAAAAAAEoEp4OlypUr6/fff8+y/bffflPFihULpCigSEVEmIN2S2bAlGFwegAAAAAAkDOng6XBgwfrn//8p7755hulpKQoJSVFX3/9tZ599lkNHjy4MGoECtfkyVJSktSpk9S1q9XVAAAAAABQYjg9kMz06dN1/Phx3XXXXXL73zg0qampGjZsGGMsoeQ5cEBKG3Q+LIzWSgAAAAAAOMFmGIaRnxMPHz6s3bt3y9vbW02bNlWtWrUKurZiLT4+XgEBAYqLi5O/v7/V5SC/BgyQPvpI6ttXWr/e6moAAAAAALCcM5lHvqe+uummm3TTTTfl93TAejt3mqGSzSZNn251NQAAAAAAlDhOj7E0YMAAvfLKK1m2z5o1S/fff3+BFAUUifHjzY8PPig1aWJtLQAAAAAAlEBOB0vffvutevbsmWX73Xffre+++65AigIK3TffSJs3S+7u0pQpVlcDAAAAAECJ5HSwdOnSJXl4eGTZ7u7urvj4+AIpCihUhiGNG2euP/aYVLu2tfUAAAAAAFBCOR0sNWnSRGvWrMmyffXq1WrUqFGBFAUUqg0bpJ9/lnx8pBdftLoaAAAAAABKLKcH7544caL69++vP//8U3feeackacuWLVq5cqU+/PDDAi8QKFApKeljKz37rFSlirX1AAAAAABQgjkdLPXp00fr16/XjBkz9OGHH8rb21u33nqrvv766+tOQQdY7v33pf37pfLlpX/9y+pqAAAAAAAo0WyGYRg3coELFy7o/fff1zvvvKPffvtNKSkpBVVbsRYfH6+AgADFxcURqJUUSUlS/frSsWPSK69IY8ZYXREAAAAAAMWOM5mH02Mspfn666/14IMPqmrVqpo3b57uuece7dy5M7+XAwrf22+boVJIiPTMM1ZXAwAAAABAiedUV7iTJ09q2bJlWrJkiS5fvqyBAwcqOTlZH330EQN3o3i7fFmaPt1cnzjRHLgbAAAAAADckDy3WLrnnnvUqFEj7d+/X2+99ZZOnz6tt956qzBrAwrOG29IZ85IdepII0daXQ0AAAAAAKVCnlssffnll/rnP/+pf/zjH7rpppsKsyagYJ07J82caa5PnSp5eFhbDwAAAAAApUSeWyxt27ZNFy9eVMuWLdW6dWvNmzdPZ8+eLczagIIxc6YUFyc1bSoNGWJ1NQAAAAAAlBp5Dpbatm2rRYsWKTIyUo8//rhWr16tatWqKTU1VZs3b9bFixcLs04gf06fNrvBSdLLL0su+R6vHgAAAAAAZOL0q2wfHx89/PDD+v7777Vnzx4999xzeuWVV1S5cmX16dPH6QIWLFig2rVry8vLSy1atNC2bdtyPX7+/Plq2LChvL29Vb9+fa1YscJh/6JFi9ShQwcFBgYqMDBQXbp0UXh4+A3fFyXUtGnS1atS27ZSr15WVwMAAAAAQKlyQ8036tevr5kzZ+rkyZNatWqV0+evWbNGo0aN0oQJE/Trr7+qQ4cO6tGjhyIiIrI9fuHChRo3bpwmT56sffv2acqUKXrqqaf06aef2o/ZunWrhgwZom+++UY//vijatasqW7duunUqVP5vi9KqD//lBYvNtdfeUWy2aytBwAAAACAUsZmGIZh1c1bt26t5s2ba+HChfZtDRs2VL9+/RQWFpbl+Hbt2ql9+/aaNWuWfduoUaO0c+dOff/999neIyUlRYGBgZo3b56GDRuWr/tmJz4+XgEBAYqLi5O/v3+ezkERe+ABaeVK6e67pc8+s7oaAAAAAABKBGcyD8sGnElKStKuXbvUrVs3h+3dunXT9u3bsz0nMTFRXl5eDtu8vb0VHh6u5OTkbM9JSEhQcnKyKlSokO/7pt07Pj7eYUEx9vvvUloruhkzrK0FAAAAAIBSyrJgKSYmRikpKQoODnbYHhwcrKioqGzP6d69uxYvXqxdu3bJMAzt3LlTS5YsUXJysmJiYrI9Z+zYsapWrZq6dOmS7/tKUlhYmAICAuxLjRo1nHm4KGoTJkiGIQ0cKN12m9XVAAAAAABQKlk+RZYt07g3hmFk2ZZm4sSJ6tGjh9q0aSN3d3f17dtXI0aMkCS5urpmOX7mzJlatWqV1q1bl6WlkzP3laRx48YpLi7Ovpw4cSIvDw9W+OEH6b//lVxdzcG7AQAAAABAobAsWAoKCpKrq2uWVkLR0dFZWhOl8fb21pIlS5SQkKBjx44pIiJCoaGh8vPzU1BQkMOxr732mmbMmKEvv/xSt9xyyw3dV5I8PT3l7+/vsKAYMgxp3Dhz/aGHpJtvtrYeAAAAAABKMcuCJQ8PD7Vo0UKbN2922L5582a1a9cu13Pd3d1VvXp1ubq6avXq1erVq5dcXNIfyqxZszRt2jR9/vnnatmyZYHdFyXA559L27ZJnp7SpElWVwMAAAAAQKnmZuXNR48eraFDh6ply5Zq27at3n77bUVEROiJJ56QZHY/O3XqlFasWCFJOnTokMLDw9W6dWudP39ec+bM0d69e7V8+XL7NWfOnKmJEydq5cqVCg0NtbdMKleunMqVK5en+6KESk2Vxo831596Sqpe3dp6AAAAAAAo5SwNlgYNGqTY2FhNnTpVkZGRatKkiTZt2qRatWpJkiIjIxUREWE/PiUlRbNnz9bBgwfl7u6uzp07a/v27QoNDbUfs2DBAiUlJWnAgAEO95o0aZImT56cp/uihFq7Vtq9W/LzS+8OBwAAAAAACo3NMAzD6iJKovj4eAUEBCguLo7xloqD5GSpcWPp8GFpyhTppZesrggAAAAAgBLJmczD8lnhgAKxbJkZKlWqJP3f/1ldDQAAAAAAZQLBEkq+K1fMVkqSOcaSn5+19QAAAAAAUEYQLKHkW7BAOnVKqlFDYgB2AAAAAACKDMESSra4OCkszFyfPFny8rK0HAAAAAAAyhKCJZRss2dLsbFSgwbSsGFWVwMAAAAAQJlCsISSKzpamjPHXJ82TXJzs7YeAAAAAADKGIIllFwzZkiXL0stWkj9+1tdDQAAAAAAZQ7BEkqm48elhQvN9bAwyWazth4AAAAAAMoggiWUTFOmSElJUufOUpcuVlcDAAAAAECZRLCEkufAAWn5cnN9xgxaKwEAAAAAYBGCJZQ8EydKqalS375SmzZWVwMAAAAAQJlFsISSZccO6aOPzFZK06dbXQ0AAAAAAGUawRJKlvHjzY8PPig1aWJtLQAAAAAAlHEESyg5vv5a+uoryd3dHLwbAAAAAABYimAJJYNhSOPGmeuPPy7Vrm1tPQAAAAAAgGAJJcQnn0jh4ZKPj/Tii1ZXAwAAAAAARLCEkiAlRZowwVwfNUoKDra0HAAAAAAAYCJYQvH3/vvS/v1SYKD0r39ZXQ0AAAAAAPgfgiUUb0lJ0qRJ5vqYMVL58paWAwAAAAAA0hEsoXh7+23p2DEpJER65hmrqwEAAAAAABkQLKH4unRJmjbNXJ840Ry4GwAAAAAAFBsESyi+3nhDio6W6tSRRo60uhoAAAAAAJAJwRKKp3PnpFmzzPVp0yQPD2vrAQAAAAAAWRAsoXh69VUpLk665RZp8GCrqwEAAAAAANkgWELxc/q09Oab5vrLL0sufJsCAAAAAFAc8Yodxc+0adLVq1K7dlLPnlZXAwAAAAAAckCwhOLlzz+lxYvN9bAwyWazth4AAAAAAJAjgiUULy+9JF27Jt19t3THHVZXAwAAAAAAckGwhOLjt9+klSvN9RkzrK0FAAAAAABcF8ESio8JE8yPAwdKt91mbS0AAAAAAOC6CJZQPPzwg7Rxo+Tqag7eDQAAAAAAij3Lg6UFCxaodu3a8vLyUosWLbRt27Zcj58/f74aNmwob29v1a9fXytWrHDYv2/fPvXv31+hoaGy2WyaO3dulmtMnjxZNpvNYalSpUpBPiw4wzCkcePM9Ycflm6+2dp6AAAAAABAnlgaLK1Zs0ajRo3ShAkT9Ouvv6pDhw7q0aOHIiIisj1+4cKFGjdunCZPnqx9+/ZpypQpeuqpp/Tpp5/aj0lISFCdOnX0yiuv5BoWNW7cWJGRkfZlz549Bf74kEeffy5t2yZ5epqDdwMAAAAAgBLBzcqbz5kzRyNHjtQjjzwiSZo7d66++OILLVy4UGFhYVmOf/fdd/X4449r0KBBkqQ6derop59+0quvvqrevXtLklq1aqVWrVpJksaOHZvjvd3c3GilVBykpkrjx5vrTz8tVa9ubT0AAAAAACDPLGuxlJSUpF27dqlbt24O27t166bt27dne05iYqK8vLwctnl7eys8PFzJyclO3f/w4cOqWrWqateurcGDB+uvv/7K9fjExETFx8c7LCgAa9dKu3dLfn5SLkEgAAAAAAAofiwLlmJiYpSSkqLg4GCH7cHBwYqKisr2nO7du2vx4sXatWuXDMPQzp07tWTJEiUnJysmJibP927durVWrFihL774QosWLVJUVJTatWun2NjYHM8JCwtTQECAfalRo0ae74ccJCdLEyea688/LwUFWVsPAAAAAABwiuWDd9tsNofPDcPIsi3NxIkT1aNHD7Vp00bu7u7q27evRowYIUlydXXN8z179Oih/v37q2nTpurSpYs2btwoSVq+fHmO54wbN05xcXH25cSJE3m+H3KwdKl0+LBUqZL0f/9ndTUAAAAAAMBJlgVLQUFBcnV1zdI6KTo6OksrpjTe3t5asmSJEhISdOzYMUVERCg0NFR+fn4KuoHWLr6+vmratKkOHz6c4zGenp7y9/d3WHADrlyRpkwx18ePN7vCAQAAAACAEsWyYMnDw0MtWrTQ5s2bHbZv3rxZ7dq1y/Vcd3d3Va9eXa6urlq9erV69eolF5f8P5TExEQdOHBAISEh+b4GnDR/vnT6tFSzpvTEE1ZXAwAAAAAA8sHSWeFGjx6toUOHqmXLlmrbtq3efvttRURE6In/BQ3jxo3TqVOntGLFCknSoUOHFB4ertatW+v8+fOaM2eO9u7d69CFLSkpSfv377evnzp1Srt371a5cuVUr149SdLzzz+v3r17q2bNmoqOjtb06dMVHx+v4cOHF/EzUEbFxUlps/5NnixlGpAdAAAAAACUDJYGS4MGDVJsbKymTp2qyMhINWnSRJs2bVKtWrUkSZGRkYqIiLAfn5KSotmzZ+vgwYNyd3dX586dtX37doWGhtqPOX36tG677Tb756+99ppee+01dezYUVu3bpUknTx5UkOGDFFMTIwqVaqkNm3a6KeffrLfF4Vs9mzp3DmpQQNp6FCrqwEAAAAAAPlkMwzDsLqIkig+Pl4BAQGKi4tjvCVnREdLdepIly9LH34o9e9vdUUAAAAAACADZzIPy2eFQxkzY4YZKrVsKd13n9XVAAAAAACAG0CwhKJz/Li0cKG5PmOGZLNZWw8AAAAAALghBEsoOpMnS0lJUufOUpcuVlcDAAAAAABuEMESisb+/dL/ZvejtRIAAAAAAKUDwRKKxsSJUmqq1K+f1KaN1dUAAAAAAIACQLCEwrdjh7RundlKafp0q6sBAAAAAAAFhGAJhW/8ePPj0KFS48bW1gIAAAAAAAoMwRIK19dfS199Jbm7S1OmWF0NAAAAAAAoQARLKDyGIY0bZ64//rgUGmppOQAAAAAAoGARLKHwrF8vhYdLPj7Siy9aXQ0AAAAAAChgBEsoHCkp6WHSqFFScLCl5QAAAAAAgIJHsITC8d570v79UmCg9K9/WV0NAAAAAAAoBARLKHiJidKkSeb62LFS+fKWlgMAAAAAAAoHwRIK3ttvS8ePSyEh0tNPW10NAAAAAAAoJARLKFiXLknTp5vrL71kDtwNAAAAAABKJYIlFKw33pCio6W6daWRI62uBgAAAAAAFCKCJRSc2Fhp5kxzfepUyd3d2noAAAAAAEChIlhCwXn1VSk+XrrlFmnwYKurAQAAAAAAhYxgCQXj1CnprbfM9Zdfllz41gIAAAAAoLTj1T8KxrRp0tWrUrt2Us+eVlcDAAAAAACKAMESbtyRI9I775jrr7wi2WzW1gMAAAAAAIoEwRJu3EsvSdeuST16SB06WF0NAAAAAAAoIgRLuDG//SatWmWuv/yytbUAAAAAAIAiRbCEGzNhgvlx0CDpttusrQUAAAAAABQpgiXk3/ffSxs3Sq6u5uDdAAAAAACgTCFYQv4YhjRunLn+8MPSTTdZWw8AAAAAAChyBEvIn88+M1sseXqag3cDAAAAAIAyh2AJzktNlcaPN9efflqqXt3aegAAAAAAgCUIluC8Dz4wZ4Pz90/vDgcAAAAAAMocgiU4JzlZmjjRXH/+ealiRWvrAQAAAAAAliFYgnOWLpWOHJEqVZJGjbK6GgAAAAAAYCHLg6UFCxaodu3a8vLyUosWLbRt27Zcj58/f74aNmwob29v1a9fXytWrHDYv2/fPvXv31+hoaGy2WyaO3dugdwXkq5ckaZMMdcnTJD8/KytBwAAAAAAWMrSYGnNmjUaNWqUJkyYoF9//VUdOnRQjx49FBERke3xCxcu1Lhx4zR58mTt27dPU6ZM0VNPPaVPP/3UfkxCQoLq1KmjV155RVWqVCmQ++J/5s+XTp+WataUnnjC6moAAAAAAIDFbIZhGFbdvHXr1mrevLkWLlxo39awYUP169dPYWFhWY5v166d2rdvr1mzZtm3jRo1Sjt37tT333+f5fjQ0FCNGjVKozJ12XL2vtmJj49XQECA4uLi5O/vn6dzSrS4OKlOHencOWnJEumhh6yuCAAAAAAAFAJnMg/LWiwlJSVp165d6tatm8P2bt26afv27dmek5iYKC8vL4dt3t7eCg8PV3JycqHdN+3e8fHxDkuZ8tprZqjUoIE0dKjV1QAAAAAAgGLAsmApJiZGKSkpCg4OdtgeHBysqKiobM/p3r27Fi9erF27dskwDO3cuVNLlixRcnKyYmJiCu2+khQWFqaAgAD7UqNGjTzdr1Q4c0Z6/XVzffp0yc3N2noAAAAAAECxYPng3TabzeFzwzCybEszceJE9ejRQ23atJG7u7v69u2rESNGSJJcXV0L7b6SNG7cOMXFxdmXEydOOHW/Em3GDOnyZallS+m++6yuBgAAAAAAFBOWBUtBQUFydXXN0kooOjo6S2uiNN7e3lqyZIkSEhJ07NgxRUREKDQ0VH5+fgoKCiq0+0qSp6en/P39HZYy4fhx6d//NtfDwqRcwjcAAAAAAFC2WBYseXh4qEWLFtq8ebPD9s2bN6tdu3a5nuvu7q7q1avL1dVVq1evVq9eveTikreHciP3LZMmT5aSkqQ775S6dLG6GgAAAAAAUIxYOljO6NGjNXToULVs2VJt27bV22+/rYiICD3xv6nsx40bp1OnTmnFihWSpEOHDik8PFytW7fW+fPnNWfOHO3du1fLly+3XzMpKUn79++3r586dUq7d+9WuXLlVK9evTzdF/+zf7/0v+deM2ZYWwsAAAAAACh2LA2WBg0apNjYWE2dOlWRkZFq0qSJNm3apFq1akmSIiMjFRERYT8+JSVFs2fP1sGDB+Xu7q7OnTtr+/btCg0NtR9z+vRp3XbbbfbPX3vtNb322mvq2LGjtm7dmqf74n8mTpRSU6V+/aTWra2uBgAAAAAAFDM2wzAMq4soieLj4xUQEKC4uLjSOd5SeLgZJtls0p49UuPGVlcEAAAAAACKgDOZh+WzwqGYGj/e/Dh0KKESAAAAAADIFsESstqyxVzc3aUpU6yuBgAAAAAAFFMES3BkGOmtlZ54QsowfhUAAAAAAEBGBEtwtH69Ob6Sr680YYLV1QAAAAAAgGKMYAnpUlKkF18010eNkoKDLS0HAAAAAAAUbwRLSPfee9L+/VJgoPT881ZXAwAAAAAAijmCJZgSE6VJk8z1sWOl8uUtLQcAAAAAABR/BEsw/ec/0vHjUkiI9PTTVlcDAAAAAABKAIIlSJcuSdOnm+svvST5+FhbDwAAAAAAKBEIliDNnSudPSvVrSuNHGl1NQAAAAAAoIQgWCrrYmOlWbPM9WnTJHd3a+sBAAAAAAAlBsFSWffqq1J8vHTrrdKgQVZXAwAAAAAAShCCpbLs1CnprbfM9Zdfllz4dgAAAAAAAHlHklCWTZsmXb0qtW8v3XOP1dUAAAAAAIAShmCpLGvbVqpeXQoLk2w2q6sBAAAAAAAljM0wDMPqIkqi+Ph4BQQEKC4uTv7+/laXk39JSZKHh9VVAAAAAACAYsKZzIMWS2UdoRIAAAAAAMgngiUAAAAAAADkC8ESAAAAAAAA8oVgCQAAAAAAAPlCsAQAAAAAAIB8IVgCAAAAAABAvhAsAQAAAAAAIF8IlgAAAAAAAJAvBEsAAAAAAADIF4IlAAAAAAAA5AvBEgAAAAAAAPLFzeoCSirDMCRJ8fHxFlcCAAAAAABQcNKyjrTsIzcES/l08eJFSVKNGjUsrgQAAAAAAKDgXbx4UQEBAbkeYzPyEj8hi9TUVJ0+fVp+fn6y2WxWl4MyJD4+XjVq1NCJEyfk7+9vdTlAqcXPGlA0+FkDig4/b0DRKA0/a4Zh6OLFi6patapcXHIfRYkWS/nk4uKi6tWrW10GyjB/f/8S+0sKKEn4WQOKBj9rQNHh5w0oGiX9Z+16LZXSMHg3AAAAAAAA8oVgCQAAAAAAAPlCsASUMJ6enpo0aZI8PT2tLgUo1fhZA4oGP2tA0eHnDSgaZe1njcG7AQAAAAAAkC+0WAIAAAAAAEC+ECwBAAAAAAAgXwiWAAAAAAAAkC8ESwAAAAAAAMgXgiWghAgLC1OrVq3k5+enypUrq1+/fjp48KDVZQGlXlhYmGw2m0aNGmV1KUCpc+rUKT344IOqWLGifHx81KxZM+3atcvqsoBS5dq1a3rxxRdVu3ZteXt7q06dOpo6dapSU1OtLg0o8b777jv17t1bVatWlc1m0/r16x32G4ahyZMnq2rVqvL29lanTp20b98+a4otRARLQAnx7bff6qmnntJPP/2kzZs369q1a+rWrZsuX75sdWlAqbVjxw69/fbbuuWWW6wuBSh1zp8/r/bt28vd3V2fffaZ9u/fr9mzZ6t8+fJWlwaUKq+++qr+/e9/a968eTpw4IBmzpypWbNm6a233rK6NKDEu3z5sm699VbNmzcv2/0zZ87UnDlzNG/ePO3YsUNVqlRR165ddfHixSKutHDZDMMwrC4CgPPOnj2rypUr69tvv9Udd9xhdTlAqXPp0iU1b95cCxYs0PTp09WsWTPNnTvX6rKAUmPs2LH64YcftG3bNqtLAUq1Xr16KTg4WO+88459W//+/eXj46N3333XwsqA0sVms+njjz9Wv379JJmtlapWrapRo0ZpzJgxkqTExEQFBwfr1Vdf1eOPP25htQWLFktACRUXFydJqlChgsWVAKXTU089pZ49e6pLly5WlwKUShs2bFDLli11//33q3Llyrrtttu0aNEiq8sCSp3bb79dW7Zs0aFDhyRJv/32m77//nvdc889FlcGlG5Hjx5VVFSUunXrZt/m6empjh07avv27RZWVvDcrC4AgPMMw9Do0aN1++23q0mTJlaXA5Q6q1ev1i+//KIdO3ZYXQpQav31119auHChRo8erfHjxys8PFz//Oc/5enpqWHDhlldHlBqjBkzRnFxcWrQoIFcXV2VkpKil19+WUOGDLG6NKBUi4qKkiQFBwc7bA8ODtbx48etKKnQECwBJdDTTz+t33//Xd9//73VpQClzokTJ/Tss8/qyy+/lJeXl9XlAKVWamqqWrZsqRkzZkiSbrvtNu3bt08LFy4kWAIK0Jo1a/Tee+9p5cqVaty4sXbv3q1Ro0apatWqGj58uNXlAaWezWZz+NwwjCzbSjqCJaCEeeaZZ7RhwwZ99913ql69utXlAKXOrl27FB0drRYtWti3paSk6LvvvtO8efOUmJgoV1dXCysESoeQkBA1atTIYVvDhg310UcfWVQRUDr961//0tixYzV48GBJUtOmTXX8+HGFhYURLAGFqEqVKpLMlkshISH27dHR0VlaMZV0jLEElBCGYejpp5/WunXr9PXXX6t27dpWlwSUSnfddZf27Nmj3bt325eWLVvqgQce0O7duwmVgALSvn17HTx40GHboUOHVKtWLYsqAkqnhIQEubg4vuxzdXVVamqqRRUBZUPt2rVVpUoVbd682b4tKSlJ3377rdq1a2dhZQWPFktACfHUU09p5cqV+uSTT+Tn52fvsxsQECBvb2+LqwNKDz8/vyxjl/n6+qpixYqMaQYUoP/7v/9Tu3btNGPGDA0cOFDh4eF6++239fbbb1tdGlCq9O7dWy+//LJq1qypxo0b69dff9WcOXP08MMPW10aUOJdunRJR44csX9+9OhR7d69WxUqVFDNmjU1atQozZgxQzfddJNuuukmzZgxQz4+Pvr73/9uYdUFz2YYhmF1EQCuL6d+uEuXLtWIESOKthigjOnUqZOaNWumuXPnWl0KUKr897//1bhx43T48GHVrl1bo0eP1qOPPmp1WUCpcvHiRU2cOFEff/yxoqOjVbVqVQ0ZMkQvvfSSPDw8rC4PKNG2bt2qzp07Z9k+fPhwLVu2TIZhaMqUKfrPf/6j8+fPq3Xr1po/f36pe7OSYAkAAAAAAAD5whhLAAAAAAAAyBeCJQAAAAAAAOQLwRIAAAAAAADyhWAJAAAAAAAA+UKwBAAAAAAAgHwhWAIAAAAAAEC+ECwBAAAAAAAgXwiWAAAAAAAAkC8ESwAAAKWYzWbT+vXrrS4DAACUUgRLAAAAhWTEiBGy2WxZlrvvvtvq0gAAAAqEm9UFAAAAlGZ33323li5d6rDN09PTomoAAAAKFi2WAAAACpGnp6eqVKnisAQGBkoyu6ktXLhQPXr0kLe3t2rXrq21a9c6nL9nzx7deeed8vb2VsWKFfXYY4/p0qVLDscsWbJEjRs3lqenp0JCQvT000877I+JidG9994rHx8f3XTTTdqwYUPhPmgAAFBmECwBAABYaOLEierfv79+++03PfjggxoyZIgOHDggSUpISNDdd9+twMBA7dixQ2vXrtVXX33lEBwtXLhQTz31lB577DHt2bNHGzZsUL169RzuMWXKFA0cOFC///677rnnHj3wwAM6d+5ckT5OAABQOtkMwzCsLgIAAKA0GjFihN577z15eXk5bB8zZowmTpwom82mJ554QgsXLrTva9OmjZo3b64FCxZo0aJFGjNmjE6cOCFfX19J0qZNm9S7d2+dPn1awcHBqlatmh566CFNnz492xpsNptefPFFTZs2TZJ0+fJl+fn5adOmTYz1BAAAbhhjLAEAABSizp07OwRHklShQgX7etu2bR32tW3bVrt375YkHThwQLfeeqs9VJKk9u3bKzU1VQcPHpTNZtPp06d111135VrDLbfcYl/39fWVn5+foqOj8/uQAAAA7AiWAAAACpGvr2+WrmnXY7PZJEmGYdjXszvG29s7T9dzd3fPcm5qaqpTNQEAAGSHMZYAAAAs9NNPP2X5vEGDBpKkRo0aaffu3bp8+bJ9/w8//CAXFxfdfPPN8vPzU2hoqLZs2VKkNQMAAKShxRIAAEAhSkxMVFRUlMM2Nzc3BQUFSZLWrl2rli1b6vbbb9f777+v8PBwvfPOO5KkBx54QJMmTdLw4cM1efJknT17Vs8884yGDh2q4OBgSdLkyZP1xBNPqHLlyurRo4cuXryoH374Qc8880zRPlAAAFAmESwBAAAUos8//1whISEO2+rXr68//vhDkjlj2+rVq/Xkk0+qSpUqev/999WoUSNJko+Pj7744gs9++yzatWqlXx8fNS/f3/NmTPHfq3hw4fr6tWrev311/X8888rKChIAwYMKLoHCAAAyjRmhQMAALCIzWbTxx9/rH79+lldCgAAQL4wxhIAAAAAAADyhWAJAAAAAAAA+cIYSwAAABZhRAIAAFDS0WIJAAAAAAAA+UKwBAAAAAAAgHwhWAIAAAAAAEC+ECwBAAAAAAAgXwiWAAAAAAAAkC8ESwAAAAAAAMgXgiUAAAAAAADkC8ESAAAAAAAA8uX/Aa97KLwlgQOhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the training and validation accuracies as functions of epoch\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'val_accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMF7V5ii2RGc"
   },
   "source": [
    "Assess the performance of the model on the validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "9n2ZYiZ47sS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.7743\n",
      "The loss value of the model on the validation data is 0.8061050772666931\n",
      "The accuracy of the model on the validation data is 0.9381333589553833\n"
     ]
    }
   ],
   "source": [
    "# Compute the final accuracy of the model on the validation data set using the 'evaluate()' method\n",
    "performance_test = nn1.evaluate(X_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the validation data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the validation data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByqB0-SJ2zpn"
   },
   "source": [
    "Find the optimal parameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "4SMFaeIuBhDe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 1/2] END model__activation_function=relu, model__hidden1_neurons=256;, score=0.933 total time=   5.5s\n",
      "[CV 2/2] END model__activation_function=relu, model__hidden1_neurons=256;, score=0.937 total time=   5.9s\n",
      "[CV 1/2] END model__activation_function=relu, model__hidden1_neurons=512;, score=0.923 total time=   6.5s\n",
      "[CV 2/2] END model__activation_function=relu, model__hidden1_neurons=512;, score=0.939 total time=   6.9s\n",
      "[CV 1/2] END model__activation_function=sigmoid, model__hidden1_neurons=256;, score=0.940 total time=   6.3s\n",
      "[CV 2/2] END model__activation_function=sigmoid, model__hidden1_neurons=256;, score=0.935 total time=   5.8s\n",
      "[CV 1/2] END model__activation_function=sigmoid, model__hidden1_neurons=512;, score=0.939 total time=   6.4s\n",
      "[CV 2/2] END model__activation_function=sigmoid, model__hidden1_neurons=512;, score=0.940 total time=   6.6s\n",
      "\n",
      " The optimal value of convolution filter size is sigmoid\n",
      "\n",
      " The optimal value of maxpooling filter size is 512\n",
      "\n",
      " The accuracy of the model with these optimal parameters is  0.9396707194596277\n"
     ]
    }
   ],
   "source": [
    "# Initialize a basic NN object using the 'KerasClassifier()' method\n",
    "# Note: Set the 'build_fn' parameter to 'create_nn' - This converts the 'create_nn' function into a 'KerasClassifier' object\n",
    "base_grid_model = KerasClassifier(build_fn=create_nn,  verbose=0)\n",
    "\n",
    "# Define a list of 'activation_function' and 'hidden1_neurons' parameters and store it in a parameter grid dictionary\n",
    "parameters_grid = {'model__activation_function':['relu', 'sigmoid'],\n",
    "                   'model__hidden1_neurons' : [256 , 512]}\n",
    "# Perform a grid search using the 'GridSearchCV()' method to obtain a grid on which to fit the training data\n",
    "# Note: Set the 'estimator' parameter to 'base_grid_model' - This specifies the estimator to be used by 'GridSearchCV()'\n",
    "# Note: Set the 'param_grid' parameter to 'parameters_grid' - This specifies the grid of parameters to search over\n",
    "# Note: Set the 'cv' parameter to 2 - This specifies the number of folds in the cross-validation process\n",
    "# Note: Set the 'verbose' parameter to 4 - This helps show more relevant information during training\n",
    "grid = GridSearchCV(estimator=base_grid_model, param_grid=parameters_grid, cv=2, verbose=4)\n",
    "\n",
    "# Train the model on the training data using the 'fit()' method\n",
    "# Note: Use the default batch size or set it to 32\n",
    "# Note: Set the 'epochs' parameter to 10\n",
    "# Note: The 'validation_split' parameter isn't particularly required since cross-validation is already in place\n",
    "grid_model = grid.fit(X_train, y_train , epochs = 10,batch_size = 32)\n",
    "\n",
    "# Print the optimal values of 'activation_function' and 'hidden1_neurons'\n",
    "best_activation_function = grid_model.best_params_['model__activation_function']\n",
    "best_hidden1_neurons = grid_model.best_params_['model__hidden1_neurons']\n",
    "best_accuracy = grid_model.best_score_\n",
    "\n",
    "\n",
    "\n",
    "print('\\n The optimal value of convolution filter size is', best_activation_function)\n",
    "print('\\n The optimal value of maxpooling filter size is', best_hidden1_neurons)\n",
    "print('\\n The accuracy of the model with these optimal parameters is ', best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Qwj0ZkwLePj"
   },
   "source": [
    "Retrain the model with the optimal combination of hyperparameters and save its training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "838332c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m91,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m32,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,545</span> (486.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,545\u001b[0m (486.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,545</span> (486.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,545\u001b[0m (486.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9125 - loss: 0.2239 - val_accuracy: 0.9351 - val_loss: 0.1877\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.1912 - val_accuracy: 0.9365 - val_loss: 0.1904\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.1884 - val_accuracy: 0.9370 - val_loss: 0.1843\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.1721 - val_accuracy: 0.9388 - val_loss: 0.1887\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1825 - val_accuracy: 0.9385 - val_loss: 0.1922\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.1842 - val_accuracy: 0.9393 - val_loss: 0.1864\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.1816 - val_accuracy: 0.9375 - val_loss: 0.1876\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1841 - val_accuracy: 0.9381 - val_loss: 0.1869\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.1807 - val_accuracy: 0.9355 - val_loss: 0.1869\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1826 - val_accuracy: 0.9365 - val_loss: 0.1874\n"
     ]
    }
   ],
   "source": [
    "# Use the 'create_nn' function to create a NN with the optimal values of 'filter_size' and 'pool_filter_size'\n",
    "# Note: Set the 'activation_function' parameter to 'best_activation_function' - This specifies the optimal value for the 'activation_function' parameter\n",
    "# Note: Set the 'hidden1_neurons' parameter to 'best_hidden1_neurons' - This specifies the optimal value for the 'hidden1_neurons' parameter\n",
    "nn1 = create_nn(activation_function=best_activation_function, hidden1_neurons=best_hidden1_neurons)\n",
    "# Capture the training history of the model using the 'fit()' method\n",
    "# Note: Set the 'validation_data' parameter to (X_val, y_val)\n",
    "# Note: Use the default batch size or set it to 32\n",
    "# Note: Set the 'epochs' parameter to 10\n",
    "nn1.summary()\n",
    "print('\\n')\n",
    "nn1_history = nn1.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=10, batch_size=32,)\n",
    "\n",
    "hist = pd.DataFrame(nn1_history.history)\n",
    "hist['epoch'] = nn1_history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.929071</td>\n",
       "      <td>0.198002</td>\n",
       "      <td>0.935067</td>\n",
       "      <td>0.187670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938471</td>\n",
       "      <td>0.184885</td>\n",
       "      <td>0.936533</td>\n",
       "      <td>0.190433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.939471</td>\n",
       "      <td>0.186519</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.184288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.939537</td>\n",
       "      <td>0.184602</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>0.188670</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.940604</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.938467</td>\n",
       "      <td>0.192234</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.940337</td>\n",
       "      <td>0.184882</td>\n",
       "      <td>0.939267</td>\n",
       "      <td>0.186407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.940337</td>\n",
       "      <td>0.183386</td>\n",
       "      <td>0.937533</td>\n",
       "      <td>0.187564</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.941271</td>\n",
       "      <td>0.183683</td>\n",
       "      <td>0.938133</td>\n",
       "      <td>0.186859</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.182750</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.940737</td>\n",
       "      <td>0.185024</td>\n",
       "      <td>0.936533</td>\n",
       "      <td>0.187380</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss  epoch\n",
       "0  0.929071  0.198002      0.935067  0.187670      0\n",
       "1  0.938471  0.184885      0.936533  0.190433      1\n",
       "2  0.939471  0.186519      0.937000  0.184288      2\n",
       "3  0.939537  0.184602      0.938800  0.188670      3\n",
       "4  0.940604  0.184745      0.938467  0.192234      4\n",
       "5  0.940337  0.184882      0.939267  0.186407      5\n",
       "6  0.940337  0.183386      0.937533  0.187564      6\n",
       "7  0.941271  0.183683      0.938133  0.186859      7\n",
       "8  0.941071  0.182750      0.935533  0.186916      8\n",
       "9  0.940737  0.185024      0.936533  0.187380      9"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display print the training history\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZJg361XLpe7"
   },
   "source": [
    "Plot the training and validation accuracies for different values of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "776c3172"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJYAAAGHCAYAAADiJdjqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACCcUlEQVR4nO3deZyN5f/H8ffsmzG2jH3GknXSYGQrkZAQlUJRUvq286WyFNlqii9pM4XsWVJE0SJalGqQNRotGMvYmcEw6/374/rNcswMM2Nm7llez8fjPJy5z3Xu8zmzmfM+1/W5nCzLsgQAAAAAAADkkLPdBQAAAAAAAKBoIlgCAAAAAABArhAsAQAAAAAAIFcIlgAAAAAAAJArBEsAAAAAAADIFYIlAAAAAAAA5ArBEgAAAAAAAHKFYAkAAAAAAAC5QrAEAAAAAACAXCFYAgCgkHv77bfl5OSkoKAgu0tBHpo7d66cnJwyvTz//PO21rZo0SJNmzYt09ucnJw0duzYAq0np9atW6eQkBD5+PjIyclJn332Wabj9u/fn+XXoLA8z8DAQHXr1s3uMgAAyJKr3QUAAIArmz17tiTpjz/+0G+//aYWLVrYXBHy0pw5c1S/fn2HY1WqVLGpGmPRokXatWuXhgwZkuG2X375RdWqVSv4orLJsizdf//9qlu3rlatWiUfHx/Vq1fvivd59tln9cADD2Q4XpifJwAAhQXBEgAAhdjmzZu1fft2de3aVatXr9aHH35YaIOl2NhYeXt7211GkRMUFKSQkBC7y8i2li1b2l3CFR05ckSnT5/W3XffrQ4dOmTrPjVq1Cj0zwsAgMKKpXAAABRiH374oSTp9ddfV+vWrbVkyRLFxsZmGHf48GE9/vjjql69utzd3VWlShX16tVLx44dSx1z9uxZDRs2TLVq1ZKHh4cqVqyoO++8U3/++ack6fvvv5eTk5O+//57h3OnLBeaO3du6rEBAwaoVKlS2rlzpzp16iRfX9/UF/Fr165Vjx49VK1aNXl6eqpOnTr6z3/+o5MnT2ao+88//1Tfvn3l7+8vDw8P1ahRQw899JDi4uK0f/9+ubq6KjQ0NMP9fvzxRzk5OWnZsmVZfu4uXbqkYcOGKTg4WH5+fipXrpxatWqllStXZhi7bNkytWjRQn5+fvL29latWrU0cODALM+d4r333lPbtm1VsWJF+fj46IYbbtCkSZOUkJBw1ftmR1bLsQIDAzVgwIDUj1OW1X333Xd68sknVaFCBZUvX1733HOPjhw5kuH+ixYtUqtWrVSqVCmVKlVKwcHBqd9r7dq10+rVq3XgwAGHZWFXqmnXrl3q0aOHypYtK09PTwUHB2vevHkOY1K+vxYvXqyXXnpJVapUUenSpXX77bcrIiIiW5+Pn376SR06dJCvr6+8vb3VunVrrV69OvX2sWPHps4yGj58uJycnBQYGJitc19Nu3btFBQUpA0bNqhly5by8vJS1apVNXr0aCUlJTmMPX36tJ566ilVrVpV7u7uqlWrll566SXFxcU5jEtOTtY777yj4OBgeXl5qUyZMmrZsqVWrVqV4fG/+uorNW3aVF5eXqpfv37qTEYAAOzGjCUAAAqpixcvavHixWrevLmCgoI0cOBAPfbYY1q2bJkefvjh1HGHDx9W8+bNlZCQoFGjRqlx48Y6deqUvv76a505c0b+/v46d+6cbr75Zu3fv1/Dhw9XixYtdP78ef3444+KiorKsBQrO+Lj43XXXXfpP//5j0aMGKHExERJ0j///KNWrVrpsccek5+fn/bv36+pU6fq5ptv1s6dO+Xm5iZJ2r59u26++WZVqFBB48eP1/XXX6+oqCitWrVK8fHxCgwM1F133aX3339fL774olxcXFIf+91331WVKlV09913Z1lfXFycTp8+reeff15Vq1ZVfHy8vv32W91zzz2aM2eOHnroIUlmaVfv3r3Vu3dvjR07Vp6enjpw4IDWr19/1c/BP//8owceeEA1a9aUu7u7tm/frldffVV//vlntl/4JyUlpX7uUri65u5PtMcee0xdu3bVokWLdPDgQb3wwgvq16+fw3MZM2aMJkyYoHvuuUfDhg2Tn5+fdu3apQMHDkiSpk+frscff1z//POPVqxYcdXHjIiIUOvWrVWxYkW9/fbbKl++vBYuXKgBAwbo2LFjevHFFx3Gjxo1Sm3atNGsWbMUExOj4cOHq3v37tqzZ4/D1/hyP/zwgzp27KjGjRvrww8/lIeHh6ZPn67u3btr8eLF6t27tx577DHdeOONuueee1KXt3l4eFz1OSQnJ2f4GkgZvw5Hjx5Vnz59NGLECI0fP16rV6/WxIkTdebMGb377ruSTKDZvn17/fPPPxo3bpwaN26sDRs2KDQ0VNu2bXMIwgYMGKCFCxfq0Ucf1fjx4+Xu7q7ff/9d+/fvd3jc7du3a9iwYRoxYoT8/f01a9YsPfroo6pTp47atm171ecHAEC+sgAAQKE0f/58S5L1/vvvW5ZlWefOnbNKlSpl3XLLLQ7jBg4caLm5uVm7d+/O8lzjx4+3JFlr167Ncsx3331nSbK+++47h+P79u2zJFlz5sxJPfbwww9bkqzZs2df8TkkJydbCQkJ1oEDByxJ1sqVK1Nvu+2226wyZcpYx48fv2pNK1asSD12+PBhy9XV1Ro3btwVH/tyiYmJVkJCgvXoo49aTZo0ST3+v//9z5JknT17Nkfnu1xSUpKVkJBgzZ8/33JxcbFOnz59xfFz5syxJGV6SUhIsCzLsiRZr7zySob7BgQEWA8//HCGcz311FMO4yZNmmRJsqKioizLsqx///3XcnFxsR588MEr1ta1a1crICAg09sur6lPnz6Wh4eHFRkZ6TCuS5culre3d+rnNeVreeeddzqM+/jjjy1J1i+//HLFmlq2bGlVrFjROnfuXOqxxMREKygoyKpWrZqVnJxsWVba9+vkyZOveL70Y7O6bNiwIXXsrbfemuF72LIsa9CgQZazs7N14MABy7Is6/3337ckWR9//LHDuDfeeMOSZH3zzTeWZVnWjz/+aEmyXnrppSvWGBAQYHl6eqae37Is6+LFi1a5cuWs//znP1d9jgAA5DeWwgEAUEh9+OGH8vLyUp8+fSRJpUqV0n333acNGzbor7/+Sh335Zdfqn379mrQoEGW5/ryyy9Vt25d3X777Xla47333pvh2PHjx/XEE0+oevXqcnV1lZubmwICAiRJe/bskWT6Mf3www+6//77dd1112V5/nbt2unGG2/Ue++9l3rs/fffl5OTkx5//PGr1rds2TK1adNGpUqVSq3lww8/TK1Dkpo3by5Juv/++/Xxxx/r8OHD2XvykrZu3aq77rpL5cuXl4uLi9zc3PTQQw8pKSlJe/fuzdY55s+fr02bNjlccjtj6a677nL4uHHjxpKUOhtp7dq1SkpK0tNPP52r82dm/fr16tChg6pXr+5wfMCAAYqNjdUvv/ySoxozc+HCBf3222/q1auXSpUqlXrcxcVF/fv316FDh7K9nC4zgwcPzvA12LRpk4KDgx3G+fr6Zqj/gQceUHJysn788UdJ5vPh4+OjXr16OYxLWbq4bt06SeZnUlK2vhbBwcGqUaNG6seenp6qW7fuFT9nAAAUFIIlAAAKob///ls//vijunbtKsuydPbsWZ09ezb1xWr6ZVYnTpy46u5V2RmTU97e3ipdurTDseTkZHXq1EnLly/Xiy++qHXr1ik8PFy//vqrJLO8T5LOnDmjpKSkbNX03HPPad26dYqIiFBCQoJmzpypXr16qVKlSle83/Lly3X//feratWqWrhwoX755Rdt2rRJAwcO1KVLl1LHtW3bVp999pkSExP10EMPqVq1agoKCtLixYuveP7IyEjdcsstOnz4sN566y1t2LBBmzZtSg3BUp7r1TRo0EAhISEOl9wqX768w8cpy8BSajlx4oSkvN3t7NSpU6pcuXKG4yk72506dSpHNWbmzJkzsiwrR4+TE9WqVcvwNQgJCXEIsSTJ398/w31Tvg9THv/UqVOqVKmSQ18qSapYsaJcXV1Tx504cUIuLi5X/T6WMn7OJPN5y+73GAAA+YkeSwAAFEKzZ8+WZVn65JNP9Mknn2S4fd68eZo4caJcXFx03XXX6dChQ1c8X3bGeHp6SlKGBsOZNd2WlOGFs2SaOG/fvl1z58516AP1999/O4wrV66cXFxcrlqTZGaEDB8+XO+9955atmypo0ePZmuWx8KFC1WzZk0tXbrUodbLn58k9ejRQz169FBcXJx+/fVXhYaG6oEHHlBgYKBatWqV6fk/++wzXbhwQcuXL0+dkSVJ27Ztu2pt2eXh4ZFpvbkNUVJmhx06dCjDDKPcKl++vKKiojIcT2kaXqFChWt+jLJly8rZ2TnfH+dq0jfDT3H06FFJaeFP+fLl9dtvv8myLIfvu+PHjysxMTG1zuuuu05JSUk6evRopoEZAABFBTOWAAAoZJKSkjRv3jzVrl1b3333XYbLsGHDFBUVlbqUpkuXLvruu++uuBSoS5cu2rt37xUbUqfsnrVjxw6H45ntUJWVlBfSlzdM/uCDDxw+9vLy0q233qply5ZlGVyl8PT01OOPP6558+Zp6tSpCg4OVps2bbJVi7u7u8OL+6NHj2a6K1wKDw8P3XrrrXrjjTckmaVuVzp/yn1SWJalmTNnXrW27AoMDMzw9Vi/fr3Onz+fq/N16tRJLi4uCgsLu+K4nMyG6dChg9avX59h97n58+fL29tbLVu2zFWt6fn4+KhFixZavny5Q13JyclauHChqlWrprp1617z41zNuXPnMvw8LFq0SM7OzqlNtDt06KDz58/rs88+cxg3f/781Nsl8zMp6apfCwAACjtmLAEAUMh8+eWXOnLkiN544w21a9cuw+1BQUF699139eGHH6pbt24aP368vvzyS7Vt21ajRo3SDTfcoLNnz+qrr77S0KFDVb9+fQ0ZMkRLly5Vjx49NGLECN100026ePGifvjhB3Xr1k3t27dXpUqVdPvttys0NFRly5ZVQECA1q1bp+XLl2e79vr166t27doaMWKELMtSuXLl9Pnnn2vt2rUZxqbsFNeiRQuNGDFCderU0bFjx7Rq1Sp98MEH8vX1TR371FNPadKkSdqyZYtmzZqVrVq6deum5cuX66mnnlKvXr108OBBTZgwQZUrV3boUTVmzBgdOnRIHTp0ULVq1XT27Fm99dZbcnNz06233prl+Tt27Ch3d3f17dtXL774oi5duqSwsDCdOXMm25+vq+nfv79Gjx6tMWPG6NZbb9Xu3bv17rvvys/PL1fnCwwM1KhRozRhwgRdvHhRffv2lZ+fn3bv3q2TJ09q3LhxkqQbbrhBy5cvV1hYmJo1ayZnZ+csl+i98sor+uKLL9S+fXuNGTNG5cqV00cffaTVq1dr0qRJua71cqGhoerYsaPat2+v559/Xu7u7po+fbp27dqlxYsXZzqDLrsiIyNTl2umd91116l27dqpH5cvX15PPvmkIiMjVbduXa1Zs0YzZ87Uk08+mdoD6aGHHtJ7772nhx9+WPv379cNN9ygn376Sa+99pruvPPO1D5nt9xyi/r376+JEyfq2LFj6tatmzw8PLR161Z5e3vr2WefzfXzAQCgQNnZORwAAGTUs2dPy93d/Yq7pfXp08dydXW1jh49almWZR08eNAaOHCgValSJcvNzc2qUqWKdf/991vHjh1Lvc+ZM2eswYMHWzVq1LDc3NysihUrWl27drX+/PPP1DFRUVFWr169rHLlyll+fn5Wv379rM2bN2e6K5yPj0+mte3evdvq2LGj5evra5UtW9a67777rMjIyEx3ONu9e7d13333WeXLl7fc3d2tGjVqWAMGDLAuXbqU4bzt2rWzypUrZ8XGxmbn02hZlmW9/vrrVmBgoOXh4WE1aNDAmjlzpvXKK69Y6f8E+uKLL6wuXbpYVatWtdzd3a2KFStad955p8OOYFn5/PPPrRtvvNHy9PS0qlatar3wwgvWl19+menuepdL2clt06ZNWY6Ji4uzXnzxRat69eqWl5eXdeutt1rbtm3Lcle4y8+V1U5/8+fPt5o3b255enpapUqVspo0aeLw9T19+rTVq1cvq0yZMpaTk5PD5yuzr+POnTut7t27W35+fpa7u7t14403OpwvfS3Lli1zOJ7ZroNZ2bBhg3XbbbdZPj4+lpeXl9WyZUvr888/z/R8ebErXPrd82699VarUaNG1vfff2+FhIRYHh4eVuXKla1Ro0al7uKX4tSpU9YTTzxhVa5c2XJ1dbUCAgKskSNHZvi+TkpKst58800rKCjIcnd3t/z8/KxWrVo5PKeAgACra9euGWq/9dZbrVtvvfWqzxEAgPzmZFmWVcBZFgAAQI4cP35cAQEBevbZZzVp0iS7y0EJ1K5dO508eVK7du2yuxQAAAoVlsIBAIBC69ChQ/r33381efJkOTs7a/DgwXaXBAAAgHRo3g0AAAqtWbNmqV27dvrjjz/00UcfqWrVqnaXBAAAgHRYCgcAAAAAAIBcYcYSAAAAAAAAcoVgCQAAAAAAALlCsAQAAAAAAIBcYVe4XEpOTtaRI0fk6+srJycnu8sBAAAAAADIE5Zl6dy5c6pSpYqcna88J4lgKZeOHDmi6tWr210GAAAAAABAvjh48KCqVat2xTEES7nk6+sryXySS5cubXM1AAAAAAAAeSMmJkbVq1dPzT6uhGApl1KWv5UuXZpgCQAAAAAAFDvZaf1D824AAAAAAADkCsESAAAAAAAAcoVgCQAAAAAAALlCj6V8ZFmWEhMTlZSUZHcpyAMuLi5ydXXN1hpTAAAAAABKAoKlfBIfH6+oqCjFxsbaXQrykLe3typXrix3d3e7SwEAAAAAwHYES/kgOTlZ+/btk4uLi6pUqSJ3d3dmuRRxlmUpPj5eJ06c0L59+3T99dfL2ZmVpAAAAACAko1gKR/Ex8crOTlZ1atXl7e3t93lII94eXnJzc1NBw4cUHx8vDw9Pe0uCQAAAAAAWzHlIh8xo6X44WsKAAAAAEAaXiUDAAAAAAAgV1gKBwAAAADFmWVJBw9Ku3aZj318JG9v82/Kxdtb8vKS6A0LIIcIlpDv2rVrp+DgYE2bNi1b4/fv36+aNWtq69atCg4OztfaAAAAgGIlOVn691/p998dL6dOXf2+Tk4mYMosdMrq45yM9fAguAKKIYIlpLraznUPP/yw5s6dm+PzLl++XG5ubtkeX716dUVFRalChQo5fiwAAACgxEhKkiIiHAOkrVulmJiMY11dpfr1JXd36cIFc4mNNf/GxZkxlpV224kTeV+vs3P2Q6nchFvu7gRXgA0IlpAqKioq9frSpUs1ZswYRUREpB7z8vJyGJ+QkJCtwKhcuXI5qsPFxUWVKlXK0X0AAACAYi0+Xtq92zFE2r7dhEOX8/CQGjeWmjZNuwQFSVntapyYaM6TEjSlD50y+zint8XHm8dJTpbOnzeX/ODikvtQKjsf5+DNcqAkIVgqKJaV+S/9/Obtne3UPn2Y4+fnJycnp9Rj+/fvV+XKlbV06VJNnz5dv/76q8LCwnTXXXfpmWee0YYNG3T69GnVrl1bo0aNUt++fVPPdflSuMDAQD3++OP6+++/tWzZMpUtW1Yvv/yyHn/88dTHSr8U7vvvv1f79u317bffavjw4dq9e7eCg4M1Z84c1atXL/VxJk6cqLffflsXL15U7969VaFCBX311Vfatm3bNX4SAQAAgAJ08aK0c6djiLRzZ1pAk56PjxQc7BgiNWiQsxDE1VUqXdpc8kNiYt6HVemvJySYx0lKMrO1MpuxlRdcXfMnsEr52JWX5yia+M4tKLGxUqlSBf+458+bX1R5ZPjw4ZoyZYrmzJkjDw8PXbp0Sc2aNdPw4cNVunRprV69Wv3791etWrXUokWLLM8zZcoUTZgwQaNGjdInn3yiJ598Um3btlX9+vWzvM9LL72kKVOm6LrrrtMTTzyhgQMH6ueff5YkffTRR3r11Vc1ffp0tWnTRkuWLNGUKVNUs2bNPHvuAAAAQJ47f17ats0xRNq924Qkl/PzcwyQmjaVrr/ezNQpzFxdTe1+fvlz/oSEvA2rLv845WuRmChFR5tLfnB3zzx0KlVKKlfO8VK2bObHmFUFGxAsIUeGDBmie+65x+HY888/n3r92Wef1VdffaVly5ZdMVi688479dRTT0kyYdWbb76p77///orB0quvvqpbb71VkjRixAh17dpVly5dkqenp9555x09+uijeuSRRyRJY8aM0TfffKPz+TXNFgAAAMips2dND6T0IVJEhFndcLkKFaRmzRxDpJo16SGUGTc3qUwZc8lrluUYXOXlTKuU68nJ5rHi483lzJnc1+vrm3XwdKVQih0BcQ0IlgqKt3f+rSW+2uPmoZCQEIePk5KS9Prrr2vp0qU6fPiw4uLiFBcXJ5+rzJJq3Lhx6vWUJXfHjx/P9n0qV64sSTp+/Lhq1KihiIiI1KAqxU033aT169dn63kBAAAAeerEiYw7s/37b+Zjq1bNOBOpalVe6BcGTk5mJpG7uwlk8pplmebpVwqkzp0zYdPp0xkvKcfPnjXnOnfOXA4cyFkdHh5XDp6yuq10adOUHSUawVJBcXLK0yVpdrk8MJoyZYrefPNNTZs2TTfccIN8fHw0ZMgQxWe2/judy5t+Ozk5KTklqc/GfVJ2sEt/n8t3tbMye+cHAAAAyEuWJR05kjFEOnQo8/E1azoGSE2aSP7+BVszCg8nJ9NU3dPTBDW5lZRkluhlFTxd6ZKYaMKtqChzyQlnZ8ewKbuhFMv2ihWCJVyTDRs2qEePHurXr58kE/T89ddfatCgQYHWUa9ePYWHh6t///6pxzZv3lygNQAAAKCYsyxp//6MIVJWM+/r1s0YIl1LeABkxcUlLbTJCcsys6KyCp2uFEzFxpplfKdOmUtOpSzby2koxbK9QodgCdekTp06+vTTT7Vx40aVLVtWU6dO1dGjRws8WHr22Wc1aNAghYSEqHXr1lq6dKl27NihWrVqFWgdAAAAKCaSk6W//soYIp09m3Gss7PUsKFjiHTjjfm3yxqQV5ycTHPwUqWkGjVydt+4uCsHT1ndlvIzlBfL9nISSrFsL98QLOGajB49Wvv27VPnzp3l7e2txx9/XD179lR0fu2UkIUHH3xQ//77r55//nldunRJ999/vwYMGKDw8PACrQMAAABFUGKi9OefaeHRli1mp7bMeqS6uUk33OAYIt1wQ573NgUKPQ8PqVIlc8mJpCQTLl1tmV5mt+flsr3shlIs27sqJ4tGNLkSExMjPz8/RUdHq/Rl70RcunRJ+/btU82aNeXp6WlThejYsaMqVaqkBQsW5Nk5+doCAAAUcXFx0h9/OM5C2r5dunQp41gvLzPzKH2I1KiRaeQMoGBZlgl7s7NM7/LbYmOv7bEvX7aXnVAqZdleEXWlzONyzFhCsRAbG6v3339fnTt3louLixYvXqxvv/1Wa9eutbs0AAAA2CU2VtqxwzFE2rXLbB9/OV9f0wMpfYhUr57kyksmoFBwcjI/p76+UkBAzu576ZJj2JTd2VLXsmyvYkXp2LGc1VlE8VsSxYKTk5PWrFmjiRMnKi4uTvXq1dOnn36q22+/3e7SAAAAUBBiYszytfQh0p49plfS5cqWlZo1cwyRatem/wpQXHl6SpUrm0tOpCzby+lue2fOlKhG/QRLKBa8vLz07bff2l0GAMBuKSv82S0GKN5OnZK2bnUMkf76K/Ox/v4ZQ6QaNfg9AeDqXFyk8uXNJScsS7p4MX9qKoQIlgAAQNF18qT066/SL7+YS3i4me5eurS5+Pllfj07t3l68sITKAyOHcu4M9v+/ZmPrV7dMUBq2lSqUqVAywUAOTmVqIb+BEsAAKBoSEoyDXd/+UXauNH8m9UMhTNnzOVauLpeezhVurTZNYeACrg6y5IOHcoYIh05kvn42rUdA6QmTaTrrivYmgEABEsAAKCQOn0642ykc+cyjqtfX2rdWmrVylzKljW9VmJipOjotOuXf3yl2yzLbGmc0ivhWri5ZT+QutI4D49rqwMoTCxL+vffjCHSyZMZxzo5mZ/z9CFScLBUpkxBVw0AyATBEgAAsF9ysrR7d1qI9Msv0p9/ZhxXqpTUsmVaiNSiRebNMa9l6UtysnThQs7DqcvHxcSY8yUkmBfLmb1gzgkPj5zPlsrsNrZJR0FLSpL27nUMkLZuNT8zl3N1lRo1cgyRGjc2P/sAgEKJYAkAABS8s2el335LC5F++y3zF5l166aFSK1amRecLi75W5uzc9p2xlWr5v48ycnS+fPXFk5FR5tzSFJcnHTihLlcC0/Paw+nSpc2M7GAyyUkmJA4fYi0bZsUG5txrIeHCY3Sh0hBQeZ7FABQZBAsAQCA/JWcLEVEOM5G2r07bQe3FD4+0k03pYVILVtKFSrYU3NecHZOC2GqVcv9eZKSTLh0LeFUTIyZhSWZ5uaXLknHj1/b8/PyuvYeVL6+ZoYKiqZLl6Rdu9ICpC1bpJ07TQh6OW9v0wMpfYjUoAEBJQAUA/xPjjzVrl07BQcHa9q0aZKkwMBADRkyREOGDMnyPk5OTlqxYoV69ux5TY+dV+cBAFyjmBjTDymlyfZvv2XeSLt27bQQqXVrM1OBkCEjFxcTwvj5Xdt5EhNNj6prCadiYtJmnly8aC7Hjl1bXd7eJmBydr6286BgWZZZ3pmYmPE2P7+MO7Ndf33+zzYEANiCv96Qqnv37rp48aK+/fbbDLf98ssvat26tbZs2aKmTZtm+5ybNm2Sj49PXpapsWPH6rPPPtO2bdscjkdFRals2bJ5+lgAgKuwLLMzW/qd2nbtyjgbyctLat48LURq2VKqWNGemksqV1fT2Pxa/69MSHAMqHITTkVHm9kukgmqMlsmhaKhQgXHAKlZM6lmTXZCBIAShGAJqR599FHdc889OnDggAICAhxumz17toKDg3MUKknSdQW45WulSpUK7LEAoMQ6f17atCktRPr1V+nUqYzjatZ07I3UuDFLXooLNzfTMD2zpuk5ER+fFlCdO5cxjEThV66cWeZJiAQAJRrBUgGxLHvejPP2zv7/9d26dVPFihU1d+5cvfLKK6nHY2NjtXTpUg0bNkx9+/bVhg0bdPr0adWuXVujRo1S3759szzn5Uvh/vrrLz366KMKDw9XrVq19NZbb2W4z/Dhw7VixQodOnRIlSpV0oMPPqgxY8bIzc1Nc+fO1bhx4ySZpW+SNGfOHA0YMCDDUridO3dq8ODB+uWXX+Tt7a17771XU6dOVan/31VkwIABOnv2rG6++WZNmTJF8fHx6tOnj6ZNmyY3XvwAgPnP659/HHsj7dhheial5+kphYQ4BkmE/bgad3epfHlzAQAARRbBUgGJjbVnl9Tz500v1OxwdXXVQw89pLlz52rMmDGpwc2yZcsUHx+vxx57TIsXL9bw4cNVunRprV69Wv3791etWrXUokWLq54/OTlZ99xzjypUqKBff/1VMTExmfZe8vX11dy5c1WlShXt3LlTgwYNkq+vr1588UX17t1bu3bt0ldffZW6ZM8vk54TsbGxuuOOO9SyZUtt2rRJx48f12OPPaZnnnlGc+fOTR333XffqXLlyvruu+/0999/q3fv3goODtagQYOy90kDgOIkNtbMRkofJGW2A1mNGo4hUnAwW9gDAACUULZ3SZw+fbpq1qwpT09PNWvWTBs2bLji+Pfee08NGjSQl5eX6tWrp/nz52c5dsmSJXJycsq0mXNOH7ekGDhwoPbv36/vv/8+9djs2bN1zz33qGrVqnr++ecVHBysWrVq6dlnn1Xnzp21bNmybJ3722+/1Z49e7RgwQIFBwerbdu2eu211zKMe/nll9W6dWsFBgaqe/fuGjZsmD7++GNJkpeXl0qVKiVXV1dVqlRJlSpVkpeXV4ZzfPTRR7p48aLmz5+voKAg3XbbbXr33Xe1YMECHUvXZLRs2bJ69913Vb9+fXXr1k1du3bVunXrcvhZA4AiyLKkffukRYukZ581fVFKl5batZNGjpRWrTKhkru7CY+GDpU++UQ6fFg6cEBaskQaPNjs4kaoBAAAUGLZOmNp6dKlGjJkiKZPn642bdrogw8+UJcuXbR7927VqFEjw/iwsDCNHDlSM2fOVPPmzRUeHq5BgwapbNmy6t69u8PYAwcO6Pnnn9ctt9xyzY+bF7y9zeyhgubtnbPx9evXV+vWrTV79my1b99e//zzjzZs2KBvvvlGSUlJev3117V06VIdPnxYcXFxiouLy3Zz7j179qhGjRqqlm7L5VatWmUY98knn2jatGn6+++/df78eSUmJqp06dI5eh579uzRjTfe6FBbmzZtlJycrIiICPn7+0uSGjVqJJd0O5RUrlxZO3fuzNFjAUCRcPGi2Qo8pTfSL79kvptX1appDbZbtTLbg3t4FHy9AAAAKBJsDZamTp2qRx99VI899pgkadq0afr6668VFham0NDQDOMXLFig//znP+rdu7ckqVatWvr111/1xhtvOARLSUlJevDBBzVu3Dht2LBBZ8+evabHzQtOTtlfkma3Rx99VM8884zee+89zZkzRwEBAerQoYMmT56sN998U9OmTdMNN9wgHx8fDRkyRPHx8dk6r5VJU06nyxpA/frrr+rTp4/GjRunzp07y8/PT0uWLNGUKVNy9Bwsy8pw7swe8/JeSk5OTkq+vHcIABQ1liUdPOgYIm3dmnFbcDc3ExylhEitWknVq9tTMwAAAIok24Kl+Ph4bdmyRSNGjHA43qlTJ23cuDHT+8TFxcnT09PhmJeXl8LDw5WQkJAaEowfP17XXXedHn300QxL3HLzuCmPHRcXl/pxTEzM1Z9kEXX//fdr8ODBWrRokebNm6dBgwbJyclJGzZsUI8ePdSvXz9JpmfSX3/9pQYNGmTrvA0bNlRkZKSOHDmiKlWqSJJ++eUXhzE///yzAgIC9NJLL6UeO3DggMMYd3d3JSUlXfWx5s2bpwsXLqTOWvr555/l7OysunXrZqteACgyLl2Sfv/dsTfSkSMZx1Wq5BgiNWtmGm8DAAAAuWRbsHTy5EklJSWlLklK4e/vr6NHj2Z6n86dO2vWrFnq2bOnmjZtqi1btmj27NlKSEjQyZMnVblyZf3888/68MMPtW3btjx7XEkKDQ1N3Y2suCtVqpR69+6tUaNGKTo6WgMGDJAk1alTR59++qk2btyosmXLaurUqTp69Gi2g6Xbb79d9erV00MPPaQpU6YoJibGIUBKeYzIyEgtWbJEzZs31+rVq7VixQqHMYGBgdq3b5+2bdumatWqydfXVx6XLdN48MEH9corr+jhhx/W2LFjdeLECT377LPq379/hq89ABQ5hw45hki//262bk/P1dU01U7fZDsggG3BAQAAkKdsb959+XKlKy1hGj16tLp06aKWLVvKzc1NPXr0SA09XFxcdO7cOfXr108zZ85UhQoV8uxxJWnkyJGKjo5OvRw8eDAbz67oevTRR3XmzBndfvvtqX2nRo8eraZNm6pz585q166dKlWqlGlj9Kw4OztrxYoViouL00033aTHHntMr776qsOYHj166L///a+eeeYZBQcHa+PGjRo9erTDmHvvvVd33HGH2rdvr+uuu06LFy/O8Fje3t76+uuvdfr0aTVv3ly9evVShw4d9O677+b8kwEAdoqPl377TZo2Terd2yxVq15duv9+6c03pV9/NWMqVpR69JBef1364QcpOtrs8Pb221LfvlJgIKESAAAA8pyTlVnjmwIQHx8vb29vLVu2THfffXfq8cGDB2vbtm364YcfsrxvQkKCjh07psqVK2vGjBkaPny4zp49qx07dqhJkyYOzZhT+uU4OzsrIiJC1atXz/XjphcTEyM/Pz9FR0dnaCx96dIl7du3L3XXORQffG0B5LuoqLSZSBs3mobb6ZZiS5JcXKTGjR2bbNesSXAEAACAPHGlzONyti2Fc3d3V7NmzbR27VqHgGft2rXq0aPHFe/r5uaWurPYkiVL1K1bNzk7O6t+/foZdvR6+eWXde7cOb311luqXr36NT0uAAB5KiFB2r49LUT65Rfpsr5ykqTy5R1DpObNi86OEAAAACjWbN0VbujQoerfv79CQkLUqlUrzZgxQ5GRkXriiSckmeVnhw8f1vz58yVJe/fuVXh4uFq0aKEzZ85o6tSp2rVrl+bNmydJ8vT0VFBQkMNjlClTRpIcjl/tcQEAyBfHjjn2Rtq8Wbp40XGMs7N0ww2OvZHq1GE2EgAAAAolW4Ol3r1769SpUxo/fryioqIUFBSkNWvWKCAgQJIUFRWlyMjI1PFJSUmaMmWKIiIi5Obmpvbt22vjxo0KDAzM08cFAOCaJSZKO3Y4Bkn//ptxXLlyUsuWaSHSTTdJvr4FXy8AAACQC7b1WCrq6LFUMvG1BZClkycdQ6TwcCk21nGMk5PUqFFaiNS6tVS3LrORAAAAUKgUiR5LJQGZXfHD1xSAJCkpSdq1y7E30t9/Zxzn55c2G6l1azMbyc+v4OsFAAAA8gnBUj5wc3OTJMXGxsrLy8vmapCXYv9/9kHK1xhACXH6tPTrr2khUni4dP58xnENGjg22a5f3/RMAgAAAIopgqV84OLiojJlyuj48eOSJG9vbzmxzKFIsyxLsbGxOn78uMqUKSMXFxe7SwKKD8uSkpNNT6KkJPNv+uuX/1uQtx09aoKkiIiMdfv6OvZGatFCKlu24D9/AAAAgI0IlvJJpUqVJCk1XELxUKZMmdSvLZAjlwcnhS1AsfO2pCS7vzrZU6+e405tDRtKhMwAAAAo4QiW8omTk5MqV66sihUrKiEhwe5ykAfc3NyYqYTsSU42M1zCw6VNm8y/27dL8fF2V1b0ODub8MbV1VxSrl/+b37dVrq01Ly5mZlUvrzdnw0AAACg0CFYymcuLi6EEUBxZlnSoUOOIdLmzdK5c9k/x+UBhx0BSmG9jWXEAAAAQKFGsAQAOXH6tAmQUkKk8HDp2LGM47y9pWbNzGyXm26SQkLMjJfLAxQaOwMAAAAowgiWACArsbHS1q1pIdKmTZlvKe/iIjVunBYiNW9u+u+48isWAAAAQPHGqx4AkEwj6T/+cAyRdu7MvLH09dc7hkhNmkheXgVfMwAUcZcuSX/+aSZ+tm5tNlsEAABFC8ESgJLHsqR//3UMkbZskS5ezDi2UiUTIKWESCEhUrlyBV8zABRhcXFmT4M//nC8/POP2e9AMvl8z55S//5Sx45M+gQAoKhwsizLsruIoigmJkZ+fn6Kjo5W6dKl7S4HwJUcO+YYIoWHm15Jlytd2gRHKSHSTTdJVavSQBoAsikuTtq7N2OA9PffaQHS5cqUMb9+IyPTjvn7S337Sv36SU2b8msYAICClpPMg2AplwiWgELq3Dkz+yh9iJT+1UoKd3cpONgxRKpbl2baAJAN8fHSX39lDJD++ivzFcSS5OcnNWqU8VKpkrl982ZpwQJp8WLp5Mm0+zVoYGYxPfigVKNG/j83AABAsFQgCJaAQiA+XtqxwzFE2rPHLHVLz8nJvDJJHyLdcIPk4WFP3QBQRCQkZB0gJSZmfp/SpTOGRw0bSlWqZG/mUUKC9PXXJmRatcr0YZLMfW+91YRMvXqZxwEAAPmDYKkAECwBBSw52ayvSB8ibdtmwqXL1ajhGCI1bcorEAC4goQEs1wtJTjavdv8u3evuS0zvr5poVH6ECkvVxBHR0uffmpCpu+/Tzvu6Sn16GFCpk6dJDe3vHk8AABgECwVAIIlIB9ZlnT4sGOItHmzFBOTcWy5co4hUvPmpjkHACCDxETTMPvyGUgREVkHSKVKZQyPGjWSqlUr2N5HkZHSRx+ZkGnPnrTj111n+jH17y81a0Y/JgAA8gLBUgEgWALy0JkzJkBK32A7KirjOC8vM/so/S5ttWrxKgIALpOUlHWAlNlET0ny8ckYIDVsaCaBFqZfs5Yl/f57Wj+m48fTbqtfP60fU0CAfTUCAFDUESwVAIIlIJcuXpS2bnUMkf76K+M4FxcpKMgxRGrUiP2nASCdpCTp338dl6/98Yf0559mh7bMeHubtnOXz0CqUaPo7V+QkCCtXWtCps8+S+vHJElt25qQ6b77TONwAACQfQRLBYBgCciGxETzSid9iLRzZ+YdX2vXdgyRmjQxr34AAEpOlvbtyzgD6c8/HcOU9Ly8Mg+QAgKKXoCUHTExjv2YUv7C9fCQ7rrLhEx33EE/JgAAsoNgqQAQLAGXsSzzqid9iLRlixQbm3Gsv79jX6SQEKl8+YKvGQAKmeRkaf/+zAOkixczv4+np2OAlLKcLTDQTP4siQ4elBYtMiHTH3+kHa9QQerTx4RMzZsXriV+AAAUJgRLBYBgCSXe8eOOIVJ4uHTqVMZxvr4mOEoJkW66qeA7vgI5dPastHSp2XjQz8/0iM/sUrasmVjHtzNyKjnZNKO+PEDasyfzPF4yM2/q1884A6lmzZIbIF2NZZmf4wULTNB07FjabXXrmoCpXz8TwgEAgDQESwWAYAklyvnzZvZR+hDpwIGM49zcpOBgxxCpXr3iueYCxU5SkrRunTR3rrRiRdbLiy7n7p516JRVIFWunFS6ND8aJYFlZR0gXbiQ+X3c3TMPkGrVIkC6FomJ0rffmpBpxQrHGWA335zWj6lsWftqBACgsCBYKgAESyi24uNNH6T0IdKePebt9fScnMwrn5QQqXlz6cYbzVvqQBHy118mTJo/Xzp0KO14o0ZSt26mAfLp02mXM2fSrme1PXt2ODtLZcrkPJQqW5YeMYWRZZnlVynBUUoj7d27TTafGXd3k71fvoStdm32Kchv585Jy5ebkGn9+rR+TO7uUvfuJmTq0sV8DABASUSwVAAIllAsJCebV9XpQ6Rt2zLfSqh6dceZSM2amSkXQBEUEyMtWybNmSP9/HPa8TJlpAcekB55xHyLX2mJm2WZGSfpQ6fLg6esbstqpkp2lSp15dlQWQVTXl4s27tWliUdPpxxBtLu3SasyIybm1l2dfkMpDp1CJAKg0OH0vox7dqVdrx8eal3bxMytWjBzw4AoGQhWCoABEsokg4fdgyRNm+WoqMzjitb1nEmUvPmUuXKBV8vkIeSk81OUXPnmp2jUvrYODtLnTtLAwaYnaM8PfO/lri4zAOoq4VSZ8+mzazIDQ+Pqy/Ry+z2krhsz7KkI0cyD5BiYjK/j6tr1gESs8wKP8uStm9P68d09Gjabddfb3ox9etnliQCAFDcESwVAIIlFHpnzpjgKH2D7SNHMo7z9JSaNnXcpa12bd6aRbGxb58Jk+bNc2wNVq+emZnUr59Utapt5eVIUpLJgq80GyqrS2Ji7h/X2dkETjkNpYrCsj3LkqKi0paupb9klrtLps9R3bppS9dSLtdfz9Kp4iKl59qCBWbJXPqG6m3amFlM999PPyYAQPFFsFQACJZQqFy8aJawpQ+R9u7NOM7ZWQoKcgyRGjUq/K/8gBy6cEH65BOz1O2HH9KOly5tthp/5JGStbQlq2V72QmlstqhLLt8fbPXzPzy2/N62Z5lmR3BMpuBdOZM5vdxcTGzjS6fgVS3LgFSSXL+vGn2vWCBCZtSWg66u5s+bP36SXfeSYtBAEDxQrBUAAiWYJukJNNMOzw8LUTasSPz6Qi1ajmGSE2aSD4+BV8zUAAsS/rpJxMmLVuW1jDZyUm6/Xaz1O3uu01ggezLatne1UKps2ev7XE9PLK/w17620uXlk6cyBge/fGHqSszzs4ZA6SGDc2sNsICpHfkSFo/ph070o6XK2dmMPXvL7VqVXJCawBA8UWwVAAIlmCLxESpUyfpu+8y3laxomOIFBIiVahQ8DUCBSwy0ixzmzdP+ueftON16pgwqX9/qUYN28orsa60bO9qodS1LNtzcsq6D5Wzs1npe/kStnr1Cqa3FoqXHTvS+jGlX2leu7aZxdS/v7kOAEBRRLBUAAiWYIv586WHHzbz71u1StuhrXlz88qZt0hRQsTGmqUpc+Y4bhVeqpSZNfDII6YPCj8SRY9lmdlmuZkllbJsz8nJTNi8fAlbvXrMWEPeS0oyv4dS+jGl3/WxVau0fkzly9tXIwAAOUWwVAAIllDgEhKkBg3MlIzXX5eGD7e7IqBAWZb0yy+mEffSpY47c7VrZ8Kke+9ltWdJdumSCZ38/CRvb7urQUl04YL02WcmZFq7Nq0fk5ub1LWrCZm6dmWJJQCg8CNYKgAESyhws2dLjz4qXXed9O+/ZmoGUAIcPmwm682d69iTPjDQTOB7+GGpZk27qgOAzEVFSYsXm5Bp27a042XLpvVjat2amZUAgMKJYKkAECyhQMXHmzUc+/dL//ufNGyY3RUB+erSJWnlSrPULf27/t7eUq9eZnZS27amZw4AFHa7dpmA6aOPTFieombNtH5M119vX30AAFyOYKkAECyhQM2YIf3nP5K/v5mtxBoPFEOWZTY5nDvXvMufflexW24xjbjvu89sXw8ARVFSkvT99yZk+vTTtN0rJalFCxMw9e7N3hsAAPsRLBUAgiUUmLg48zbmwYPStGnS4MF2VwTkqaNHzYusuXPNtvApqldPW+pWp45t5QFAvoiNTevH9M03aTMzXV2lO+80IVO3buxYCACwB8FSASBYQoGZPl16+mmpShXp77/Z0gjFQny89PnnJkz68kvzLr5kXkDdc49Z6ta+veTiYmuZAFAgjh5N68e0dWvacT+/tH5Mbdqw/Be5FxNjOiocO2Y2Ey5Txu6KABR2Ock8bP/vafr06apZs6Y8PT3VrFkzbdiw4Yrj33vvPTVo0EBeXl6qV6+e5s+f73D78uXLFRISojJlysjHx0fBwcFasGCBw5jExES9/PLLqlmzpry8vFSrVi2NHz9eySlvFQGFxaVL0quvmuujRhEqoUizLPOC6bnnTE7aq5f0xRcmVGrVSvrgA/Pi6qOPpNtvJ1QCUHJUqiT997/S77+bfkwjRphZm9HR0syZpqdc7drS6NGOmxgAKc6dk3buNG/avPOOacd5771S06ZSuXImpLzxRqlTJ6lWLWnKFPNnJgDkBVtnLC1dulT9+/fX9OnT1aZNG33wwQeaNWuWdu/erRo1amQYHxYWpuHDh2vmzJlq3ry5wsPDNWjQIC1atEjdu3eXJH3//fc6c+aM6tevL3d3d33xxRcaNmyYVq9erc6dO0uSXn31Vb355puaN2+eGjVqpM2bN+uRRx7RxIkTNTiby4yYsYQC8fbbZulb9erSX3+xPzGKpBMnTFg0Z460Y0fa8SpVpIceMkvd6te3rz4AKIySk6UffjCzmD75xAQHKW66Ka0f03XX2VcjCs7589KBA2bW0b595t/0l1Onrn6O8uXNn5JHjpiPa9Qw718+8ACz4QBkVGSWwrVo0UJNmzZVWFhY6rEGDRqoZ8+eCg0NzTC+devWatOmjSZPnpx6bMiQIdq8ebN++umnLB+nadOm6tq1qyZMmCBJ6tatm/z9/fXhhx+mjrn33nvl7e2dYXZTVgiWkO9iY83bk0ePmqkcjz9ud0VAtiUkSGvWmKVuX3whJSaa4+7uUs+ephF3x46mlwgA4MpiY6VVq0zI9PXXacuHXV2lO+4wIVP37kxsLsouXEgLjlIu6QOkkyevfo5y5aTAwLRLzZpp1wMCzOYXSUnSvHlm9ltKwBQcLE2aZP5fBoAUOck8bPuTPj4+Xlu2bNGIESMcjnfq1EkbN27M9D5xcXHyvKyDoZeXl8LDw5WQkCA3NzeH2yzL0vr16xUREaE33ngj9fjNN9+s999/X3v37lXdunW1fft2/fTTT5o2bVqW9cbFxSkuLi7145iYmOw+VSB3wsJMqBQYaF6FA0XAzp1mZtLChWamUoqQENM3qU8f84cvACD7vL3N788+fUyPnCVLTMi0ZYsJ77/4Qipd2uyc2b+/2UmTGSiFy8WLGWcZpQ+Q0v+fmZWyZR2Do/QBUkCA+R64GhcXaeBA87301lvS669L27aZJXIdO0pvvCE1aZK75wig5LItWDp58qSSkpLk7+/vcNzf319Hjx7N9D6dO3fWrFmz1LNnTzVt2lRbtmzR7NmzlZCQoJMnT6py5cqSpOjoaFWtWlVxcXFycXHR9OnT1TFdBD98+HBFR0erfv36cnFxUVJSkl599VX17ds3y3pDQ0M1bty4PHjmQDacP2/+Z5fMW0ru7vbWA1zBqVPSokVmdtLvv6cdr1jRvMAZMEAKCrKrOgAoXvz9zSr5wYOlPXtMkL9woRQZKX34obkEBEgPPmh+B7PUuGBcvGi+BlktVTt27OrnKF3ahETpZxqlv/j55V293t7SyJHSoEHSxIlmr5i1a82lXz9zLCAg7x4PQPFm21K4I0eOqGrVqtq4caNatWqVevzVV1/VggUL9Oeff2a4z8WLF/X0009rwYIFsixL/v7+6tevnyZNmqRjx46pYsWKkqTk5GT9+++/On/+vNatW6cJEybos88+U7t27SRJS5Ys0QsvvKDJkyerUaNG2rZtm4YMGaKpU6fq4YcfzrTezGYsVa9enaVwyB9vvGE6d9aubf5qvGw2HmC3xESzHGPOHLM8IyHBHHdzM8sxBgwwyzP41gWA/JecLG3YYGYxLVtmdgBLERJiAqY+fUzgj9y5dCktOMpsuVoW74s78PV1DI0uD5Ds3Knt33+ll182uxNK5j3NZ581e8cw0xgomYpEj6X4+Hh5e3tr2bJluvvuu1OPDx48WNu2bdMPP/yQ5X0TEhJ07NgxVa5cWTNmzNDw4cN19uxZOWcx5/exxx7TwYMH9fXXX0uSqlevrhEjRujpp59OHTNx4kQtXLgw00ArM/RYQr6JiTF/aZw+bRbBP/SQ3RUBqXbvNjOTFixw/CO6SRMTJj3wgFShgl3VAQAuXjQ7gy1YIH31VVqPOxcXE/j36yf16EE/psvFxUkHD2Y+22j//rR+RFdSqlTms41SjpUpIzk55dMTyCObN0svvih99535uEwZEy49+6x0WUcSAMVckeix5O7urmbNmmnt2rUOwdLatWvVo0ePK97Xzc1N1apVk2RmH3Xr1i3LUEkyvZbSzzaKjY3NMN7FxUXJycm5eSpA3nrnHRMq1a1rXqUDNjtzRlq61MxOCg9PO16hgnmBMmCA2cIYAGA/Ly/p/vvN5cSJtH5MmzZJq1ebi6+v1KuXmcl0660lox9TfLwJjjJrjJ0SHF3t7XYfn6xnGwUGmpk9hT04upqQEGndOhNKDh9ueie++KL583TCBPP/vouL3VUCKGxs3RVu6dKl6t+/v95//321atVKM2bM0MyZM/XHH38oICBAI0eO1OHDhzV//nxJ0t69exUeHq4WLVrozJkzmjp1qtauXastW7YoMDBQkumFFBISotq1ays+Pl5r1qzR8OHDFRYWpscee0ySNGDAAH377bf64IMP1KhRI23dulWPP/64Bg4c6NDk+0qYsYR8ER1t/jI5e9bsz06wBJskJUnffmtmJ61YYd7Jlcwfk127mkbcd95J+y8AKCr+/DOtH9OBA2nHq1dP68fUsKF99V2rhATH4OjyAOnw4asHR97eWc82CgyUypcv+sFRTiQlmVBy9Gjp0CFz7IYbzA5ynTuXrM8FUBIViaVwKaZPn65JkyYpKipKQUFBevPNN9W2bVtJJgDav3+/vv/+e0nSnj179MADDygiIkJubm5q37693njjDdWrVy/1fC+//LKWLl2qQ4cOycvLS/Xr19fgwYPVu3fv1DHnzp3T6NGjtWLFCh0/flxVqlRR3759NWbMGLln81USwRLyxbhx0tixUoMG5i0i3hJCAdu714RJ8+ebP8JTBAWZMOnBB03jWABA0ZScLP30kwmYPv7YvKeVomlTEzD17Vv4ftcnJppwI6vm2IcOmed2JV5emTfFTgmQKlQgLMnMxYtmxtJrr6V9v9x2mwmYmjWztzYA+adIBUtFFcES8tyZM+Yvm5gYs+7o/vvtrgglREyMeXExZ460cWPa8bJlzaS5Rx4xLzb4YxsAipdLl6QvvjCzUtascezH1KmTCZl69DAzefJbYqJ5QyOz2UYpwVFS0pXP4eFx5aVqFSvyf9m1OHXKhEvvvmuWFkomhHz1VfP5BlC8ECwVAIIl5LnRo83erkFB0vbtJaPhAWyTnGwac86dK336qXk3UjLfdnfcYfom3XWX+SMdAFD8nTxp3tdasED67be046VKSffea0Kmdu1yP5k6Kcn0McqqOfbBg2nBVlbc3a+8VK1iRf58Kgj795sd5D76yHzs5iY9/bQ5Vr68raUByEMESwWAYAl56tQp8xfR+fPmVf4999hdEYqpf/81YdK8eWbb5BT165uZSf36SVWq2FYeAKAQ2Ls3rR/Tvn1px6tWTevHFBTkeJ+kJCkqKuvm2JGRVw+O3NykgICsd1bz9yc4Kkx+/900+P72W/Nx6dLSyJHS4MHsOggUBwRLBYBgCXlq5Ejp9del4GBpyxb+akKeOn9e+uQTs9Ttxx/Tjvv5SX36mEDppptYHgAAcGRZ0s8/m1lMH39s9hZJERxslklHRpoQKTLSNNC+Ejc3qUaNrJerVa7Mn0BF0TffmJ3jtm83H1etanaQe+gh2oUCRRnBUgEgWEKeOX5cqlVLunBBWrnSrD8CrlFysrRhg5mdtGyZ+faSTHjUsaNZ6tazJ+8oAgCy59IlafVqM4tp9erMQyRXV8fg6PIAqXJlgobiKjnZLI17+eW0GdFBQdIbb0hduvDmFVAUESwVAIIl5JkXXpD+9z+zrcamTfzPi2ty4IBZ5jZvnln2lqJOHTMzqX9/s7U0AAC5deqUWbl/9KhjgFS1KsFRSXfpkmnu/dprZl8ayfTmmjRJat7c1tIA5BDBUgEgWEKeOHrUzFa6eNG8/XfnnXZXhCIoNlZavtwsdVu/Pu14qVJS794mUGrdmswSAAAUjDNnpNBQ6e23pbg4c6x3b7ODXO3a9tYGIHtyknmwihmw0xtvmFCpRQszTxjIppS+F4MGSZUqmZlIKaHSbbdJ8+eb3HLWLKlNG0IlAABQcMqWNbOU9u41vZacnMyugw0aSM89J504YXeFAPISM5ZyiRlLuGZHjpjZSnFx0tdfS5062V0RioBDh0xoNHeu9Ndfacdr1jR9kx56yCxHAAAAKCy2bzc7yH39tfnY19d8/N//St7e9tYGIHPMWAKKgtBQEyq1aWO6KQNZuHhRWrJE6tzZNEV96SUTKnl7Sw8/LH3/vfT339KYMYRKAACg8LnxRumrr6S1a6UmTaRz50yj7+uvN7OrExPtrhDAtWDGUi4xYwnX5OBB0005Pl5at86sXQLSsSwpPNzMTFq8WIqOTrutbVszO6lXL/OOHwAAQFGRnGzeMHvpJWn/fnOsYUPp9delbt1Yvg8UFsxYAgq7114zoVK7doRKcBAVZXoSNGoktWwpvf++CZVq1JBGjzYzk374wTTkJlQCAABFjbOz9MAD0p9/SlOnSuXKSbt3S3fdJd16q/Tbb3ZXCCCnmLGUS8xYQq7t3y/VrSslJJiEoG1buyuCzeLipM8/N7u6ffWVeSdPkjw9pXvvNSFS+/bmDzEAAIDi5OxZs5/NtGnSpUvmWK9e5n3Y66+3szKgZGPGElCYvfqqCZVuv51QqQSzLGnLFunZZ6UqVaT77pPWrDGhUuvW0owZZle3hQulDh0IlQAAQPFUpoxpPbp3r3kzzclJ+uQTszzumWek48ftrhDA1TBjKZeYsYRc+ecfqV49KSnJ7BXfurXdFaGAHT8uffSRmZ20c2fa8apVzY5uDz9svkUAAABKop07pREjzBtuklSqlPTii9LQoZKPj721ASVJTjIPgqVcIlhCrgwYIM2bJ91xh/Tll3ZXg3yWlGSCpKgo0xtp0SJp9eq0nU88PKSePc27c7ffLrm42FouAABAofHddyZQ2rzZfFypkjR2rPToo5Krq62lASUCwVIBIFhCju3dKzVoYNY6/fabdNNNdleEXIqLM8vUoqKufDl+PK1fUno33WQyxj59pLJlC7x8AACAIiE5WVq2TBo5Utq3zxyrX98snevRgx3kgPxEsFQACJaQY/36mTVQ3bqZTs0odC5cyDokOnIk7frp09k/p7OzVLGi6aN0220mUGrUKN+eAgAAQLETH292yp0wQTp50hxr00aaPFlq1cre2oDiimCpABAsIUf27DFpQkrH5qZN7a6oxLAss9vI1WYXRUVJ585l/7zu7mZKduXKV75UrMgSNwAAgLwQHS1NmiS9+aZ08aI5ds89Zgc5elQCeYtgqQAQLCFH+vSRli41DXVWrLC7mmIhOVk6cSJ7gVFcXPbP6+Nz9bCocmWpXDmmXwMAANjh8GHplVfMZijJyeZNvEGDzLFKleyuDigeCJYKAMESsm3nTunGG83UmW3bzHVkKSEhe/2Ljh0zzbGzq2zZ7AVGvr7599wAAACQd/74w/RfSuky4eMjPf+8uZQqZW9tQFFHsFQACJaQbb16SZ9+av5dtszuamwTG5u92UUp6+azw8lJuu66zAOiKlXSrleqJHl65t9zAwAAgH1+/FF64QUpPNx87O9vZi899pjk5mZvbUBRRbBUAAiWkC3btklNmpgEZMcOKSjI7orylGVJMTHZC4yio7N/XlfX7PUv8vdnu1kAAACYv0s/+UQaNUr6+29zrG5ds4Pc3XfTwgDIKYKlAkCwhGzp2VNaudL0WFq82O5qsi05WTp1KnuBUUrjxOzw8srecrTy5c1uagAAAEBOxMdLM2ZI48ebfpyS2Tlu0iTp5pvtrQ0oSgiWCgDBEq5qyxYpJMQkJH/8IdWvb3dFSkw0vYmuFhYdPWrGZpefX/YCo9KlebcIAAAA+S8mRvrf/6QpU0xLBknq0cPMYGrQwN7agKKAYKkAECzhqrp1k1avlvr1kxYsyNeHunQpe7OLTpww04Szq0KF7PUv8vbOv+cGAAAA5FZUlDR2rPThh2bjF2dn03tp7FjztyyAzBEsFQCCJVzRb79JLVuavU/37JGuv/6aT2lZ0p9/ml0vdu50DIzOnMn+eVxcTG+i7PQvcne/5rIBAAAA2+3ZY3aQW7nSfOztLQ0bZpp+sysw8oJlSQcOmCby4eHmtdRrr9ldVe4RLBUAgiVc0R13SF9/LQ0YIM2Zk+vTJCVJGzea/wBXrZL++ivrsR4e2VuOVqGCCZcAAACAkuann0yY9Ouv5uPrrpPGjJEef5w3VZEzJ05ImzaZECnl3/Q7XPv7m0kARbUVCMFSASBYQpZ+/tl0BnRxkfbulWrVytHdL1yQvvnGhElffGGaaKdwd5duu01q106qWtUxMCpTpuj+0gIAAAAKimVJK1aYGUx795pjdeqY2SW9evE3NTI6f176/fe0ACk8XNq/P+M4Nzfpxhul5s2lm26S+vcvum/qEywVAIIlZOn226V168zi7Zkzs3WXo0fNEreVK6Vvv5Xi4tJuK1tW6tpVuusuqXNn0wAbAAAAwLVJSJBmzTL9lo4fN8datDA7yLVta2tpsFFCgmk9kj5E2r3b7Jx9ufr100Kkm26SGjeWPD0Lvub8kK/BUmBgoAYOHKgBAwaoRo0a11RoUUawhEz98IOZTuTmZt7+CAzMdJhlmV9Oq1aZMOm33xxvr1nT7Fpx111m8pObW75XDgAAAJRI586Z3eP+9z+zekCSuneXXn9datjQ3tqQv5KTpb//dlzStnWr2RzpctWqpYVIzZubDcD9/Aq+5oKSr8HSO++8o7lz52r79u1q3769Hn30Ud19993y8PC4pqKLGoIlZGBZJlT68UfpiSeksDCHmxMTzSq5lDDpn38c7968eVqYFBTEFFwAAACgIB09Ko0fL82YkbaD3MCB0rhxZldkFH1HjjiGSJs2SWfPZhxXpoxjiNS8ecn7HiiQpXDbt2/X7NmztXjxYiUmJuqBBx7QwIED1bRp01wVXdQQLCGD9eulDh1MI6R//pGqVdP586aH96pV0urVGfsldehgwqTu3UveLyoAAACgMIqIkEaNkpYvNx97eUn//a/04ovFe4ZKcRMdLW3e7Nhc+/DhjOM8PKSmTdNCpJtuMj23Svob/QXaYykhIUHTp0/X8OHDlZCQoKCgIA0ePFiPPPKInIrxV4JgCQ4sS7rlFunnn3XkkZf0eYuJWrnStFqKj08bVq6c6ZfUo4fUqRNbmwIAAACF1caNJkz6+WfzcfnyZge5J55gB7nC5tIlaft2xxApIiLjOGdnqVEjxxApKIjWI5kpkGApISFBK1as0Jw5c7R27Vq1bNlSjz76qI4cOaJ3331X7du316JFi3L1BIoCgiWksCzpj5kbtfI/q7XS6W5tskIcbq9VywRJPXpIbdpIrq42FQoAAAAgRyzLrD4YPjwtqKhVy+wgd999JqhAwUpKkv780zFE2rHDNN2+XM2ajs21mzSRSpUq+JqLonwNln7//XfNmTNHixcvlouLi/r376/HHntM9evXTx2zadMmtW3bVhcvXszdMygCCJZKtsRE6aefTK+klSst7dvnODuvRYu0fkkNGzKNEgAAACjKEhOl2bOlV14xvZgk07x50iSpfXt7ayvOLEuKjHTcoW3LFun8+Yxjr7vOMUQKCTHHkDs5yTxynK82b95cf/31l8LCwnTo0CH973//cwiVJKlhw4bq06dPts43ffp01axZU56enmrWrJk2bNhwxfHvvfeeGjRoIC8vL9WrV0/z5893uH358uUKCQlRmTJl5OPjo+DgYC1YsCDDeQ4fPqx+/fqpfPny8vb2VnBwsLZs2ZKtmlEynTsnLVsm9e8vVaxo/gOZNk3at89JHrqkrs5fasb/YnTkiPTrr9LIkWaaJaESAAAAULS5ukqPP252EBs/3sx62bxZuu020+pi5067KyweTp2SvvrKfI67dZMqVTIbbd93nzR5stmE+/x5ycdHattWev55aelSad8+6dgx09f2lVekLl0IlQpSjmcsHThwQAEBAXny4EuXLlX//v01ffp0tWnTRh988IFmzZql3bt3q0aNGhnGh4WFafjw4Zo5c6aaN2+u8PBwDRo0SIsWLVL37t0lSd9//73OnDmj+vXry93dXV988YWGDRum1atXq3PnzpKkM2fOqEmTJmrfvr2efPJJVaxYUf/8848CAwNVu3btbNXOjKWS4fBhM/V11SrTmzt9v6Ty5aVu3Sz12PCCOv77vkq98JR5ywIAAABAsXb8uDRhgvT++2Y2k5OTNGCACUSqVbO7uqLhwgVp61bHJW3//ptxnKur1LixY1+kBg0kF5eCr7kkydelcJs2bVJycrJatGjhcPy3336Ti4uLQkJCsrhnRi1atFDTpk0Vlm5b9gYNGqhnz54KDQ3NML5169Zq06aNJk+enHpsyJAh2rx5s3766acsH6dp06bq2rWrJkyYIEkaMWKEfv7556vOjroSgqXiybLMuw0rV5owafNmx9vr1Enrl9S6teTyxUqpZ08Tme/bRywOAAAAlCB//SW99JJZ2SBJnp7SkCGmJ1OZMnZWVrgkJEh//OEYIu3aJSUnZxxbt65jiBQcbD6vKFg5yTxy3Eb46aef1osvvpghWDp8+LDeeOMN/fbbb9k6T3x8vLZs2aIRI0Y4HO/UqZM2btyY6X3i4uLkedl3lJeXl8LDw5WQkCC3y1q5W5al9evXKyIiQm+88Ubq8VWrVqlz586677779MMPP6hq1ap66qmnNGjQoCzrjYuLU1xcXOrHMTEx2XqeKPwSEqQNG9LCpP37025zcpJatjS9knr0kOrXT7e0LTnZzLOUpOeeI1QCAAAASpjrr5c+/lj67Tezg9yPP0qvvy7NmCGNHi09+aTZzr4ksSzpn38cQ6Tffzc7t12ucmXTnzYlRAoJIZArinIcLO3evVtNmzbNcLxJkybavXt3ts9z8uRJJSUlyd/f3+G4v7+/jqZ0Q7tM586dNWvWLPXs2VNNmzbVli1bNHv2bCUkJOjkyZOqXLmyJCk6OlpVq1ZVXFycXFxcNH36dHXs2DH1PP/++6/CwsI0dOhQjRo1SuHh4Xruuefk4eGhhx56KNPHDg0N1bhx47L9/FC4xcSYtbsrV0pr1khnz6bd5ukpdexogqRu3aTLvkXTrFhh9rT09ZWGDSuIsgEAAAAUQi1aSN9/L33xhTRihLR7t/Tf/0pvvSW9+qrUp0/x3UHu6FHHEGnTJunMmYzj/PxMgJQSIjVvLlWtWvD1Iu/lOFjy8PDQsWPHVKtWLYfjUVFRcs3FPupOl3U2tiwrw7EUo0eP1tGjR9WyZUtZliV/f38NGDBAkyZNkku6BZa+vr7atm2bzp8/r3Xr1mno0KGqVauW2rVrJ0lKTk5WSEiIXnvtNUkmFPvjjz8UFhaWZbA0cuRIDR06NPXjmJgYVa9ePcfPF/Y5eDCtX9J33zluR3nddSZE6tFDuv12s7LtitLPVhoyxDRcAgAAAFBiOTlJ3bubxtHz5kljxpjVEA8+KE2ZYtqxduhgd5XXJibG7MqWskPbpk3mddblPDzMEraUHdqaNzezu4pruFbS5TgJ6tixo0aOHKmVK1fKz89PknT27FmNGjXKYVbQ1VSoUEEuLi4ZZicdP348wyymFF5eXpo9e7Y++OADHTt2TJUrV9aMGTPk6+urChUqpI5zdnZWnTp1JEnBwcHas2ePQkNDU4OlypUrq2HDhg7nbtCggT799NMs6/Xw8JBHSZvDWMRZlplQlLLE7fffHW+vWzetX1LLljls/rZsmVkk7Odn3ooAAAAAAJlm048+KvXta3aRfv1181rk9tulzp2lN96QbrzR7iqvLi5O2rHDMUT680/zOis9JyepYUPHEOmGGyR3d3vqRsHLcbA0ZcoUtW3bVgEBAWrSpIkkadu2bfL399eCBQuyfR53d3c1a9ZMa9eu1d133516fO3aterRo8cV7+vm5qZq/99qf8mSJerWrZucrxB9Wpbl0B+pTZs2ioiIcBizd+/ePNvtDvZJSDBbUKaESZGRabc5OZmG2yn9kurVy+WDJCVJY8ea60OHSmXLXmvZAAAAAIoZb29p1Chp0CBp4kQpLEz6+mvpm2+k/v3NrnKZbIZui+RkKSLCMUTats1xlUeKgADH5tpNm5ruICi5crwrnCRduHBBH330kbZv3y4vLy81btxYffv2zdA8+2qWLl2q/v376/3331erVq00Y8YMzZw5U3/88YcCAgI0cuRIHT58WPPnz5dkwp/w8HC1aNFCZ86c0dSpU7V27Vpt2bJFgYGBkkwvpJCQENWuXVvx8fFas2aNhg8frrCwMD322GOSzM52rVu31rhx43T//fcrPDxcgwYN0owZM/Tggw9mq3Z2hSs8zp5N65f05ZdSdHTabV5eUqdOJkzq1k2qWDEPHvCjj6R+/UygtG+fmbUEAAAAAFfwzz9mB7mlS83HHh5mD6CRIwv2vWrLkg4dcuyLtHmzdO5cxrHlyzuGSM2b59FrKhR6+bornCT5+Pjo8ccfz1Vx6fXu3VunTp3S+PHjFRUVpaCgIK1ZsyZ15lBUVJQi0005SUpK0pQpUxQRESE3Nze1b99eGzduTA2VJBN6PfXUUzp06JC8vLxUv359LVy4UL17904d07x5c61YsUIjR47U+PHjVbNmTU2bNi3boRLsFxlpZiStXGma5CUmpt1WsaJZ29yjh1nD7O2dhw+cmCilNHF//nlCJQAAAADZUru2tGSJ2ffnxRfN65jJk6VZs0zg9PTTZiOhvHb6tAmQUkKk8HDp2LGM47y9pWbN0kKkm26SAgPT7YoNZCFXM5YksztcZGSk4uPjHY7fddddeVJYYceMpYJlWdLWrWlh0rZtjrfXr5/WL+mmm3LYLykn5s2TBgww0f2+fcz5BAAAAJBjlmVWWwwfLu3aZY7VqGF2kHvggdw3uY6NNa+b0odI//yTcZyLi9S4seNMpIYNTX8oQMpZ5pHjYOnff//V3XffrZ07d8rJyUkpd0/ZyS0pKSmXZRctBEv5Lz7epPgpO7ml323A2Vlq08YscbvrLtOIO98lJJgE699/Tce9F18sgAcFAAAAUFwlJUnz50ujR0uHD5tjwcFmB7mr7Y2VmGj2E0oJkTZtknbuNOe8XJ06js21g4PzeGUHip18DZa6d+8uFxcXzZw5U7Vq1VJ4eLhOnTqlYcOG6X//+59uueWWayq+qCBYyh9nz0pr1qT1S0q/ztfb2+yicNddUteu0nXXFXBxH34oPfaYeeB9+yQfnwIuAAAAAEBxdPGi9NZbZge5lJ6xHTua97ObNDEznPbtc2yuvWWLud/lKlVyDJFCQqRy5Qr2+aDoy9dgqUKFClq/fr0aN24sPz8/hYeHq169elq/fr2GDRumrVu3XlPxRQXBUt7Zvz9tiduPPzr2S/L3T5uV1KGDacZti/h4My3qwAFpyhSzGxwAAAAA5KFTp8xyuPfeMy9BJKllS+mvv8xtl/P1dVzOdtNNUtWq9EXCtcvX5t1JSUkqVaqUJBMyHTlyRPXq1VNAQIAiIiJyVzFKFMsy6XpKmLRjh+PtDRuaXkl33WV+MeZ2fXGemjPHhEqVKklPPGF3NQAAAACKofLlpalTpWeflV5+WVq0SPr1V3Obu7tZwpa+uXbduoXk9RJKtBwHS0FBQdqxY4dq1aqlFi1aaNKkSXJ3d9eMGTNUq1at/KgRxUBcnPTdd2n9klLWD0vmF+HNN6eFSXXq2FdnpuLipIkTzfWRI1mMDAAAACBf1awpffSRaev6++/SDTeYi4eH3ZUBGeU4WHr55Zd14cIFSdLEiRPVrVs33XLLLSpfvryWLl2a5wWi6Dp92vRLWrVK+uorx35JPj6mX1KPHqZfUvny9tV5VbNmSYcOmTmljz9udzUAAAAASogbbzQXoDDLcY+lzJw+fVply5ZN3RmuJKDHUub27TPL21atMv2S0u9IULmy1L27CZNuu03y9LSvzmy7eNFMoTpyRJo+XXrySbsrAgAAAAAgX+Vbj6XExER5enpq27ZtCgoKSj1ejhbzJVZysumXtHKlueza5Xh7UFDaEreQkCK4/nfGDBMq1aghDRxodzUAAAAAABQqOQqWXF1dFRAQoKT001BQ4ly6JK1fb2Ylff65yV1SuLhIt9ySFiYV6bZbsbFSaKi5/vLLLGgGAAAAAOAyueqxNHLkSC1cuJCZSiXIqVPS6tVp/ZL+v82WJKlUKemOO0yYdOedUrH5tggLk44dM53zBgywuxoAAAAAAAqdHAdLb7/9tv7++29VqVJFAQEB8vHxcbj9999/z7PiYK9//knrl/TTT479kqpUMTOSevSQ2rcvhpN5zp+XXn/dXB89WnJzs7ceAAAAAAAKoRwHSz179syHMlAYJCdLmzal9Uvavdvx9saN08KkZs2kYt2r/d13pZMnpdq1pf797a4GAAAAAIBCKU92hSuJisuucBcvmn5JK1eafklHj6bd5uIi3XqrCZK6dzcrwkqEmBjzZE+flubPJ1gCAAAAAJQo+bYrHIqX4cPNxJzY2LRjvr5Sly4mTOrSRSpb1r76bPP22yZUqldP6tvX7moAAAAAACi0chwsOTs7y+kKa6DYMa7o8PQ0oVK1amlL3G69tRj2S8qJs2elKVPM9VdekVzJXgEAAAAAyEqOXzWvWLHC4eOEhARt3bpV8+bN07hx4/KsMOS/xx4zYVKTJsW8X1JOTJtmwqWGDaX777e7GgAAAAAACrU867G0aNEiLV26VCtXrsyL0xV6xaXHEtI5fdr0VoqJkT7+WLrvPrsrAgAAAACgwOUk83DOqwdt0aKFvv3227w6HVDwpk41odINN0j33mt3NQAAAAAAFHp5EixdvHhR77zzjqpVq5YXpwMK3smT0ltvmevjxknOeZa5AgAAAABQbOW4x1LZsmUdmndblqVz587J29tbCxcuzNPigALzv/9J58+bhlM9e9pdDQAAAAAARUKOg6U333zTIVhydnbWddddpxYtWqhsidybHkXe8ePSO++Y6+PG0ckcAAAAAIBsynGwNGDAgHwoA7DRpElSbKwUEiJ162Z3NQAAAAAAFBk5biQzZ84cLVu2LMPxZcuWad68eXlSFFBgoqKk994z18ePZ7YSAAAAAAA5kONg6fXXX1eFChUyHK9YsaJee+21PCkKKDBvvCFduiS1bCndcYfd1QAAAAAAUKTkOFg6cOCAatasmeF4QECAIiMj86QooEAcPiy9/765zmwlAAAAAAByLMfBUsWKFbVjx44Mx7dv367y5cvnSVFAgQgNleLipJtvlm6/3e5qAAAAAAAocnIcLPXp00fPPfecvvvuOyUlJSkpKUnr16/X4MGD1adPn/yoEch7kZHSzJnm+oQJzFYCAAAAACAXcrwr3MSJE3XgwAF16NBBrq7m7snJyXrooYfosYSi47XXpPh4qX17qV07u6sBAAAAAKBIcrIsy8rNHf/66y9t27ZNXl5euuGGGxQQEJDXtRVqMTEx8vPzU3R0tEqXLm13OciJ/ful66+XEhOlH3+UbrnF7ooAAAAAACg0cpJ55HjGUorrr79e119/fW7vDthn4kQTKnXsSKgEAAAAAMA1yHGPpV69eun111/PcHzy5Mm677778qQoIN/88480d665Pm6craUAAAAAAFDU5ThY+uGHH9S1a9cMx++44w79+OOPeVIUkG/Gj5eSkqQuXaRWreyuBgAAAACAIi3HwdL58+fl7u6e4bibm5tiYmLypCggX0RESAsXmuvMVgIAAAAA4JrlOFgKCgrS0qVLMxxfsmSJGjZsmCdFAfli/HgpOVnq3l1q3tzuagAAAAAAKPJy3Lx79OjRuvfee/XPP//otttukyStW7dOixYt0ieffJLnBQJ5YvduafFic53ZSgAAAAAA5Ikcz1i666679Nlnn+nvv//WU089pWHDhunw4cNav369AgMDc1zA9OnTVbNmTXl6eqpZs2basGHDFce/9957atCggby8vFSvXj3Nnz/f4fbly5crJCREZcqUkY+Pj4KDg7VgwYIszxcaGionJycNGTIkx7WjCBk3TrIs6e67pSZN7K4GAAAAAIBiIcczliSpa9euqQ28z549q48++khDhgzR9u3blZSUlO3zLF26VEOGDNH06dPVpk0bffDBB+rSpYt2796tGjVqZBgfFhamkSNHaubMmWrevLnCw8M1aNAglS1bVt27d5cklStXTi+99JLq168vd3d3ffHFF3rkkUdUsWJFde7c2eF8mzZt0owZM9S4cePcfBpQVOzcKX38sbk+dqytpQAAAAAAUJw4WZZl5eaO69ev1+zZs7V8+XIFBATo3nvv1b333qsmOZgN0qJFCzVt2lRhYWGpxxo0aKCePXsqNDQ0w/jWrVurTZs2mjx5cuqxIUOGaPPmzfrpp5+yfJymTZuqa9eumjBhQuqx8+fPq2nTppo+fbomTpyo4OBgTZs2Ldu1x8TEyM/PT9HR0SpdunS27wcb3HuvtHy5dN99aQETAAAAAADIVE4yjxwthTt06JAmTpyoWrVqqW/fvipbtqwSEhL06aefauLEiTkKleLj47VlyxZ16tTJ4XinTp20cePGTO8TFxcnT09Ph2NeXl4KDw9XQkJChvGWZWndunWKiIhQ27ZtHW57+umn1bVrV91+++3ZqjcuLk4xMTEOFxQBW7eaUMnJSXrlFburAQAAAACgWMl2sHTnnXeqYcOG2r17t9555x0dOXJE77zzTq4f+OTJk0pKSpK/v7/DcX9/fx09ejTT+3Tu3FmzZs3Sli1bZFmWNm/erNmzZyshIUEnT55MHRcdHa1SpUrJ3d1dXbt21TvvvKOOHTum3r5kyRL9/vvvmc6KykpoaKj8/PxSL9WrV8/hM4YtUpa+9ekjNWpkaykAAAAAABQ32e6x9M033+i5557Tk08+qeuvvz7PCnBycnL42LKsDMdSjB49WkePHlXLli1lWZb8/f01YMAATZo0SS4uLqnjfH19tW3bNp0/f17r1q3T0KFDVatWLbVr104HDx7U4MGD9c0332SY/XQlI0eO1NChQ1M/jomJIVwq7DZvllatkpydpTFj7K4GAAAAAIBiJ9szljZs2KBz584pJCRELVq00LvvvqsTJ07k+oErVKggFxeXDLOTjh8/nmEWUwovLy/Nnj1bsbGx2r9/vyIjIxUYGChfX19VqFAhdZyzs7Pq1Kmj4OBgDRs2TL169UqdnbRlyxYdP35czZo1k6urq1xdXfXDDz/o7bfflqura5bNxz08PFS6dGmHCwq5lKVvDz4o1a9vby0AAAAAABRD2Q6WWrVqpZkzZyoqKkr/+c9/tGTJElWtWlXJyclau3atzp07l6MHdnd3V7NmzbR27VqH42vXrlXr1q2veF83NzdVq1ZNLi4uWrJkibp16yZn56yfimVZiouLkyR16NBBO3fu1LZt21IvISEhevDBB7Vt2zaHmU8own79VVqzRnJxkUaPtrsaAAAAAACKpWwvhUvh7e2tgQMHauDAgYqIiNCHH36o119/XSNGjFDHjh21atWqbJ9r6NCh6t+/v0JCQtSqVSvNmDFDkZGReuKJJySZ5WeHDx/W/PnzJUl79+5VeHi4WrRooTNnzmjq1KnatWuX5s2bl3rO0NBQhYSEqHbt2oqPj9eaNWs0f/781J3nfH19FRQU5FCHj4+Pypcvn+E4irCU2UoPPSTl4dJNAAAAAACQJsfBUnr16tXTpEmTFBoaqs8//1yzZ8/O0f179+6tU6dOafz48YqKilJQUJDWrFmjgIAASVJUVJQiIyNTxyclJWnKlCmKiIiQm5ub2rdvr40bNyowMDB1zIULF/TUU0/p0KFD8vLyUv369bVw4UL17t37Wp4qipKffpK++UZydZVeftnuagAAAAAAKLacLMuy7C6iKIqJiZGfn5+io6Ppt1TYdOggrV8vDRokzZhhdzUAAAAAABQpOck8st1jCSgSvv/ehEpubsxWAgAAAAAgnxEsofiwrLTeSoMGSTVq2FsPAAAAAADFHMESio/166Uff5Q8PKSRI+2uBgAAAACAYo9gCcWDZUljxpjr//mPVK2avfUAAAAAAFACECyhePjmG2njRsnTUxoxwu5qAAAAAAAoEQiWUPSln6301FNS5cr21gMAAAAAQAlBsISib80aKTxc8vaWXnzR7moAAAAAACgxCJZQtKWfrfTMM5K/v731AAAAAABQghAsoWhbuVL6/XepVCnphRfsrgYAAAAAgBKFYAlFV3Ky9Mor5vpzz0kVKthbDwAAAAAAJQzBEoqu5culHTskX19p2DC7qwEAAAAAoMQhWELRlJSUNlvpv/+VypWztx4AAAAAAEoggiUUTcuWSbt3S35+JlgCAAAAAAAFjmAJRU9SkjR2rLk+bJhUpoyd1QAAAAAAUGIRLKHoWbxYioiQypaVBg+2uxoAAAAAAEosgiUULYmJ0rhx5voLL0ilS9tbDwAAAAAAJRjBEoqWhQulv/+WKlSQnnnG7moAAAAAACjRCJZQdCQkSOPHm+svvij5+tpbDwAAAAAAJRzBEoqOefOkffukihWlp56yuxoAAAAAAEo8giUUDfHx0oQJ5vqIEZKPj731AAAAAAAAgiUUEbNnS5GRUuXK0hNP2F0NAAAAAAAQwRKKgkuXpFdfNddHjZK8vOytBwAAAAAASCJYQlEwa5Z06JBUrZr02GN2VwMAAAAAAP4fwRIKt4sXpddeM9dfekny9LS3HgAAAAAAkIpgCYXbBx9IUVFSjRrSwIF2VwMAAAAAANIhWELhdeGCFBpqro8eLbm721sPAAAAAABwQLCEwissTDp+XKpZU3r4YburAQAAAAAAlyFYQuF0/rz0xhvm+pgxkpubvfUAAAAAAIAMCJZQOL3zjnTypFSnjtSvn93VAAAAAACATBAsofCJiZEmTzbXX3lFcnW1tx4AAAAAAJApgiUUPm+9JZ05I9WrJ/Xta3c1AAAAAAAgCwRLKFzOnpWmTDHXx46VXFzsrAYAAAAAAFwBwRIKlzfflKKjpUaNpPvus7saAAAAAABwBQRLKDxOnzbBksRsJQAAAAAAigCCJRQeU6ZI585JjRtL99xjdzUAAAAAAOAqbA+Wpk+frpo1a8rT01PNmjXThg0brjj+vffeU4MGDeTl5aV69epp/vz5DrcvX75cISEhKlOmjHx8fBQcHKwFCxY4jAkNDVXz5s3l6+urihUrqmfPnoqIiMjz54YcOHnSNO2WpHHjJGfbvzUBAAAAAMBV2PrqfenSpRoyZIheeuklbd26Vbfccou6dOmiyMjITMeHhYVp5MiRGjt2rP744w+NGzdOTz/9tD7//PPUMeXKldNLL72kX375RTt27NAjjzyiRx55RF9//XXqmB9++EFPP/20fv31V61du1aJiYnq1KmTLly4kO/PGVmYPFm6cEFq0kTq0cPuagAAAAAAQDY4WZZl2fXgLVq0UNOmTRUWFpZ6rEGDBurZs6dCQ0MzjG/durXatGmjyZMnpx4bMmSINm/erJ9++inLx2natKm6du2qCRMmZHr7iRMnVLFiRf3www9q27ZttmqPiYmRn5+foqOjVbp06WzdB1k4dkyqVUuKjZU+/1zq1s3uigAAAAAAKLFyknnYNmMpPj5eW7ZsUadOnRyOd+rUSRs3bsz0PnFxcfL09HQ45uXlpfDwcCUkJGQYb1mW1q1bp4iIiCsGRtHR0ZLMbKesxMXFKSYmxuGCPDJpkgmVmjeXuna1uxoAAAAAAJBNtgVLJ0+eVFJSkvz9/R2O+/v76+jRo5nep3Pnzpo1a5a2bNkiy7K0efNmzZ49WwkJCTp58mTquOjoaJUqVUru7u7q2rWr3nnnHXXs2DHTc1qWpaFDh+rmm29WUFBQlvWGhobKz88v9VK9evVcPGtkEBUlTZ9uro8fLzk52VsPAAAAAADINts7JDtdFiRYlpXhWIrRo0erS5cuatmypdzc3NSjRw8NGDBAkuSSbmt6X19fbdu2TZs2bdKrr76qoUOH6vvvv8/0nM8884x27NihxYsXX7HOkSNHKjo6OvVy8ODB7D9JZO3116VLl6RWraTOne2uBgAAAAAA5IBtwVKFChXk4uKSYXbS8ePHM8xiSuHl5aXZs2crNjZW+/fvV2RkpAIDA+Xr66sKFSqkjnN2dladOnUUHBysYcOGqVevXpn2bHr22We1atUqfffdd6pWrdoV6/Xw8FDp0qUdLrhGhw5JH3xgrk+YwGwlAAAAAACKGNuCJXd3dzVr1kxr1651OL527Vq1bt36ivd1c3NTtWrV5OLioiVLlqhbt25yvsL29JZlKS4uzuHjZ555RsuXL9f69etVs2bNa3syyJ3QUCkuTmrbVrrtNrurAQAAAAAAOeRq54MPHTpU/fv3V0hIiFq1aqUZM2YoMjJSTzzxhCSz/Ozw4cOaP3++JGnv3r0KDw9XixYtdObMGU2dOlW7du3SvHnzUs8ZGhqqkJAQ1a5dW/Hx8VqzZo3mz5/vsPPc008/rUWLFmnlypXy9fVNnTXl5+cnLy+vAvwMlGCRkdLMmeY6vZUAAAAAACiSbA2WevfurVOnTmn8+PGKiopSUFCQ1qxZo4CAAElSVFSUIiMjU8cnJSVpypQpioiIkJubm9q3b6+NGzcqMDAwdcyFCxf01FNP6dChQ/Ly8lL9+vW1cOFC9e7dO3VMSsjUrl07h3rmzJmT2rMJ+ezVV6WEBDNT6dZb7a4GAAAAAADkgpNlWZbdRRRFMTEx8vPzU3R0NP2WcmrfPqluXSkxUdqwQbr5ZrsrAgAAAAAA/y8nmYftu8KhBJo40YRKnToRKgEAAAAAUIQRLKFg/f23lNITa9w4e2sBAAAAAADXhGAJBWvCBCkpSbrzTqllS7urAQAAAAAA14BgCQXnzz+lhQvNdWYrAQAAAABQ5BEsoeCMHy8lJ0t33SWFhNhdDQAAAAAAuEYESygYf/whLVliro8da2spAAAAAAAgbxAsoWCMGydZlnTPPVKTJnZXAwAAAAAA8gDBEvLfjh3SsmXmOrOVAAAAAAAoNgiWkP9SwqT775duuMHWUgAAAAAAQN4hWEL++v13acUKyclJeuUVu6sBAAAAAAB5iGAJ+StltlLfvlLDhraWAgAAAAAA8hbBEvLPpk3S559Lzs7SmDF2VwMAAAAAAPIYwRLyT8rSt379pHr17K0FAAAAAADkOYIl5I9ffpG+/FJycZFGj7a7GgAAAAAAkA8IlpA/UmYrPfywVKeOvbUAAAAAAIB8QbCEvLdhg7R2reTqymwlAAAAAACKMYIl5L2U2UqPPioFBtpaCgAAAAAAyD8ES8hb331nLu7u0qhRdlcDAAAAAADyEcES8o5lpc1WGjRIqlHD3noAAAAAAEC+IlhC3lm3zvRX8vCQRo60uxoAAAAAAJDPCJaQNyxLGjPGXH/iCalqVXvrAQAAAAAA+Y5gCXnj66+lX36RvLykESPsrgYAAAAAABQAgiVcu/SzlZ56SqpUyd56AAAAAABAgSBYwrVbvVratEny9pZefNHuagAAAAAAQAEhWMK1ST9b6dlnpYoV7a0HAAAAAAAUGIIlXJvPPpO2bpVKlZKef97uagAAAAAAQAEiWELuJSdLr7xirg8eLFWoYG89AAAAAACgQBEsIfc+/VTauVMqXVoaOtTuagAAAAAAQAEjWELuJCVJY8ea6//9r1SunK3lAAAAAACAgkewhNz5+GNp926pTBlpyBC7qwEAAAAAADYgWELOJSamzVYaNsyESwAAAAAAoMQhWELOLV4s7d1rlr8995zd1QAAAAAAAJsQLCFnEhOlcePM9RdeMI27AQAAAABAiUSwhJxZsED65x+pQgXpmWfsrgYAAAAAANiIYAnZl5AgjR9vrg8fLpUqZW89AAAAAADAVrYHS9OnT1fNmjXl6empZs2aacOGDVcc/95776lBgwby8vJSvXr1NH/+fIfbly9frpCQEJUpU0Y+Pj4KDg7WggULrvlxIWnuXGn/fsnfX3rqKburAQAAAAAANrM1WFq6dKmGDBmil156SVu3btUtt9yiLl26KDIyMtPxYWFhGjlypMaOHas//vhD48aN09NPP63PP/88dUy5cuX00ksv6ZdfftGOHTv0yCOP6JFHHtHXX3+d68eFpLg4aeJEc33kSMnb2956AAAAAACA7Zwsy7LsevAWLVqoadOmCgsLSz3WoEED9ezZU6GhoRnGt27dWm3atNHkyZNTjw0ZMkSbN2/WTz/9lOXjNG3aVF27dtWECRNy9biSFBcXp7i4uNSPY2JiVL16dUVHR6t0SWhgHRZmZilVqSL9/bfk5WV3RQAAAAAAIB/ExMTIz88vW5mHbTOW4uPjtWXLFnXq1MnheKdOnbRx48ZM7xMXFydPT0+HY15eXgoPD1dCQkKG8ZZlad26dYqIiFDbtm1z/biSFBoaKj8/v9RL9erVs/U8i4VLl6RXXzXXR40iVAIAAAAAAJJsDJZOnjyppKQk+fv7Oxz39/fX0aNHM71P586dNWvWLG3ZskWWZWnz5s2aPXu2EhISdPLkydRx0dHRKlWqlNzd3dW1a1e988476tixY64fV5JGjhyp6Ojo1MvBgwdz+9SLnpkzpcOHpWrVpMces7saAAAAAABQSLjaXYCTk5PDx5ZlZTiWYvTo0Tp69Khatmwpy7Lk7++vAQMGaNKkSXJxcUkd5+vrq23btun8+fNat26dhg4dqlq1aqldu3a5elxJ8vDwkIeHRy6eYRF38aL02mvm+ssvSyXxcwAAAAAAADJl24ylChUqyMXFJcMsoePHj2eYTZTCy8tLs2fPVmxsrPbv36/IyEgFBgbK19dXFSpUSB3n7OysOnXqKDg4WMOGDVOvXr1Seyfl5nFLtPffl44elQICpEcesbsaAAAAAABQiNgWLLm7u6tZs2Zau3atw/G1a9eqdevWV7yvm5ubqlWrJhcXFy1ZskTdunWTs3PWT8WyrNTG29fyuCXOhQvS66+b66NHS+7u9tYDAAAAAAAKFVuXwg0dOlT9+/dXSEiIWrVqpRkzZigyMlJPPPGEJNPX6PDhw5o/f74kae/evQoPD1eLFi105swZTZ06Vbt27dK8efNSzxkaGqqQkBDVrl1b8fHxWrNmjebPn++wA9zVHhf/b/p06fhxqVYt6aGH7K4GAAAAAAAUMrYGS71799apU6c0fvx4RUVFKSgoSGvWrFFAQIAkKSoqSpGRkanjk5KSNGXKFEVERMjNzU3t27fXxo0bFRgYmDrmwoULeuqpp3To0CF5eXmpfv36WrhwoXr37p3tx4Wkc+ekN94w18eMkdzc7K0HAAAAAAAUOk6WZVl2F1EUxcTEyM/PT9HR0SpdurTd5eS90FBp1Cjp+uul3bslV9v7vAMAAAAAgAKQk8zDth5LKMSio6XJk831V14hVAIAAAAAAJkiWEJGb70lnTkj1a8v9eljdzUAAAAAAKCQIliCozNnpKlTzfWxYyUXF1vLAQAAAAAAhRfBEhy9+aZZCteokXTffXZXAwAAAAAACjGCJaQ5dUqaNs1cHzdOcubbAwAAAAAAZI3kAGmmTJHOnZNuvFG6+267qwEAAAAAAIUcwRKMEyekt98215mtBAAAAAAAsoH0AMbkydKFC1LTptJdd9ldDQAAAAAAKAIIliAdOya9+665Pn685ORkbz0AAAAAAKBIIFiC9MYb0sWLUosW0p132l0NAAAAAAAoIgiWSrojR6SwMHOd2UoAAAAAACAHCJZKutdfly5dktq0kTp2tLsaAAAAAABQhBAslWSHDkkffGCuM1sJAAAAAADkEMFSSfbaa1J8vHTrrVL79nZXAwAAAAAAihiCpZKseXOpenVp3DhmKwEAAAAAgBxzsizLsruIoigmJkZ+fn6Kjo5W6dKl7S4n9xISJDc3u6sAAAAAAACFRE4yD2YslXSESgAAAAAAIJcIlgAAAAAAAJArBEsAAAAAAADIFYIlAAAAAAAA5ArBEgAAAAAAAHKFYAkAAAAAAAC5QrAEAAAAAACAXCFYAgAAAAAAQK4QLAEAAAAAACBXCJYAAAAAAACQKwRLAAAAAAAAyBVXuwsoqizLkiTFxMTYXAkAAAAAAEDeSck6UrKPKyFYyqVz585JkqpXr25zJQAAAAAAAHnv3Llz8vPzu+IYJys78RMySE5O1pEjR+Tr6ysnJye7y8mVmJgYVa9eXQcPHlTp0qXtLgco1vh5AwoGP2tAweBnDSgY/KzBLpZl6dy5c6pSpYqcna/cRYkZS7nk7OysatWq2V1GnihdujS/pIACws8bUDD4WQMKBj9rQMHgZw12uNpMpRQ07wYAAAAAAECuECwBAAAAAAAgVwiWSjAPDw+98sor8vDwsLsUoNjj5w0oGPysAQWDnzWgYPCzhqKA5t0AAAAAAADIFWYsAQAAAAAAIFcIlgAAAAAAAJArBEsAAAAAAADIFYIlAAAAAAAA5ArBUgk2ffp01axZU56enmrWrJk2bNhgd0lAsRIaGqrmzZvL19dXFStWVM+ePRUREWF3WUCxFxoaKicnJw0ZMsTuUoBi6fDhw+rXr5/Kly8vb29vBQcHa8uWLXaXBRQriYmJevnll1WzZk15eXmpVq1aGj9+vJKTk+0uDciAYKmEWrp0qYYMGaKXXnpJW7du1S233KIuXbooMjLS7tKAYuOHH37Q008/rV9//VVr165VYmKiOnXqpAsXLthdGlBsbdq0STNmzFDjxo3tLgUols6cOaM2bdrIzc1NX375pXbv3q0pU6aoTJkydpcGFCtvvPGG3n//fb377rvas2ePJk2apMmTJ+udd96xuzQgAyfLsiy7i0DBa9GihZo2baqwsLDUYw0aNFDPnj0VGhpqY2VA8XXixAlVrFhRP/zwg9q2bWt3OUCxc/78eTVt2lTTp0/XxIkTFRwcrGnTptldFlCsjBgxQj///DMz3YF81q1bN/n7++vDDz9MPXbvvffK29tbCxYssLEyICNmLJVA8fHx2rJlizp16uRwvFOnTtq4caNNVQHFX3R0tCSpXLlyNlcCFE9PP/20unbtqttvv93uUoBia9WqVQoJCdF9992nihUrqkmTJpo5c6bdZQHFzs0336x169Zp7969kqTt27frp59+0p133mlzZUBGrnYXgIJ38uRJJSUlyd/f3+G4v7+/jh49alNVQPFmWZaGDh2qm2++WUFBQXaXAxQ7S5Ys0e+//65NmzbZXQpQrP37778KCwvT0KFDNWrUKIWHh+u5556Th4eHHnroIbvLA4qN4cOHKzo6WvXr15eLi4uSkpL06quvqm/fvnaXBmRAsFSCOTk5OXxsWVaGYwDyxjPPPKMdO3bop59+srsUoNg5ePCgBg8erG+++Uaenp52lwMUa8nJyQoJCdFrr70mSWrSpIn++OMPhYWFESwBeWjp0qVauHChFi1apEaNGmnbtm0aMmSIqlSpoocfftju8gAHBEslUIUKFeTi4pJhdtLx48czzGICcO2effZZrVq1Sj/++KOqVatmdzlAsbNlyxYdP35czZo1Sz2WlJSkH3/8Ue+++67i4uLk4uJiY4VA8VG5cmU1bNjQ4ViDBg306aef2lQRUDy98MILGjFihPr06SNJuuGGG3TgwAGFhoYSLKHQocdSCeTu7q5mzZpp7dq1DsfXrl2r1q1b21QVUPxYlqVnnnlGy5cv1/r161WzZk27SwKKpQ4dOmjnzp3atm1b6iUkJEQPPvigtm3bRqgE5KE2bdooIiLC4djevXsVEBBgU0VA8RQbGytnZ8eX6y4uLkpOTrapIiBrzFgqoYYOHar+/fsrJCRErVq10owZMxQZGaknnnjC7tKAYuPpp5/WokWLtHLlSvn6+qbOEvTz85OXl5fN1QHFh6+vb4beZT4+Pipfvjw9zYA89t///letW7fWa6+9pvvvv1/h4eGaMWOGZsyYYXdpQLHSvXt3vfrqq6pRo4YaNWqkrVu3aurUqRo4cKDdpQEZOFmWZdldBOwxffp0TZo0SVFRUQoKCtKbb77JFuhAHsqqZ9mcOXM0YMCAgi0GKGHatWun4OBgTZs2ze5SgGLniy++0MiRI/XXX3+pZs2aGjp0qAYNGmR3WUCxcu7cOY0ePVorVqzQ8ePHVaVKFfXt21djxoyRu7u73eUBDgiWAAAAAAAAkCv0WAIAAAAAAECuECwBAAAAAAAgVwiWAAAAAAAAkCsESwAAAAAAAMgVgiUAAAAAAADkCsESAAAAAAAAcoVgCQAAAAAAALlCsAQAAAAAAIBcIVgCAAAoxpycnPTZZ5/ZXQYAACimCJYAAADyyYABA+Tk5JThcscdd9hdGgAAQJ5wtbsAAACA4uyOO+7QnDlzHI55eHjYVA0AAEDeYsYSAABAPvLw8FClSpUcLmXLlpVklqmFhYWpS5cu8vLyUs2aNbVs2TKH++/cuVO33XabvLy8VL58eT3++OM6f/68w5jZs2erUaNG8vDwUOXKlfXMM8843H7y5Endfffd8vb21vXXX69Vq1bl75MGAAAlBsESAACAjUaPHq17771X27dvV79+/dS3b1/t2bNHkhQbG6s77rhDZcuW1aZNm7Rs2TJ9++23DsFRWFiYnn76aT3++OPauXOnVq1apTp16jg8xrhx43T//fdrx44duvPOO/Xggw/q9OnTBfo8AQBA8eRkWZZldxEAAADF0YABA7Rw4UJ5eno6HB8+fLhGjx4tJycnPfHEEwoLC0u9rWXLlmratKmmT5+umTNnavjw4Tp48KB8fHwkSWvWrFH37t115MgR+fv7q2rVqnrkkUc0ceLETGtwcnLSyy+/rAkTJkiSLly4IF9fX61Zs4ZeTwAA4JrRYwkAACAftW/f3iE4kqRy5cqlXm/VqpXDba1atdK2bdskSXv27NGNN96YGipJUps2bZScnKyIiAg5OTnpyJEj6tChwxVraNy4cep1Hx8f+fr66vjx47l9SgAAAKkIlgAAAPKRj49PhqVpV+Pk5CRJsiwr9XpmY7y8vLJ1Pjc3twz3TU5OzlFNAAAAmaHHEgAAgI1+/fXXDB/Xr19fktSwYUNt27ZNFy5cSL39559/lrOzs+rWrStfX18FBgZq3bp1BVozAABACmYsAQAA5KO4uDgdPXrU4Zirq6sqVKggSVq2bJlCQkJ0880366OPPlJ4eLg+/PBDSdKDDz6oV155RQ8//LDGjh2rEydO6Nlnn1X//v3l7+8vSRo7dqyeeOIJVaxYUV26dNG5c+f0888/69lnny3YJwoAAEokgiUAAIB89NVXX6ly5coOx+rVq6c///xTktmxbcmSJXrqqadUqVIlffTRR2rYsKEkydvbW19//bUGDx6s5s2by9vbW/fee6+mTp2aeq6HH35Yly5d0ptvvqnnn39eFSpUUK9evQruCQIAgBKNXeEAAABs4uTkpBUrVqhnz552lwIAAJAr9FgCAAAAAABArhAsAQAAAAAAIFfosQQAAGATOhIAAICijhlLAAAAAAAAyBWCJQAAAAAAAOQKwRIAAAAAAAByhWAJAAAAAAAAuUKwBAAAAAAAgFwhWAIAAAAAAECuECwBAAAAAAAgVwiWAAAAAAAAkCv/B7bnRm8dilacAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the training and validation accuracies as functions of epoch\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'val_accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVRv5V2NO47f"
   },
   "source": [
    "Evaluate the performance of the model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "0565ad1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1797\n",
      "The loss value of the model on the test data is 0.18737970292568207\n",
      "The accuracy of the model on the test data is 0.9365333318710327\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy of the model on the testing data set using the 'evaluate()' method\n",
    "performance_test = nn1.evaluate(X_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the test data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the test data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S80lrDQv3BJD"
   },
   "source": [
    "### Find the optimal parameters using RandomizedSearchCV\n",
    "\n",
    "Randomized search cross-validation is a technique used for hyperparameter optimization in machine learning models. It is an alternative to grid search, which exhaustively searches through all possible combinations of hyperparameters.\n",
    "\n",
    "In randomized search cross-validation, instead of trying every combination, a fixed number of random combinations of hyperparameters are sampled from a predefined search space. This approach allows for a more efficient exploration of the hyperparameter space, especially when the search space is large.\n",
    "\n",
    "\n",
    "You can understand about its implementation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "CfuGYfyFtSWt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV 1/2] END model__activation_function=relu, model__hidden1_neurons=303;, score=0.919 total time=   1.5s\n",
      "[CV 2/2] END model__activation_function=relu, model__hidden1_neurons=303;, score=0.923 total time=   1.5s\n",
      "[CV 1/2] END model__activation_function=sigmoid, model__hidden1_neurons=448;, score=0.932 total time=   1.2s\n",
      "[CV 2/2] END model__activation_function=sigmoid, model__hidden1_neurons=448;, score=0.934 total time=   1.5s\n",
      "\n",
      "The optimal value of activation function is sigmoid\n",
      "\n",
      "The optimal value of hidden1_neurons is 448\n",
      "\n",
      "The accuracy of the model with these optimal parameters is 0.93307120828334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distribution for randomized search\n",
    "parameters_dist = {\n",
    "    'model__activation_function': ['relu', 'sigmoid'],\n",
    "    'model__hidden1_neurons': randint(256, 513),  # Range of values for hidden1_neurons\n",
    "}\n",
    "# Initialize a basic NN object using the 'KerasClassifier()' method\n",
    "base_random_model = KerasClassifier(build_fn=create_nn, verbose=0)\n",
    "\n",
    "# Perform randomized search using the 'RandomizedSearchCV()' method\n",
    "\n",
    "# Note: Set the 'estimator' parameter to 'base_random_model' - This specifies the estimator to be used by 'RandomizedSearchCV()'\n",
    "# Note: Set the 'param_distributions' parameter to 'parameters_dist' - This specifies the parameters to search over\n",
    "# Note: Set the 'cv' parameter to 2 - This specifies the number of folds in the cross-validation process\n",
    "# Note: Set the 'n_iter' parameter to 2 - This specifies the number of parameter settings that are sampled\n",
    "# Note: Set the 'verbose' parameter to 4 - This helps show more relevant information during training\n",
    "# Note: Set the 'random_state' parameter to 0 - This helps generate the consistent results across multiple runs\n",
    "randomized_search = RandomizedSearchCV(estimator=base_random_model,\n",
    "    param_distributions=parameters_dist,\n",
    "    n_iter=2,  # Number of parameter settings to sample\n",
    "    cv=2,  # Number of cross-validation folds\n",
    "    verbose=4,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Train the model on the training data using the 'fit()' method\n",
    "# Note: Set the 'epochs' parameter to 10\n",
    "randomized_model = randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal values of 'activation_function' and 'hidden1_neurons'\n",
    "best_activation_function = randomized_model.best_params_['model__activation_function']\n",
    "best_hidden1_neurons = randomized_model.best_params_['model__hidden1_neurons']\n",
    "best_accuracy = randomized_model.best_score_\n",
    "\n",
    "print('\\nThe optimal value of activation function is', best_activation_function)\n",
    "print('\\nThe optimal value of hidden1_neurons is', best_hidden1_neurons)\n",
    "print('\\nThe accuracy of the model with these optimal parameters is', best_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ4ufJzY3Mj_"
   },
   "source": [
    "Retrain the model on the optimal set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "6oCF0Y5FuQDp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            │        \u001b[38;5;34m80,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m28,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,993</span> (425.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m108,993\u001b[0m (425.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,993</span> (425.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m108,993\u001b[0m (425.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2109 - val_accuracy: 0.9353 - val_loss: 0.1885\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.1857 - val_accuracy: 0.9365 - val_loss: 0.1872\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.1873 - val_accuracy: 0.9373 - val_loss: 0.1873\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.1795 - val_accuracy: 0.9323 - val_loss: 0.2056\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9388 - loss: 0.1900 - val_accuracy: 0.9383 - val_loss: 0.1910\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.1901 - val_accuracy: 0.9381 - val_loss: 0.1915\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.1901 - val_accuracy: 0.9385 - val_loss: 0.1935\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.1855 - val_accuracy: 0.9365 - val_loss: 0.1985\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.1955 - val_accuracy: 0.9381 - val_loss: 0.1929\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 0.1851 - val_accuracy: 0.9395 - val_loss: 0.1969\n"
     ]
    }
   ],
   "source": [
    "# Use the 'create_nn' function to create a NN with the optimal values of 'filter_size' and 'pool_filter_size'\n",
    "# Note: Set the 'activation_function' parameter to 'best_activation_function' - This specifies the optimal value for the 'activation_function' parameter\n",
    "# Note: Set the 'hidden1_neurons' parameter to 'best_hidden1_neurons' - This specifies the optimal value for the 'hidden1_neurons' parameter\n",
    "nn2 = create_nn(activation_function='sigmoid', hidden1_neurons= 448)\n",
    "\n",
    "# Capture the training history of the model using the 'fit()' method\n",
    "# Note: Set the 'validation_data' parameter to (X_val, y_val)\n",
    "# Note: Use the default batch size or set it to 32\n",
    "# Note: Set the 'epochs' parameter to 10\n",
    "nn2.summary()\n",
    "print('\\n')\n",
    "nn2_history = nn2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "hist = pd.DataFrame(nn2_history.history)\n",
    "hist['epoch'] = nn2_history.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozvcqpmX3Twu"
   },
   "source": [
    "Plot the training and validation accuracies for different values of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "MXzdJR5suQAL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJYAAAGHCAYAAADiJdjqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACbl0lEQVR4nOzdd3hU5dPG8W8qhBZ67yBFqhRpKmBHwIJIUToCdhCQKgiIIiBFQVA6iALiD6xYEFFRRIpUEaT33iGQet4/5k2WkABJSHJS7s917ZWzT052Z0NIdmdn5vFyHMdBREREREREREQknrzdDkBERERERERERFInJZZERERERERERCRBlFgSEREREREREZEEUWJJREREREREREQSRIklERERERERERFJECWWREREREREREQkQZRYEhERERERERGRBFFiSUREREREREREEkSJJRERERERERERSRAllkRERFK4999/Hy8vLypWrOh2KJKIZs2ahZeXV6yX3r17uxrbp59+yvjx42P9nJeXF0OGDEnWeOJr2bJl1KhRg8yZM+Pl5cUXX3wR63l79+697r9BSnmcxYsXp0mTJm6HISIicl2+bgcgIiIiNzZjxgwA/vnnH/766y9q1arlckSSmGbOnEm5cuWirRUsWNClaMynn37Kli1b6NGjR4zP/fnnnxQuXDj5g4ojx3Fo0aIFZcqU4auvviJz5syULVv2hl/z8ssv8/TTT8dYT8mPU0REJKVQYklERCQFW7t2LRs3bqRx48Z8++23TJ8+PcUmloKCgsiUKZPbYaQ6FStWpEaNGm6HEWe1a9d2O4QbOnz4MKdPn+aJJ57gvvvui9PXFC1aNMU/LhERkZRKrXAiIiIp2PTp0wF45513qFu3LvPnzycoKCjGeYcOHaJr164UKVIEf39/ChYsSPPmzTl27FjUOWfPnqVXr16ULFmSDBkykDdvXh555BG2bdsGwC+//IKXlxe//PJLtNuObBeaNWtW1FqHDh3IkiULmzdv5sEHHyRr1qxRL+KXLl3KY489RuHChcmYMSOlS5emW7dunDx5Mkbc27Zto3Xr1uTLl48MGTJQtGhR2rVrR3BwMHv37sXX15cRI0bE+LrffvsNLy8vFi5ceN3v3ZUrV+jVqxdVq1YlMDCQnDlzUqdOHb788ssY5y5cuJBatWoRGBhIpkyZKFmyJJ06dbrubUf64IMPuOeee8ibNy+ZM2emUqVKjBo1itDQ0Jt+bVxcrx2rePHidOjQIep6ZFvd8uXLef7558mdOze5cuWiWbNmHD58OMbXf/rpp9SpU4csWbKQJUsWqlatGvWz1qBBA7799lv27dsXrS3sRjFt2bKFxx57jBw5cpAxY0aqVq3K7Nmzo50T+fM1b948Bg4cSMGCBcmWLRv3338/27dvj9P34/fff+e+++4ja9asZMqUibp16/Ltt99GfX7IkCFRVUZ9+/bFy8uL4sWLx+m2b6ZBgwZUrFiRFStWULt2bQICAihUqBCDBg0iPDw82rmnT5/mhRdeoFChQvj7+1OyZEkGDhxIcHBwtPMiIiKYMGECVatWJSAggOzZs1O7dm2++uqrGPf//fffU61aNQICAihXrlxUJaOIiIjbVLEkIiKSQl2+fJl58+ZRs2ZNKlasSKdOnXj22WdZuHAh7du3jzrv0KFD1KxZk9DQUAYMGEDlypU5deoUP/zwA2fOnCFfvnxcuHCBu+66i71799K3b19q1arFxYsX+e233zhy5EiMVqy4CAkJ4dFHH6Vbt27069ePsLAwAHbt2kWdOnV49tlnCQwMZO/evYwdO5a77rqLzZs34+fnB8DGjRu56667yJ07N8OGDeO2227jyJEjfPXVV4SEhFC8eHEeffRRPvzwQ/r06YOPj0/UfU+cOJGCBQvyxBNPXDe+4OBgTp8+Te/evSlUqBAhISH89NNPNGvWjJkzZ9KuXTvAWrtatmxJy5YtGTJkCBkzZmTfvn38/PPPN/0e7Nq1i6effpoSJUrg7+/Pxo0beeutt9i2bVucX/iHh4dHfe8i+fom7Cnas88+S+PGjfn00085cOAAr732Gm3atIn2WAYPHsybb75Js2bN6NWrF4GBgWzZsoV9+/YBMGnSJLp27cquXbtYvHjxTe9z+/bt1K1bl7x58/L++++TK1cu5s6dS4cOHTh27Bh9+vSJdv6AAQOoV68e06ZN4/z58/Tt25emTZvy77//Rvs3vtavv/7KAw88QOXKlZk+fToZMmRg0qRJNG3alHnz5tGyZUueffZZqlSpQrNmzaLa2zJkyHDTxxARERHj3wBi/jscPXqUVq1a0a9fP4YNG8a3337L8OHDOXPmDBMnTgQsodmwYUN27drF0KFDqVy5MitWrGDEiBFs2LAhWiKsQ4cOzJ07l86dOzNs2DD8/f35+++/2bt3b7T73bhxI7169aJfv37ky5ePadOm0blzZ0qXLs0999xz08cnIiKSpBwRERFJkebMmeMAzocffug4juNcuHDByZIli3P33XdHO69Tp06On5+fs3Xr1uve1rBhwxzAWbp06XXPWb58uQM4y5cvj7a+Z88eB3BmzpwZtda+fXsHcGbMmHHDxxAREeGEhoY6+/btcwDnyy+/jPrcvffe62TPnt05fvz4TWNavHhx1NqhQ4ccX19fZ+jQoTe872uFhYU5oaGhTufOnZ077rgjav3dd991AOfs2bPxur1rhYeHO6Ghoc6cOXMcHx8f5/Tp0zc8f+bMmQ4Q6yU0NNRxHMcBnDfeeCPG1xYrVsxp3759jNt64YUXop03atQoB3COHDniOI7j7N692/Hx8XGeeeaZG8bWuHFjp1ixYrF+7tqYWrVq5WTIkMHZv39/tPMaNWrkZMqUKer7Gvlv+cgjj0Q777PPPnMA588//7xhTLVr13by5s3rXLhwIWotLCzMqVixolO4cGEnIiLCcRzPz+vo0aNveHtXn3u9y4oVK6LOrV+/foyfYcdxnC5dujje3t7Ovn37HMdxnA8//NABnM8++yzaeSNHjnQA58cff3Qcx3F+++03B3AGDhx4wxiLFSvmZMyYMer2HcdxLl++7OTMmdPp1q3bTR+jiIhIUlMrnIiISAo1ffp0AgICaNWqFQBZsmThqaeeYsWKFezYsSPqvO+++46GDRtSvnz5697Wd999R5kyZbj//vsTNcYnn3wyxtrx48d57rnnKFKkCL6+vvj5+VGsWDEA/v33X8DmMf3666+0aNGCPHnyXPf2GzRoQJUqVfjggw+i1j788EO8vLzo2rXrTeNbuHAh9erVI0uWLFGxTJ8+PSoOgJo1awLQokULPvvsMw4dOhS3Bw+sX7+eRx99lFy5cuHj44Ofnx/t2rUjPDyc//77L063MWfOHNasWRPtktCKpUcffTTa9cqVKwNEVSMtXbqU8PBwXnzxxQTdfmx+/vln7rvvPooUKRJtvUOHDgQFBfHnn3/GK8bYXLp0ib/++ovmzZuTJUuWqHUfHx/atm3LwYMH49xOF5vu3bvH+DdYs2YNVatWjXZe1qxZY8T/9NNPExERwW+//QbY9yNz5sw0b9482nmRrYvLli0D7P8kEKd/i6pVq1K0aNGo6xkzZqRMmTI3/J6JiIgkFyWWREREUqCdO3fy22+/0bhxYxzH4ezZs5w9ezbqxerVbVYnTpy46e5VcTknvjJlykS2bNmirUVERPDggw+yaNEi+vTpw7Jly1i9ejWrVq0CrL0P4MyZM4SHh8cppldeeYVly5axfft2QkNDmTp1Ks2bNyd//vw3/LpFixbRokULChUqxNy5c/nzzz9Zs2YNnTp14sqVK1Hn3XPPPXzxxReEhYXRrl07ChcuTMWKFZk3b94Nb3///v3cfffdHDp0iPfee48VK1awZs2aqCRY5GO9mfLly1OjRo1ol4TKlStXtOuRbWCRsZw4cQJI3N3OTp06RYECBWKsR+5sd+rUqXjFGJszZ87gOE687ic+ChcuHOPfoEaNGtGSWAD58uWL8bWRP4eR93/q1Cny588fbS4VQN68efH19Y0678SJE/j4+Nz05xhifs/Avm9x/RkTERFJSpqxJCIikgLNmDEDx3H4/PPP+fzzz2N8fvbs2QwfPhwfHx/y5MnDwYMHb3h7cTknY8aMADEGDMc2dBuI8cIZbIjzxo0bmTVrVrQ5UDt37ox2Xs6cOfHx8blpTGAVIX379uWDDz6gdu3aHD16NE5VHnPnzqVEiRIsWLAgWqzXPj6Axx57jMcee4zg4GBWrVrFiBEjePrppylevDh16tSJ9fa/+OILLl26xKJFi6IqsgA2bNhw09jiKkOGDLHGm9AkSmR12MGDB2NUGCVUrly5OHLkSIz1yKHhuXPnvuX7yJEjB97e3kl+Pzdz9TD8SEePHgU8yZ9cuXLx119/4ThOtJ+748ePExYWFhVnnjx5CA8P5+jRo7EmzERERFILVSyJiIikMOHh4cyePZtSpUqxfPnyGJdevXpx5MiRqFaaRo0asXz58hu2AjVq1Ij//vvvhgOpI3fP2rRpU7T12Haoup7IF9LXDkz+6KOPol0PCAigfv36LFy48LqJq0gZM2aka9euzJ49m7Fjx1K1alXq1asXp1j8/f2jvbg/evRorLvCRcqQIQP169dn5MiRgLW63ej2I78mkuM4TJ069aaxxVXx4sVj/Hv8/PPPXLx4MUG39+CDD+Lj48PkyZNveF58qmHuu+8+fv755xi7z82ZM4dMmTJRu3btBMV6tcyZM1OrVi0WLVoULa6IiAjmzp1L4cKFKVOmzC3fz81cuHAhxv+HTz/9FG9v76gh2vfddx8XL17kiy++iHbenDlzoj4P9n8SuOm/hYiISEqniiUREZEU5rvvvuPw4cOMHDmSBg0axPh8xYoVmThxItOnT6dJkyYMGzaM7777jnvuuYcBAwZQqVIlzp49y/fff0/Pnj0pV64cPXr0YMGCBTz22GP069ePO++8k8uXL/Prr7/SpEkTGjZsSP78+bn//vsZMWIEOXLkoFixYixbtoxFixbFOfZy5cpRqlQp+vXrh+M45MyZk6+//pqlS5fGODdyp7hatWrRr18/SpcuzbFjx/jqq6/46KOPyJo1a9S5L7zwAqNGjWLdunVMmzYtTrE0adKERYsW8cILL9C8eXMOHDjAm2++SYECBaLNqBo8eDAHDx7kvvvuo3Dhwpw9e5b33nsPPz8/6tevf93bf+CBB/D396d169b06dOHK1euMHnyZM6cORPn79fNtG3blkGDBjF48GDq16/P1q1bmThxIoGBgQm6veLFizNgwADefPNNLl++TOvWrQkMDGTr1q2cPHmSoUOHAlCpUiUWLVrE5MmTqV69Ot7e3tdt0XvjjTf45ptvaNiwIYMHDyZnzpx88sknfPvtt4waNSrBsV5rxIgRPPDAAzRs2JDevXvj7+/PpEmT2LJlC/PmzYu1gi6u9u/fH9WuebU8efJQqlSpqOu5cuXi+eefZ//+/ZQpU4YlS5YwdepUnn/++agZSO3ateODDz6gffv27N27l0qVKvH777/z9ttv88gjj0TNObv77rtp27Ytw4cP59ixYzRp0oQMGTKwfv16MmXKxMsvv5zgxyMiIpKs3JwcLiIiIjE9/vjjjr+//w13S2vVqpXj6+vrHD161HEcxzlw4IDTqVMnJ3/+/I6fn59TsGBBp0WLFs6xY8eivubMmTNO9+7dnaJFizp+fn5O3rx5ncaNGzvbtm2LOufIkSNO8+bNnZw5czqBgYFOmzZtnLVr18a6K1zmzJljjW3r1q3OAw884GTNmtXJkSOH89RTTzn79++PdYezrVu3Ok899ZSTK1cux9/f3ylatKjToUMH58qVKzFut0GDBk7OnDmdoKCguHwbHcdxnHfeeccpXry4kyFDBqd8+fLO1KlTnTfeeMO5+inQN9984zRq1MgpVKiQ4+/v7+TNm9d55JFHou0Idj1ff/21U6VKFSdjxoxOoUKFnNdee8357rvvYt1d71qRO7mtWbPmuucEBwc7ffr0cYoUKeIEBAQ49evXdzZs2HDdXeGuva3r7fQ3Z84cp2bNmk7GjBmdLFmyOHfccUe0f9/Tp087zZs3d7Jnz+54eXlF+37F9u+4efNmp2nTpk5gYKDj7+/vVKlSJdrtXR3LwoULo63Htuvg9axYscK59957ncyZMzsBAQFO7dq1na+//jrW20uMXeGu3j2vfv36ToUKFZxffvnFqVGjhpMhQwanQIECzoABA6J28Yt06tQp57nnnnMKFCjg+Pr6OsWKFXP69+8f4+c6PDzcGTdunFOxYkXH39/fCQwMdOrUqRPtMRUrVsxp3LhxjNjr16/v1K9f/6aPUUREJKl5OY7jJHMuS0RERCRejh8/TrFixXj55ZcZNWqU2+FIOtSgQQNOnjzJli1b3A5FREQkRVErnIiIiKRYBw8eZPfu3YwePRpvb2+6d+/udkgiIiIichUN7xYREZEUa9q0aTRo0IB//vmHTz75hEKFCrkdkoiIiIhcRa1wIiIiIiIiIiKSIKpYEhERERERERGRBFFiSUREREREREREEkSJJRERERERERERSRDtCpdAERERHD58mKxZs+Ll5eV2OCIiIiIiIiIiicJxHC5cuEDBggXx9r5xTZISSwl0+PBhihQp4nYYIiIiIiIiIiJJ4sCBAxQuXPiG5yixlEBZs2YF7JucLVs2l6MREREREREREUkc58+fp0iRIlG5jxtRYimBItvfsmXLpsSSiIiIiIiIiKQ5cRn9o+HdIiIiIiIiIiKSIEosiYiIiIiIiIhIgiixJCIiIiIiIiIiCaIZS0nIcRzCwsIIDw93OxRJBD4+Pvj6+sapx1REREREREQkPVBiKYmEhIRw5MgRgoKC3A5FElGmTJkoUKAA/v7+bociIiIiIiIi4jollpJAREQEe/bswcfHh4IFC+Lv768ql1TOcRxCQkI4ceIEe/bs4bbbbsPbW52kIiIiIiIikr4psZQEQkJCiIiIoEiRImTKlMntcCSRBAQE4Ofnx759+wgJCSFjxoxuhyQiIiIiIiLiKpVcJCFVtKQ9+jcVERERERER8dCrZBERERERERERSRC1womIiIiIiIiIJJTjwLlzcPKkXU6csPWmTd2NK5kosSRJrkGDBlStWpXx48fH6fy9e/dSokQJ1q9fT9WqVZM0NhEREREREZForlyx5FBkoigyWXSj62Fh0W+jVCklliT9udnOde3bt2fWrFnxvt1Fixbh5+cX5/OLFCnCkSNHyJ07d7zvS0RERERERCRKeDicPh235FDk9UuXEnZfmTNDnjyQOzcUL56oDyMlU2JJohw5ciTqeMGCBQwePJjt27dHrQUEBEQ7PzQ0NE4Jo5w5c8YrDh8fH/Lnzx+vrxEREREREZE0znHgwoX4VRKdPm1fF1++vpYgyp3bkyyK7Xrkca5ccM1r5vRCiaXk4jgQFJT895spE9ykEinS1cmcwMBAvLy8otb27t1LgQIFWLBgAZMmTWLVqlVMnjyZRx99lJdeeokVK1Zw+vRpSpUqxYABA2jdunXUbV3bCle8eHG6du3Kzp07WbhwITly5OD111+na9euUfd1dSvcL7/8QsOGDfnpp5/o27cvW7dupWrVqsycOZOyZctG3c/w4cN5//33uXz5Mi1btiR37tx8//33bNiw4Ra/iSIiIiIiIpLogoPh1Kn4tZ2FhCTsvnLkuH5yKLZkUbZscX4tnd4psZRcgoIgS5bkv9+LF60cL5H07duXMWPGMHPmTDJkyMCVK1eoXr06ffv2JVu2bHz77be0bduWkiVLUqtWrevezpgxY3jzzTcZMGAAn3/+Oc8//zz33HMP5cqVu+7XDBw4kDFjxpAnTx6ee+45OnXqxB9//AHAJ598wltvvcWkSZOoV68e8+fPZ8yYMZQoUSLRHruIiIiIiIhcR0QEnDkT90qiEyes+ighMma05M+NkkNXX8+ZE+IxnkXiR4kliZcePXrQrFmzaGu9e/eOOn755Zf5/vvvWbhw4Q0TS4888ggvvPACYMmqcePG8csvv9wwsfTWW29Rv359APr160fjxo25cuUKGTNmZMKECXTu3JmOHTsCMHjwYH788UcuXryY4McqIiIiIiKSLkV23MSnkujUKUsuxZe3d/wqiXLnts4cSTGUWEoumTJZ9ZAb95uIatSoEe16eHg477zzDgsWLODQoUMEBwcTHBxM5ptUSVWuXDnqOLLl7vjx43H+mgIFCgBw/PhxihYtyvbt26MSVZHuvPNOfv755zg9LhERERERkTQrNNQSPzdLDl19fOVKwu4rW7a4VxLlzg3Zs1tySVItJZaSi5dXorakueXahNGYMWMYN24c48ePp1KlSmTOnJkePXoQcpO+12uHfnt5eRFxk+z21V8TuYPd1V9z7a52TkIGtImIiIiIiKRkjgNnz8a9kujECTh3LmH35e/vSQLFdYC1v3+iPlxJ+ZRYkluyYsUKHnvsMdq0aQNYomfHjh2UL18+WeMoW7Ysq1evpm3btlFra9euTdYYREREREREYggJsbay2C6XLt38cxcuxEwchYfHPw4vL0v8xKftLHNmDbCWm1JiSW5J6dKl+d///sfKlSvJkSMHY8eO5ejRo8meWHr55Zfp0qULNWrUoG7duixYsIBNmzZRsmTJZI1DRERERERSCcexXcnik+SJ7+eCgiAsLGniz5Ll5smhq6/nyAE+PkkTi6RrSizJLRk0aBB79uzhoYceIlOmTHTt2pXHH3+ccwkttUygZ555ht27d9O7d2+uXLlCixYt6NChA6tXr07WOEQkjYiIgOXLYfNmKFgQihWDokUhXz7NABAREUkOERFw+XLCEjnxSQIl5/gMb2+rAMqUKebleuuZMlkC6dpkUe7ctjOaSArg5WgQTYKcP3+ewMBAzp07R7Zs2aJ97sqVK+zZs4cSJUqQUf/ZXfPAAw+QP39+Pv7440S7Tf3biqRxu3bBrFkwZw7s3x/z8/7+UKSIJZkik02RHyMv+t0gIiJpXXh44lTz3Ohzly8n72Py84tbkudGn7vZ5/391VYmqcaNch7XUsWSpAlBQUF8+OGHPPTQQ/j4+DBv3jx++uknli5d6nZoIpLSXbgACxdaQmnFCs96YCA0bGgzDfbvh0OHbEbCrl12uZ68eaMnm65NQOXKpSeVIiKS/MLC4Lff7O/arSaAbrJRT6LLmDHxkzxXfy4gwBJLIpIgSixJmuDl5cWSJUsYPnw4wcHBlC1blv/973/cf//9bocmIilRRAT8+qslkz7/3J4kg5WoP/ggdOgAjz0WvfooLMySS/v3w7599vHq43377In38eN2WbMm9vvOlOn6SaeiRaFwYT25FRGRxBMcDLNnw6hRN35jJKGSusonIEBzgURSOCWWJE0ICAjgp59+cjsMEUnpdu+2NrfZs2HvXs962bKWTGrbFgoViv1rfX0tAVSsGNx9d8zPOw6cOXP9pNP+/XD0qCWxtm2zS2y8vKLPdYotARUYeKvfCRERSesuXoSPPoKxY+HwYVvLmRMqV06cKp9MmewNGFXhiqR7SiyJiEjadvGiVSXNmmVVSpGyZYNWrSyhVLv2rT8x9vKyJ+w5c8Idd8R+TnAwHDhw/aqn/fvtnEOH7LJyZey3ky1bzGTT1YmoAgX07q6ISHp16hRMmGCX06dtrVAheO01ePZZSw6JiCQiJZZERCTtiYiweUmzZtn8pEuXbN3LC+6/Hzp2hMcft/L65JQhA5QubZfYRETY7IsbVT2dOgXnz9uOdZs3x347vr7WUne9qqciRfTCQkQkrTl82KqTPvzQ83evdGno1w/atLG/QSIiSUCJJRERSTv27vW0uu3e7Vm/7TZPq1uRIm5Fd3Pe3pAvn13uvDP2cy5dir3SKfL44EGbB7V3b/R2v2vlyhV7tVPkcd68am8QEUkNdu2y+UmzZnmGalepAgMGwJNPqoJVRJKcEksiIpK6XboEixbBzJmwfLlnPWtWaNnSEkp166adJEnmzFC+vF1iEx4OR45cv+pp3z7bCe/UKbv8/Xfst5Mhw/WTTsWKWUWU3v0WEXHP5s0wYgQsWGAVrwB33WUJpYcfTjt/90QkxVNiSUREUh/HgT/+sGTSZ5/ZHCWwJ9H33mvJpGbNbLBoeuPjY0mfwoWhXr3Yzzl3LmaL3dXHhw/brKcdO+xyPfnz37jqKUcOvbAREUlsf/5pCaWvv/asNWoE/fvHvrmEiEgSU2JJRERSj/37rdVt1qzoWyaXKuVpdStWzK3oUo/AQNsVqHLl2D8fEmLDw2Ob8RT58fJl2+Xu6FH466/YbydLlhtXPRUsaPOgRETkxhwHli61hNIvv9ialxc89ZTNULrephEiIslAz+YkUTVo0ICqVasyfvx4AIoXL06PHj3o0aPHdb/Gy8uLxYsX8/jjj9/SfSfW7YhIChMUBIsXWzJp2TJ7cg2WtGjRwhJKd92lypjE5O8PJUrYJTaOY210N6p6On7cKsm2brVLbLy9baeiG1U9Zc2adI9TRCSli4iAL76At9+Gdetszc8P2rWDPn2gTBlXwxMRASWW5CpNmzbl8uXL/PTTTzE+9+eff1K3bl3WrVtHtWrV4nyba9asIXMi7zw0ZMgQvvjiCzZs2BBt/ciRI+TIkSNR70tEXOI4Vuo/a5bNjjh/3vO5hg09rW5ZsrgVYfrm5QW5c9ulevXYz7l8GQ4cuH7V04EDEBpqHw8cuP595cgRe7VT5Fr+/JagEhFJS0JD4dNP4Z13YNs2WwsIgK5doVevlL0RhYikO0osSZTOnTvTrFkz9u3bR7FrWklmzJhB1apV45VUAsiTJ09ihnhD+fPnT7b7EpEkcvCgp9Xt6tk+JUpA+/Z2KV7cregkPgIC7J30672bHhEBx47duOrpzBnPZePG2G/Hz89eYF2ddCpXDqpVs90AlXQSkdTk8mWYPh1Gj7bfgwDZs8NLL8Err0AyPrcWEYkrJZaSieNYN0dyy5Qp7t0hTZo0IW/evMyaNYs33ngjaj0oKIgFCxbQq1cvWrduzYoVKzh9+jSlSpViwIABtG7d+rq3eW0r3I4dO+jcuTOrV6+mZMmSvPfeezG+pm/fvixevJiDBw+SP39+nnnmGQYPHoyfnx+zZs1i6NChgLW+AcycOZMOHTrEaIXbvHkz3bt3588//yRTpkw8+eSTjB07liz/X+HQoUMHzp49y1133cWYMWMICQmhVatWjB8/Hj8/v7h900Tk1l2+bGX+s2bZ/IjIVrdMmWx2RMeONoxUCYK0xdsbChSwS+3asZ9z4ULsO9tFfjx0yN7V373bLtfKmtXmjlSrZpVV1atboktbb4tISnPuHEyaBOPHWysxQL580LMnPPccZMvmangiIjeixFIyCQpyp2Pj4kXbmToufH19adeuHbNmzWLw4MFRiZuFCxcSEhLCs88+y7x58+jbty/ZsmXj22+/pW3btpQsWZJatWrd9PYjIiJo1qwZuXPnZtWqVZw/fz7W2UtZs2Zl1qxZFCxYkM2bN9OlSxeyZs1Knz59aNmyJVu2bOH777+PatkLDAyMcRtBQUE8/PDD1K5dmzVr1nD8+HGeffZZXnrpJWbNmhV13vLlyylQoADLly9n586dtGzZkqpVq9KlS5e4fdNEJGEcxwY+z5oF8+fbE+pI9etbq9uTT2q+TnqXNStUqGCX2ISF2Q52V1c77d0LmzZZhdOFC/Dbb3aJlDkzVK1qSabIhFO5choiLiLuOH7ckkkffOBp+y5e3OYndehg1Z8iIimcnkVJNJ06dWL06NH88ssvNGzYELA2uGbNmlGoUCF69+4dde7LL7/M999/z8KFC+OUWPrpp5/4999/2bt3L4ULFwbg7bffplGjRtHOe/3116OOixcvTq9evViwYAF9+vQhICCALFmy4Ovre8PWt08++YTLly8zZ86cqBlPEydOpGnTpowcOZJ8+fIBkCNHDiZOnIiPjw/lypWjcePGLFu2TIklkaRy6BDMnWsJpciZEWDtS+3b2zDSUqVcC09SGV9fz6yla4WF2c/YunV2+ftvWL8eLl2CP/6wS6SAAKhSxVPVVK0a3H67tdmJiCSFffvg3Xdh2jS4csXWbr/ddnhr1Uq/f0QkVXG9r2DSpEmUKFGCjBkzUr16dVasWHHD8z/44APKly9PQEAAZcuWZc6cOdc9d/78+Xh5ecW6S1h87/dWZcpk1UPJfcmUKX5xlitXjrp16zJjxgwAdu3axYoVK+jUqRPh4eG89dZbVK5cmVy5cpElSxZ+/PFH9kf2f9/Ev//+S9GiRaOSSgB16tSJcd7nn3/OXXfdRf78+cmSJQuDBg2K831cfV9VqlSJNji8Xr16REREsH379qi1ChUq4HNVS0SBAgU4Hll+LCKJ48oVG8DdqJElAPr1sxf8AQHQtq3t9LZ7NwwdqqSSJB5fX6hY0RKW778Pv/9u1QD//AMffww9eliLZZYs1o65apVVDHTqZBVNWbNCrVrw/PP2wm/9eggJcftRiUhqt22btXiXLg0TJ9rfyJo1bffTzZvt76KSSiKSyrhasbRgwQJ69OjBpEmTqFevHh999BGNGjVi69atFI3l3cfJkyfTv39/pk6dSs2aNVm9ejVdunQhR44cNG3aNNq5+/bto3fv3tx99923fL+Jwcsr7i1pbuvcuTMvvfQSH3zwATNnzqRYsWLcd999jB49mnHjxjF+/HgqVapE5syZ6dGjByFxfKLtRM5NuYrXNQOgVq1aRatWrRg6dCgPPfQQgYGBzJ8/nzFjxsTrMTiOE+O2Y7vPa2cpeXl5EREREa/7EpFYOA6sWWOVSfPmwdmzns/ddZc9qW7eXDMjJHn5+FhFwO23Q5s2thYRYYPiI6uaIj+ePw+rV9slkr8/VKoUvY2uUiXIkMGdxyMiqce6dTBiBCxa5JkleO+9MGCAfYzrUFQRkRTI1cTS2LFj6dy5M88++ywA48eP54cffmDy5MmMGDEixvkff/wx3bp1o2XLlgCULFmSVatWMXLkyGiJpfDwcJ555hmGDh3KihUrOHv1C5oE3G9606JFC7p3786nn37K7Nmz6dKlC15eXqxYsYLHHnuMNv//ZDwiIoIdO3ZQvnz5ON3u7bffzv79+zl8+DAFCxYE4M8//4x2zh9//EGxYsUYOHBg1Nq+ffuinePv7094ePhN72v27NlcunQpqmrpjz/+wNvbmzLX26FIRG7dkSOeVretWz3rRYp4dnUrXdq18ERi8PaGsmXt8vTTthYRYVV0V7fRrVtnCdLItUiRlVGRbXSRySbNRRERx7EZb2+/DT/+6Fl/7DHo39+qIkVE0gDXEkshISGsW7eOfv36RVt/8MEHWblyZaxfExwcTMaMGaOtBQQEsHr1akJDQ6OqT4YNG0aePHno3LlzjBa3hNxv5H0HBwdHXT8fOVwvDcqSJQstW7ZkwIABnDt3jg4dOgBQunRp/ve//7Fy5Upy5MjB2LFjOXr0aJwTS/fffz9ly5alXbt2jBkzhvPnz0dLIEXex/79+5k/fz41a9bk22+/ZfHixdHOKV68OHv27GHDhg0ULlyYrFmzkuGad4ufeeYZ3njjDdq3b8+QIUM4ceIEL7/8Mm3bto2aryQiiSQ4GL7+GmbOhO+/txflABkz2gDuDh2gYUPtxCWph7e3JUBLl4b/fzMLx4E9ezxJpsjL6dOwYYNdpk+3c318bOD41ZVNVarEvz9dRFInx4Fvv7UKpcjXFz4+0Lo19O1ryWgRkTTEtRlLJ0+eJDw8PMaL/Hz58nH06NFYv+ahhx5i2rRprFu3DsdxWLt2LTNmzCA0NJSTJ08CVpUyffp0pk6dmmj3CzBixAgCAwOjLkWKFInPw011OnfuzJkzZ7j//vuj2gMHDRpEtWrVeOihh2jQoAH58+ePdX7V9Xh7e7N48WKCg4O58847efbZZ3nrrbeinfPYY4/x6quv8tJLL1G1alVWrlzJoEGDop3z5JNP8vDDD9OwYUPy5MnDvHnzYtxXpkyZ+OGHHzh9+jQ1a9akefPm3HfffUycODH+3wwRiclx7EX1Sy/ZdvFPPQVLllhSqW5dmDIFjh616qX771dSSVI/Ly8oWdJaOEeMsOqDkydtF7r//Q8GDoSHH4Y8eSA83HammzkTXn7Z/k9kzeqZ+fTeezbz6eJFtx+ViCSmsDBr/65aFZo2taRShgw2q23HDpvvpqSSiKRBXk5sg2+SweHDhylUqBArV66MNsD5rbfe4uOPP2bb1bsF/b/Lly/z4osv8vHHH+M4Dvny5aNNmzaMGjWKY8eOERAQQOXKlZk0aVLUTmMdOnTg7NmzfPHFFwm+X4i9YqlIkSKcO3eObNfMCLly5Qp79uyJGg4uaYf+bSXdO3oUPvnEWt22bPGsFypkO7p16ABqN5X0zHFs98Nr2+hie/PKywvKlfNUNVWvbi9INXtMJHUJDoY5c2DkSNi1y9ayZIEXXrCNAgoUcDU8EZGEOH/+PIGBgbHmPK7lWitc7ty58fHxiVEldPz48eu2KgUEBDBjxgw++ugjjh07RoECBZgyZQpZs2Yld+7cbNq0ib1790abtxQ5iNnX15ft27dTpEiReN8vQIYMGWK0W4mIpAshIfDNN5ZMWrLEqjHA3oV94gkbxH3ffapKEgFLFhUubJfHHvOsHz4cs43u8GH491+7fPKJ59wyZaK30d1xB2TPnuwPRURu4uJFq9AdM8b+PwPkygXdu1tFb44c7sYnIpJMXEss+fv7U716dZYuXcoTTzwRtb506VIeu/qJWCz8/PyitqyfP38+TZo0wdvbm3LlyrF58+Zo577++utcuHCB9957jyJFitzS/YqIpBuOYzNjZs2yF7ynTnk+V7u2VSa1bKkXuyJxVbCgXZo08awdPWrJpqsTTgcOwH//2eXqVu9SpTxVTdWq2SVnzuR/HCJis9UmTID337djsMrd3r2hS5fUsxW0iEgicXVXuJ49e9K2bVtq1KhBnTp1mDJlCvv37+e5554DoH///hw6dIg5c+YA8N9//7F69Wpq1arFmTNnGDt2LFu2bGH27NkAZMyYkYrX9C1n//8XPVev3+x+RUTSrePHPa1umzZ51gsUsFa39u0hjgP7ReQm8ueHRx6xS6QTJzyJpsiPe/dae82uXfDZZ55zS5SI3kZXrRrkzp3sD0Mk3Th8GMaOhQ8/hEuXbK10aejXD9q0sUpeEZF0yNXEUsuWLTl16hTDhg3jyJEjVKxYkSVLllCsWDEAjhw5wv79+6PODw8PZ8yYMWzfvh0/Pz8aNmzIypUrKV68eKLer4hIuhIaarvXzJplH8PCbN3fHx5/3KqTHnjAtlUXkaSVJw889JBdIp06FbOyafdu26Vuzx4bHh6paNHobXTVq0PevMn/OETSkl27YNQo+zsZEmJrVapA//420F+t4CKSzrk2vDu1u9Egq8gBz8WLFycgIMClCCUpXL58mb1792p4t6QNGzd6Wt1OnPCs33mnp9VNrTYiKdOZM7B+ffTKph07Yj+3UKHoVU3Vq2uYsEhcbN5su0AuWGC7ngLUqwcDBkCjRjZTTUQkjUoVw7vTMj8/PwCCgoKUWEpjgoKCAM+/sUiqc/IkfPqpbYO+YYNnPX9+aNvWWt0qVHAtPBGJoxw54N577RLp3Dn7f331jnTbt9sudYcOwVdfec4tUCBmG12hQnqhLAKwahW8/TZ8/bVn7eGHLaF0993uxSUikkKpYimBbpa9O3LkCGfPniVv3rxkypQJLz1RS9UcxyEoKIjjx4+TPXt2CuidXklNQkPh++8tmfTNN3YdrNXt0UetOumhh9TqJpIWXbhgyaar2+i2bfNUX1wtb96YbXRFiijZJOmD48BPP1lC6ZdfbM3Ly1rd+ve33RlFRNKR+FQsKbGUQDf7JjuOw9GjRzl79mzyBydJJnv27OTPn1+JQkkdNm+2Vre5c20od6Tq1S2Z1Lq1bYssIunLpUvWCnt1G93WrRAeHvPc3Lk9iabIj8WLK9kkaUdEBHzxhSWU1q2zNV9f27CiTx8oW9bV8ERE3KLEUjKI6zc5PDyc0MjqAEnV/Pz88NFwRknpTp2yLcpnzfI8QQarRIhsdatUybXwRCSFunzZdoK8uo1uyxbPMP+r5cgRvaqpenUoWVLJJkldQkOtNXzkSPj3X1sLCICuXaFXL6vWExFJx5RYSgbx+SaLiCSpsDD44QdrdfvqK0+rm58fNG1q1UkPP2zXRUTi6soVq3y8uo1u82bP75irBQbGrGwqXRq8vZM/bpEbuXwZpk+H0aMhcvfpwEB4+WV45RXbmVFERJRYSg5KLImI6/75x9PqdvSoZ/2OOyyZ9PTT1sYiIpJYQkKskunqyqZNmyA4OOa5WbPa76OrB4SXKaOt2cUd587B5MkwbpynPTxfPujZE557DvR8XkQkGiWWkoESSyLiijNnPK1ua9Z41nPnhjZtLKFUpYpb0YlIehQaaonuyMqmv/+2geFXrsQ8N3NmSzZd3UpXtqw2D5Ckc/w4vPceTJwI58/bWvHi8Npr0LGjtb+JiEgMSiwlAyWWRCTZhIXB0qWWTPriC6sYAHsh1rixPTFu1Mh2eRMRSQnCwmxuzdVtdBs2QFBQzHMDAqBqVahc2XOpVMnak0QSav9+ePddmDbN2t8Aype3Hd5atVJ7uIjITSixlAyUWBKRJPfvvzB7Nnz8MRw+7FmvXNmSSU8/bUO5RURSg/Bw2L49ehvd+vVw8WLs5xctagmmq5NNZcooISA3tm2bDeSeO9czfL5mTRgwAB59VHO/RETiSImlZKDEkogkibNnYcECG8T911+e9Vy54JlnrNWtalXtviQiaUNEBOzYYUmmzZttXtOmTXDgQOzn+/tb1cnVyabKlSF/fv1eTO/WrYMRI2DRIoh8eXPvvVahdN99+vkQkWRz7pxtOunlZSPcUisllpKBEksikmjCw+Gnn6zVbfFizxBcHx945BFLJjVpolY3EUk/zp61RNPVyabNm69f3ZQrV8xkU4UKkClTsoYtycxx4Lff4O234ccfPeuPPWYJpVq13ItNRNIVx4FVq2DqVHuPOCjI9gc4cCD1FtoqsZQMlFgSkVu2fbu1us2ZA4cOedYrVLBWtzZt7C+SiIhYddO+fTGTTf/9Z5+7lpcXlC4dPdlUqRKULKl2qNTOcWDJEksorVxpaz4+NjupXz+oWNHd+EQk3Th92jpvp0yxfSwilS8PXbtCt26pd48AJZaSgRJLIpIg587BZ59Zq9uff3rWc+a0mUkdOthuSSrZFxGJm8uXbSbd1cmmTZs8W8pfK3NmSzxcnWyqVMmqniRlCw+HhQut5W3TJlvLkMHejHntNUsaiogkMceBFSusOmnhQk+zQcaM0LIldOkCdeum/qfzSiwlAyWWRCTOHAd+/tmSSYsWeXan8fa23dw6dICmTe3JsYiIJI5jxzxJpsiP//zjeQVwrUKFoiebKleGcuXUhpwSBAdbde/IkbBrl61lyQLPPw+vvgoFCrgbn4ikCydOWLPBtGnWeBCpcmWrTnrmGcie3bXwEp0SS8lAiSURuSnHgaVLYdAgWL3as16+vKfVTU+GRUSST1gY7NwZPdm0eTPs2RP7+b6+lly6OtlUubIloVL7W9GpwcWL1l8yZoxnd9RcuaB7d3jpJciRw934RCTNi4iA5cvtV9HixRAaauuZM0Pr1ladVLNm2vyToMRSMlBiSURu6Lff4PXXrU4WbIBs+/aWUKpRI23+9RERSa3On4ctW2JWOJ07F/v52bPHTDZVrGhVNHLrTp+GCRPg/fftGCyZ17u3vYrLnNnd+EQkzTt61JoNpk2D3bs96zVq2K+h1q0ha1b34ksOSiwlAyWWRCRWf/1lFUpLl9r1DBnghRegb18N4hYRSU0cx7bzuTbZtG2bzfqJTcmS0ZNNlSrZAHEfn+SNPbU6cgTGjoUPP/TsAFi6tA3kbtNGLeMikqTCw22DyalT4euvrcgVIFs2a3Pr0gXuuMPdGJOTEkvJQIklEYlm/XoYPBi++cau+/nBs8/CwIH2LquIiKQNwcGWXLo62bRpkyVFYpMxo+32eW2FU548yRt3SrZ7N4waZeUBISG2VqUK9O8PzZsrMSciSergQZgxA6ZPh/37Pet16tjspKeeSp+FkkosJQMllkQEgK1b4Y034PPP7bqPj7W8DRoExYu7GpqIiCSjkyct0XR1sumffyAoKPbz8+WLmWwqX94SUenF5s3wzjswf74NMgGoVw8GDLDNLdQ2LiJJJCwMliyx6qQlSzy/gnLkgLZtrTqpYkV3Y3SbEkvJQIklkXRuxw4YOhQ+/dTaJby8rNn6jTegTBm3oxMRkZQgPNyqca5ONm3ebDubxfYU3MfH/oZc205XrFjaSrKsWgVvv229JpEeftgSSnff7V5cIpLm7d1rlUkzZnj2BAC45x6rTmrWDAICXAsvRVFiKRkosSSSTu3bB2++CbNmeWZsPPkkDBmitzVERCRuLl2yaqark02bNnkGVV8rWzZLMEUmnCKPAwOTN+5b4Tjw00+WUPrlF1vz8rJWt379oFo1V8MTkbQrNBS++sqqk3780ZPXz50bOnSw6RVly7oaYoqkxFIyUGJJJJ05fBjeesv+IkXuM9q4MQwbpifDIiJy6xzH5jRdm2z691/P351rFSsWPdlUubJVPPn6Jm/sNxIRAV98YQmldetszdcX2rWDPn30ak5EkszOnbar28yZcPy4Z/3++63V7bHHtCfAjSixlAyUWBJJJ44ft/kPkyfDlSu2dv/9llCqU8fd2EREJO0LDYXt26MnmzZvth3rYuPvD7ffHj3ZVKkS5M+fvO10oaEwb579Df33X1sLCLBXc716QdGiyReLiKQbwcGweDFMmQLLl3vW8+eHjh2hc2coVcq9+FITJZaSgRJLImnc6dPw7rvw/vvWsgBw113WBteggauhiYiIcOZM9GHhkccXL8Z+fu7cMZNNFSpApkyJG9flyza8ZPRoax8Ha9l76SXo3l274YlIkvj3X2ssmDMHTp2yNS8vG9/WpQs0aWKbNkvcKbGUDJRYEkmjzp+H8eNhzBg7BqhZ0xJKDz6YtoaniohI2hIRYZNpr042bdpkG05Ebnl0NS8vuO22mO10JUqAt3f87vvcOavuHTfO03OSNy/07AnPP29zokREEtHly7BwoSWUfv/ds164MHTqZJdixdyLL7VTYikZKLEkksZcugQTJ8KoUZ7hqZUrW0KpaVMllEREJPW6fBm2bo2ebNq0CU6ciP38zJltQ4qrd6arVAly5ox57vHj8N578MEHllwCeyXXp4/1nWh7JRFJZJs2WTJp7lw4e9bWfHxs/GnXrlal5OPjaohpghJLyUCJJZE04soV+OgjGyoa+Q5ruXIwdKjtVBPfd2xFRERSi2PHYiabtm61ISWxKVQoeqJpzRp7dXf5sn2+fHno3x9atVLPiYgkqosXYcEC+5Xz11+e9WLFrNWtY0coWNC9+NIiJZaSgRJLIqlcSIjNgBg+HA4dsrWSJWHIEHj6ab3NISIi6VNYmLXOXZ1s2rzZWuyup0YNGDgQHn1Ub8iISKJat86SSZ9+Chcu2Jqvr+3o1rWr7amjXztJIz45jxS0F6mISDIIC7O62aFDPU+SixSBQYOgQwe9wyoiIumbr69VHpUvDy1aeNbPn4ctW6InmwIDoUcPuO8+tYyLSKI5f94SSVOnwt9/e9ZLl7bqpPbtIV8+9+KTmJRYEpH0ISLC6meHDIH//rO1/PntHdYuXSBDBlfDExERSdGyZYO6de0iIpLIHMda3KZOhfnzISjI1v394ckn7el6gwbKYadUSiyJSNrmOPDFFzB4sL3TCrblcr9+tktNYm+zLCIiIiIicXLmjDUTTJnieaoOVjTZpQu0bWtP3SVlU2JJRNImx4HvvrMWt8ga2uzZoXdveOUVyJrV1fBERERERNIjx4Hff7dk0uef2146ABkzWgduly5Qr56qk1ITJZZEJO35+Wd4/XX480+7niULvPoq9OxpySUREREREUlWJ0/C7NkwbRps2+ZZr1zZkknPPAM5crgXnyScEksiknb88YcllH75xa4HBMBLL0GfPqqhFRERERFJZhERsHy5zU5avNg2ZgbInBlatbKd3WrWVHVSaqfEkoikfmvXWsvb99/bdX9/6NYN+veHAgXcjU1EREREJJ05ehRmzbLqpF27POvVq1syqVUr2xNA0gYllkQk9dq0yYZyf/mlXff1hU6drGqpSBF3YxMRERERSUfCw2HpUqtO+uorCAuz9axZrc2tSxeoVs3dGCVpKLEkIqnPtm0wZAgsWGDXvb2hTRtLMpUq5WpoIiIiIiLpyaFDMGMGTJ8O+/Z51uvUsWRSixbW+iZplxJLIpJ67N4NQ4fanqQREbbWsqUlmcqVczU0EREREZH0IizMNmCeOhW+/dbz1Dx7dmjXzhJKFSu6GqIkIyWWRCTlO3AAhg+3t0Iia2ofewyGDbNtJEREREREJMnt22eVSTNmWKVSpHvusWTSk0/a/jmSviixJCIp15EjMGIEfPSRZwuJhx+2hFLNmu7GJiIiko5duQJ+fuDj43YkIpLUQkPh66+tOumHH8BxbD13bmjfHp59Vs0D6Z0SSyKS8pw8CaNGwcSJcPmyrdWvb1VLd93lbmwiIiLpxLlztpvTrl2wc2f0jwcPQp488NZbtm+GEkwiac+uXbar28yZcOyYZ/2++6w66fHHIUMG18KTFESJJRFJOc6ehTFjYPx4uHjR1urUgTffhHvvBS8vN6MTERFJUxwHTpyIPXG0c6e9z3MjJ07YtuFTpth7QbVqJU/cIpJ0goNh8WKrTvr5Z896vnzQsaNVJ2mvHLmWEksi4r4LF+D99+Hddy25BHDHHVah1KiREkoiIiIJFBFh1UWxJY927bI/wTeSJ4+9iCxdOvrH4sVtc9Y33oC1a6F2batcGjEC8uZNlocmIolo2zZLJs2eDadO2ZqXFzz0kCWQmzSx9leR2Hg5TmSHpMTH+fPnCQwM5Ny5c2TLls3tcERSp6AgmDQJRo70vC1aoYJVKD3+uBJKIiIicRASYgN1Y6s62rPHKhBupEiR6Emjq49v9jT36FHo189ejAIEBtqf8eefB1+9hS2Sol2+DJ9/bgmlFSs864UKQefOliwuVsy9+MRd8cl5KLGUQEosidyC4GD7C/bWW/aMFOC222DoUGjRQoMaRERErnHpEuzeHXvl0b59nq2+Y+PraxVG11YdlS4NJUpAxoy3Ht/KlfDSS7B+vV2vVMna4+6559ZvW0QS1+bN9lT84489zQLe3tC4sVUnPfywEsOixFKyUGJJJAFCQ2HWLHsr88ABWyte3Oro27TRXzAREUnXzpyJvepo1y7bKPVGAgJib1krVQqKFk2eP7Hh4fZidcAAeywATz8No0dDwYJJf/8icn2XLln76tSpsGqVZ71YMZub1LGjVSqJRFJiKRkosSQSD+Hh8OmnMGSIvd0K9pfr9detxtbf39XwREREkoPjWKHu9YZlRyZjrid79tirjkqVggIFUk4H+cmT9id+yhR7zFmywODB0L27/uSLJLe//7Zk0iefeGaq+frCY4/Zzm4PPGDVSiLXUmIpGSixJBIHERHWuP3GGzYREGyi54AB0K1b4tTei4iIpCDh4bB/f8wh2ZHHQUE3/vr8+WOvOipdGnLmTJ7HkFjWrYMXX4S//rLrZcvChAn2QlZEks758zBvniWU1q3zrJcubdVJHTrYLm8iN6LEUjJQYknkBhwHvv4aBg2CTZtsLWdO6NPHBjBkzuxufCKSZi1dCocO2QDhwECr8Ig8DgzUjjaSOIKDbSh2bFVHe/da5/f1eHtba1psVUclS1p1T1oSEQFz5thTgBMnbK1ZMxg7VkOBRRKT48Dq1ZZMmj/fWt/AqgSbNbPqpAYNVJ0kcafEUjJQYkkkFo4DP/5oCaU1a2wtWzbo1Qt69Lj51jIiIrdg6VJ48MEbnxMQEDPZFFsC6npr2bJpHFx6ceFCzGqjyI8HDtifvOvx97ckUWzJo+LF02c72Nmz1hE/caJVdQUEQP/+8NprKmAWuRVnzlib25QpNpQ7Urlylkxq1w5y53YvPkm9lFhKBkosiVzj119toMLvv9v1zJnhlVegd+/UV7svIqlOWBhUrQr//AMVK0LWrHDunF3OnvW8c5sYsmRJeGIqe3aLTe8Yu89x4NSp6w/LPn78xl+fJUvsiaPSpW2MoDY4jd2mTfDyy/Dbb3a9ZEkYPx6aNnU1LJFUxXHgjz8smbRwIVy5YusZM8JTT9nObvXqpZy5a5I6KbGUDJRYEvl/q1ZZQmnZMrueIYMNVOjb1+YpiYgkgw8/hOeftzz2zp2QI0f0z4eF2cyJq5NNkcdxXbt8OXFi9fKy5FJCklKRx1my6AVDXEREwOHD1x+Wff78jb8+d+7YZx2VKmV/4vRvkDCOY606vXvbvw/YNufjx9v3V0Rid/KktZZOmwb//utZr1TJkknPPBPz759IQimxlAyUWJJ07++/bYuXb7+1635+Vm87YID2KhWRZHXunL0YPXkS3n/fqiGSQkiIJSISkpSKvB4SkjixeHtbW96ttPVlypQ2EiOhobBvX+zDsnfv9ryTfz2FCl1/p7XAwOR5DOnVhQswfDiMG2f/jv7+1hrXv7/GMYpEchz45RerTlq0yPN3JFMmaN3ann7feWfa+H0uKYsSS8lAiSVJt7ZssV3eFi2y6z4+trXE66/b4AgRkWT22mvw7rs2T2LTppQ9oPvKlYQlpa5eCwtLnFh8fW+tpS8wMPlm41y+bEmi2KqO9u2zmT3X4+Njf55iqzoqWdJm/Yi7tm2D7t1tTCNAkSI23PvJJ/ViWdKvsDCr7HvnHWvzjlS9uiWTWrfW+FJJWqkqsTRp0iRGjx7NkSNHqFChAuPHj+fuu+++7vkffPABEydOZO/evRQtWpSBAwfSrl27qM8vWrSIt99+m507dxIaGsptt91Gr169aNu2bdQ5YWFhDBkyhE8++YSjR49SoEABOnTowOuvv453HIceKLEk6c5//8HQobZ3qePYM72nn7Yk0223uR2diKRTu3ZB+fJW7fDtt/DII25HlLQcx5Ist9LSd+6ctYglBn//W2vpCwz0DLI+e/b6w7IPHbpxHBkzxkwaRX4sWjRlJxvFOA58+aXt9bFvn63dd59VId5+u6uhiSSrK1dg5kwYPdp2nwRrn37mGUsoVavmbnySfsQn5+HqviYLFiygR48eTJo0iXr16vHRRx/RqFEjtm7dStGiRWOcP3nyZPr378/UqVOpWbMmq1evpkuXLuTIkYOm/z/xL2fOnAwcOJBy5crh7+/PN998Q8eOHcmbNy8PPfQQACNHjuTDDz9k9uzZVKhQgbVr19KxY0cCAwPp3r17sn4PRFK8vXth2DBr6I58S7h5c9vapUIFNyMTEaFPH0sqPfggNGrkdjRJz8vL2h8yZYICBRJ2G45jw8wTmpQ6d85aAh3HWjJOnPBsI58QGTPaeL5z5258XmBgzKRR5HGBAhqIntp5ecHjj9v/5VGjrEpj2TKoUsWqmQYPVnWGpG3nz9u8wHHj4OhRW8uTB159FV54Qa25krK5WrFUq1YtqlWrxuTJk6PWypcvz+OPP86IESNinF+3bl3q1avH6NGjo9Z69OjB2rVr+T1yJ6pYVKtWjcaNG/Pmm28C0KRJE/Lly8f06dOjznnyySfJlCkTH3/8cZxiV8WSpHmHDsFbb9l0wNBQW2vSxJJMd9zhbmwiItjMiYYNLaGwcaPtBifJIyLC5uPcSkvfxYsxbzdfvuvvtJYzp9qi0pPdu+0F9Vdf2fX8+a2C45ln9HMgaUvkfMAJE+z3I1g7aJ8+0KmTvZEg4oZUUbEUEhLCunXr6NevX7T1Bx98kJUrV8b6NcHBwWS8ppk/ICCA1atXExoait81dc6O4/Dzzz+zfft2Ro4cGbV+11138eGHH/Lff/9RpkwZNm7cyO+//8748eOvG29wcDDBwcFR18/fbBsRkdTq2DF7m3DyZIj8mX/gAUso1a7tbmwiIv8vPBx69rTjbt2UVEpu3t6eVraECg/37NR3+TIULmztHiJg86++/BKWLLGKpZ07oW1b+OgjewFetarbEYrcmoMHYcwYG8odFGRrZctCv342bSKyTVgkNXCtaPjkyZOEh4eTL1++aOv58uXjaGTt3zUeeughpk2bxrp163Ach7Vr1zJjxgxCQ0M5efJk1Hnnzp0jS5Ys+Pv707hxYyZMmMADDzwQ9fm+ffvSunVrypUrh5+fH3fccQc9evSgdevW1413xIgRBAYGRl2KFClyi98BkRTm9GnbhqVkSdvvNzgY7r7bSgJ+/FFJJRFJUebMgfXrLbExdKjb0UhC+PjYttjFi9ucLCWVJDaPPGL7hrz9tlVu/P67DS9+6SU4c8bt6ETib8cOePZZz1PuoCD7mf78cxvS3aGDkkqS+rjeje51TS2r4zgx1iINGjSIRo0aUbt2bfz8/Hjsscfo0KEDAD4+PlHnZc2alQ0bNrBmzRreeustevbsyS+//BL1+QULFjB37lw+/fRT/v77b2bPns27777L7Nmzrxtn//79OXfuXNTlwIEDCX/QIinJuXM2L6lECatUCgqyPUt/+AF+/RXq13c7QhGRaC5cgAED7Pj1120GhYikXRky2Htf27ZBixbWivnBB1CmjHXsJ9YwepGktGEDtGplO5hOn26TJurXt6fca9bYLohXvaQVSVVcm7EUEhJCpkyZWLhwIU888UTUevfu3dmwYQO//vrrdb82NDSUY8eOUaBAAaZMmULfvn05e/bsdXd0e/bZZzlw4AA//PADAEWKFKFfv368+OKLUecMHz6cuXPnsm3btjjFrxlLkupdumS15KNGed7yq1IF3nzTZilpgIGIpFCvv24j4EqVsnd3M2RwOyIRSU4//wwvvwxbt9r1mjVh4kR7X0wkpfn9dxgxwto6IzVpYsnSunXdi0vkZuKT83CtYsnf35/q1auzdOnSaOtLly6l7k3+h/n5+VG4cGF8fHyYP38+TZo0uW5SCawK6ur5SEFBQTHO9/HxIUJvd0h6cPmybTdRsqT9RTtzxnoQPvsM/v4bmjZVUklEUqz9+20mBdggXyWVRNKfe++16o+xY62Fcs0aqFXL2otuZYdCkcTiOPD993DPPTZZYskSm03XurVtNvH110oqSdri2vBugJ49e9K2bVtq1KhBnTp1mDJlCvv37+e5554DrP3s0KFDzJkzB4D//vuP1atXU6tWLc6cOcPYsWPZsmVLtBa2ESNGUKNGDUqVKkVISAhLlixhzpw50Xaea9q0KW+99RZFixalQoUKrF+/nrFjx9KpU6fk/QaIJKeQEKu7HT4cDh+2tVKlrA2udWvV3opIqtCvH1y5Yu0Djz/udjQi4hY/P9s1rnVr6NvX5q5Nnw7/+5891enWDXxdfaUj6VF4OCxaZBVK69fbmr8/tG9vu7yVLu1ufCJJxdVfty1btuTUqVMMGzaMI0eOULFiRZYsWUKxYsUAOHLkCPv37486Pzw8nDFjxrB9+3b8/Pxo2LAhK1eupHjx4lHnXLp0iRdeeIGDBw8SEBBAuXLlmDt3Li1btow6Z8KECQwaNIgXXniB48ePU7BgQbp168bgwYOT7bGLJJuwMHu2NWwY7Ntna0WLwuDB0K6dPTMTEUkF/vwT5s2zospx41RcKSKQPz/Mng1du9pA7w0b7OPUqdYed9ddbkco6UFICMydCyNHwn//2VrmzJbg7NkTChVyNz6RpObajKXUTjOWJMULD4cFC6wiaccOWytQAAYOtFpx9Y+ISCoSEWFtA3/9BZ06WWWCiMjVwsNt6/aBAz3jI9u0sXGSBQq4G5ukTUFBNkB+9Gg4eNDWcuSAV16xOWC5crkbn8itiE/OQ4mlBFJiSVKsiAhYvNgqkiKnWubObfOUnn8eAgLcjU9EJAE+/RSeecbeAd6xQy8SReT6Tp605NLUqTbrJksWeOMNe7GvbdwlMZw9azsTjh9vP29gf5d69bLquaxZ3YxOJHGkiuHdIpLIHAe+/RZq1IDmzS2plD27bZ20e7fV4SqpJCKpUFCQzVABy5ErqSQiN5I7N3z0EaxebUO9L16E116zzW9/+snt6CQ1O3bMZv0VLWo7lJ48afvhfPSRPd3u1UtJJUmflFgSSe0cx54l1a1re5euX29vzQ0aBHv2wIAB+gsnIqnamDHWYlC0qOXIRUTiokYNWLkSZsyAPHlg2zZ44AF7/+2qMa4iN7V3L7z4IhQvbnOULlyAihXhk09g+3arUsqY0e0oRdyjxJJIarZiBTRsaM+SVq2yiqQ+fSyhNGyYVSyJiKRihw/DO+/Y8ciRKrwUkfjx9oaOHW2g8iuv2PX//Q/KlbOi7itX3I5QUrKtW21Ht9KlYdIk+3mpXRu++go2boSnn9bugyKgxJJI6rRmDTz8MNxzD/z6qw0MeOUVq8EdOdJqwEVE0oABA6wVrk4duGqDVxGReMmeHd57zwq777kHLl+2VqaKFW2SgMjV1qyBZs2gQgXbXDk83N7HXb7cquCaNrUkpYgY/XcQSU0cx7ZDuvNO+OEHe4ukWzfYudOeLeXP73aEIiKJZt0620YcYNw48PJyNx4RSf0qV4ZffrENAQoWhF27bJJA06Z2LOmX41ji6IEH7Kn24sW23qyZJZp+/BEaNNDfIpHYKLEkkppMmgQzZ9pbJO3bW1P3hx9CkSJuRyYikqgcB1591Y6fecYG8IqIJAYvL2jd2mYu9elj79N98w3cfruNqAwKcjtCSU4REdbaVqcO3HuvjS718bGn2lu3WutkjRpuRymSsnk5juO4HURqFJ+t90QSxfbtcMcdVrv9/vvw8stuRyQikmQ+/xyeespmKm3frvy5iCSdbdtsosDSpXa9aFEYO9YqVVSdknaFhcGCBTBiBPzzj61lzAjPPgu9e0OxYu7GJ+K2+OQ8VLEkkhqEhUG7dpZUuv9+25ZCRCSNunLFqgjAntwrqSQiSalcOZswsGiRJZX277ed4x58EP791+3oJLFduQIffQRlykCbNpZUypoV+vWz3d8mTFBSSSS+4p1YKl68OMOGDWO/9ugUST5vvw2rV9vkychWOBGRNOr9921zy4IFPQkmEZGk5OUFTzxhiaRBgyBDBmuJqlwZXnvNtpeX1O3CBXj3XShRAp57zv7O5M5tuwPu32+VS/nyuR2lSOoU71envXr14ssvv6RkyZI88MADzJ8/n+Dg4KSITUTApgUOG2bHH3wAhQu7G4+ISBI6dgyGD7fjt9+GLFncjUdE0pdMmexp1z//2EDvsDBLRpQtC598YvPfJHU5dQreeMOqkF57DY4etUrY99+Hffts99Hs2d2OUiR1S/CMpY0bNzJjxgzmzZtHWFgYTz/9NJ06daJatWqJHWOKpBlLkiyCgqBaNRsw0qIFzJ+vZn8RSdO6dYMpU6B6dSvUVIGmiLjp22+he3fPjnF3322tUlWquBuX3NyhQzBmjP1NuXTJ1sqWhb59bVMIf3934xNJ6eKT87jl4d2hoaFMmjSJvn37EhoaSsWKFenevTsdO3bEKw2/AFZiSZLFK6/Ys5cCBWDLFsiZ0+2IRESSzObNULWq7dDz22/2Ak5ExG1Xrtgw7+HDbdyltze88IJVNuXI4XZ0cq2dO2HkSJg9G0JDba1aNejf39odfXzcjU8ktUiW4d2hoaF89tlnPProo/Tq1YsaNWowbdo0WrRowcCBA3nmmWcSetMiArY1yYQJdjxzppJKIpKmOQ68+qollZo3V1JJRFKOjBmtXWrbNtutMiICJk604c/Tp9t1cd/GjdC6tVUlTZtmSaV77oHvv4e1a+1vi5JKIkkj3hVLf//9NzNnzmTevHn4+PjQtm1bnn32WcqVKxd1zpo1a7jnnnu4fPlyogecUqhiSZLUmTNQqZLV8L7wgs1WEhFJw77+Gh591FoT/v0XSpZ0OyIRkdgtWwYvv+zZMe7OOy3RVLOmu3GlVytX2ky+b7/1rDVubBVK9eq5F5dIapekFUs1a9Zkx44dTJ48mYMHD/Luu+9GSyoB3H777bRq1Sq+Ny0ikV56yZJKt90Go0a5HY2ISJIKCYHeve341VeVVBKRlO2++6w6ZswY26Z+9WqoVQu6doWTJ92OLn1wHPjhB6hf35JH335rLYqtWsGGDfDNN0oqiSSneFcs7du3j2LFiiVVPKmGKpYkyXz2GbRsabW6f/xhz1Qk1QkJgU2b4K+/YNUqG5H18svQqZPbkYmkPO+9Bz16QN68sGMH6M+qiKQWR47YMOiPP7brOXLYLKZu3dR2lRTCw2HxYhgxAv7+29b8/KB9e+jTx96TFZHEkaTDu9esWUNERAS1rnmx+9dff+Hj40ONGjXiH3EqpMSSJIlDh6wF7swZGDTIpkJKiuc4cPCgJZBWrbJk0rp1Nuzzav7+1uNfqZI7cYqkRKdOQenScPYsfPSRveMvIpLa/P67FZxv3GjXq1a19jhVzSSOkBD45BMbyr19u61lymQJvJ49oXBhd+MTSYuStBXuxRdf5MCBAzHWDx06xIsvvhjfmxORSI4DnTtbUql6dUssSYp06ZLtWDVqFDRrZk9mihaFFi1s15g//rCkUo4c0KgRDBkC999vT4ratbOPImKGDrWkUuXK9itQRCQ1uusue1Ppgw8ge3Zrx7rrLvu7f+SI29GlXkFBtpdN6dJW9b19uz2/GjwY9u2z511KKom4L94VS1myZGHTpk2UvGYAwp49e6hcuTIXLlxI1ABTKlUsSaKbNAlefNG2Hvn7byhf3u2IBNvpZccOTzXSqlW2JXp4ePTzfHygShWoXdsutWpZObaXl33+6FGoWNGqM1SMJmK2bbP/F+Hh8NNPNrdERCS1O3ECBg60nckcx+YwDRliLfF+fm5HlzqcPWtPjcePt+8nQP780KuXVSllzepmdCLpQ3xyHr7xvfEMGTJw7NixGImlI0eO4Osb75sTEYD//vNMrh05UkklF50+bUM4r25rO3s25nmFCnmSSLVrQ7VqVpJ9Pfnzw+TJVtX09tvQtKl2jxHp3duSSk2bKqkkImlHnjwwZQp06WLtcatXW0Jk2jSrvtHvu+s7dsySSZMmwfnztlaihM2xat/e3n8VkZQn3hVLrVq14ujRo3z55ZcEBgYCcPbsWR5//HHy5s3LZ599liSBpjSqWJJEExZmDfirV9szjR9/tG0tJMmFhlr1UWQCadUqy/FdKyDAuhOvrkZKaNn100/DvHlQrpwVpgUE3NpjEEmtfvwRHnoIfH3hn3+gTBm3IxIRSXwRETBrliVGIneMe+opePdda6MXs2+ffU+mTfPMqKxQAfr3tz1tVL8gkvySdHj3oUOHuOeeezh16hR33HEHABs2bCBfvnwsXbqUIkWKJDzyVESJJUk0b75pjeKBgZblSCf/h9xw6FD0SqS1a+Hy5ZjnlSljyaPIRFKlSolXun76tLX+HDliu2CNG5c4tyuSmoSF2WDbf/7R/wMRSR/OnIE33rAZTBERVuU8cKBVMmXI4HZ07vn3XyvW/+QT+9sA9hxswABo0kTvtYq4KUkTSwCXLl3ik08+YePGjQQEBFC5cmVat26NXzpqGlZiSRLF2rVQp479JZ07F555xu2I0oygIKsIujqRdPBgzPOyZ7cnMJGJpDvvhFy5kja2JUugcWM7Xr4cGjRI2vsTSWk+/BCefx5y5oSdO20Qq4hIerBxo81aWrHCrpcuDe+9B4884m5cyW3tWhgxAhYvtjlUYBudDBhgz4siZ1SKiHuSPLEkSixJIrh82QbzbNtmNdELFuivaAI5jr04vXrA9qZNnne+Inl7285Tke1stWtbdZIb74Z17QpTp0Lx4harhlBKenH2rA22P3kS3n/fXmCJiKQnjmNt8b17e3aMa9rUqjdLlXI3tqTkOPDrrzZrculSz/oTT1jLm2ZPiqQsyZJY2rp1K/v37yfkmn2zH3300YTcXKqjxJLcsu7d7VVVgQLWApfUZTJpyJkzNpIqci7SX39Zi9m1ChSIPhepenXIkiX5443NhQuW5Nq7F5591pJMIunBa6/ZHI1y5Sypmo6KnUVEorlwwXaJHT/e3gzLkAH69IF+/W68IUhqExEB335rCaVVq2zNx8cK9fv2hdtvdzc+EYldkiaWdu/ezRNPPMHmzZvx8vIi8su9/r/SIvzaPbjTKCWW5Jb89BM88IAdf/cdPPywu/GkYGFhsGWLJ4m0apUVeV0rQ4boA7Zr17YB2ym5COzXX6FhQ3sH75tvPO1xImnVzp32AiI01F5kpLfWDxGR2Pz7L7zyij09BBvqPW6cVfKk5OcxNxMWBp99Bu+8Y++hgj1f69zZ3mQoXtzV8ETkJpI0sdS0aVN8fHyYOnUqJUuWZPXq1Zw6dYpevXrx7rvvcvfdd99S8KmFEkuSYGfP2jTogwdtyMikSW5HlKIcORJ9l7Y1a2xe0rVKlYqeRKpcGfz9kz/eW9Wzpz15zJ/fEmgqXJO0rFkzm6fx4IPw/fep+wWTiEhichxYtAhefRUOHLC1Bx6w4vZy5dyNLb6Cg2H2bBvKvXu3rWXNCi+8YBs25M/vangiEkdJmljKnTs3P//8M5UrVyYwMJDVq1dTtmxZfv75Z3r16sX69etvKfjUQoklSbA2bWzri9tug/XrIXNmtyNyzZUrMQds798f87xs2WIO2M6TJ/njTQqXL1ul1b//QqtWNnNBJC365Rer0PP2tha4ChXcjkhEJOUJCrKh1qNGQUgI+PpasmnQoJQ/j/HiRfjoIxgzxjM7KnduSya9+KJtmCIiqUd8ch6+8b3x8PBwsvz/kJLcuXNz+PBhypYtS7Fixdi+fXvCIhZJLz77zJJK3t4wZ066Sio5jr1rdfWA7Y0brSXmat7eULFi9AHb5cql3e1mAwLsR6F2bZg/38reW7RwOyqRxBUebtV5AN26KakkInI9mTLBm29C+/aWUPrmGxg92jYPfvddaN065VV7njoFEyZYddWZM7ZWuLC1u3XunK6e7oqkW/FOLFWsWJFNmzZRsmRJatWqxahRo/D392fKlCmULFkyKWIUSRsOH4bnnrPjAQMsk5CGnTtnbWxXVyOdPBnzvHz5og/YrlEj5b8jl9hq1ICBA22A5/PPw9132+BxkbRi9mwr0AwMhKFD3Y5GRCTlK10avv7a5tF17w67dtmw648+siRO5cpuRwiHDsHYsRbTpUu2VqaMDeRu0yZ1jigQkYSJdyvcDz/8wKVLl2jWrBm7d++mSZMmbNu2jVy5crFgwQLuvffepIo1RVErnMSL40CjRvDDD9b39OefaWorpPBw+Oef6AO2//3XHvbV/P2hWrXoiaRixVLeO29uCAmx78n69TbE++uv9X2RtOHCBXuhcfSoveveu7fbEYmIpC5XrlgCZ/hwa6H38bHWsqFD3Wkv27nTWvVmz7bnLwB33AH9+9ssPR+f5I9JRBJfks5Yis3p06fJkSNH1M5w6YESSxIvkyfbxMKMGW2oUPnybkd0S44e9SSR/vrLKpMuXox5XokS0QdsV6liu4FI7LZssbxjSAhMnw6dOrkdkcite/11eOstG7j/zz/6HSAiklD790OvXvD553Y9Tx4bkN2+ffKMDNi0yXZ4W7AAIiJs7e67rRD/oYf0hphIWpNkiaWwsDAyZszIhg0bqFix4i0HmpopsSRxtmMHVK1q0xjHj7d65lQkONiqaK5uadu7N+Z5WbNCzZrRq5Hy5k32cFO90aOhTx/7fm7apK14JXXbt89mpF25YrsdPfGE2xGJiKR+P/0EL78M27bZ9Vq1YOJEa61PCn/+CW+/bfOeIj3yiFUo3XVX0tyniLgvyYZ3+/r6UqxYMcLDw28pQJF0IywM2ra1pNJ999mzgBTMcSxpdPWA7Q0bPGXOkby8bPhu5HDt2rWtCEulz7euZ0/48kv44w/o2BGWLUu7g8sl7evXz5JK9evD44+7HY2ISNpw//22AcqECTBkiL3pd+ed0KWLVYjmzn3r9+E4sHSpJZR+/dXWvLxsg5F+/ew9UxGRSPFuhZs5cyYLFy5k7ty55MyZM6niSvFUsSRxMny47Q8bGAibN0ORIm5HFM2FC9EHbK9aBSdOxDwvT57ou7TVrAn6sU86O3da22AqLXITAewd7rp17YXIunU2f0NERBLXkSNW6Tx3rl3PkcOSS127JuwNv4gIWLwYRoyw391gY0Hbt7f7ue22xItdRFK2JJ2xdMcdd7Bz505CQ0MpVqwYma/ZP/Lvv/+Of8SpkBJLclPr1lkWJiwMPv7YtsdwUXi4DdS+esD2P//EHLDt52cvAK9OJJUoob755Hb1WK4NG6BsWbcjEom7iAhLKv31l80Kmz7d7YhERNK2FSvgpZesjR6souiDD+x3cVyEhsInn9jMpsgWu0yZLEHVqxcULpwkYYtICpZkrXAAj6uWXeTmLl+2RFJYGDRvbvvDJrPjx+1FXWQiafVqq1C6VrFi0QdsV61qyQxx13PPwRdfwI8/Qrt21hrnG+/f2CLumDfPfvdkzmyFmyIikrTuvtve0/zoI9s0YcMGqFfPnkOMHAn588f+dUFBlvx/910bDg6209zLL8MrryROW52IpH2JsitceqSKJbmhHj3gvfegQAFrgcuVK0nvLiTEnkBEDtdetQp27455XubMMQdsX++Jhrjv4EGoWBHOnbMX5wMHuh2RyM0FBVmF3cGD1o4xYIDbEYmIpC8nTtjv3unTrTI9a1YYOtQqmvz87Jxz52DSJBg3zjMGIV8+q07q1k0jD0QkiVvhxCixJNe1bJlNVQRYsgQaNUrUm3cce0fp6rlI69fb7m3Xuv326AO2b79dVS+pzccf27uNfn5WdaZhmZLSvfkmDB4MRYtaO0VAgNsRiYikT6tXWzJpzRq7fvvtNjtp1Sprkzt/3taLF4e+faFDB1Wti4hHkiaWvL298brBsJX0smOcEksSq7NnoVIle6v+uedsUE4i2b8f5syB2bNtuPO1cuWKOWA7e/ZEu3txiePAk0/aIM1KlezJYYYMbkclErtDh6BMGatamjcPWrVyOyIRkfQtIgJmzrSd3E6ejP65ChVsvVUrvfEoIjEl6YylxYsXR7seGhrK+vXrmT17NkOHDo3vzYmkLS+/bEml0qWtWf0WBQXBokUwaxb8/LNn0Lavr1WuXJ1IKlVKA7bTIi8vm5fw++/WVTlkiL3bKJISDRxov7fq1IGWLd2ORkREvL2hc2do1syqSSdPhurVrVWuaVP7vIjIrUq0VrhPP/2UBQsW8OWXXybGzaV4qliSGBYuhBYt7C/0H39YticBHAdWrrRk0oIF0QduN2xoZcrNmkGWLIkStaQSX3wBTzxhP14rVsR9lxeR5LJuHdSoYcd//QV33uluPCIiEtOVK2p3E5G4SdKKpeupVasWXbp0SaybE0ldjhyx1jeA/v0TlFQ6cMDm6cyaBTt2eNZLlID27e1SvHiiRCup0OOPQ9u29jPSvr0Na8+c2e2oRIzj2J4FYJtgKqkkIpIyKakkIkkhURJLly9fZsKECRQuXDgxbk4kdXEcqzE+fRqqVbM64zi6fNkqUWbOhJ9+8rS6Zc4MTz1l1Ul3360yZTHvvw/Ll9uMrX79YMIEtyMSMf/7n7VrBgSoVVNEREQkvYl3YilHjhzRhnc7jsOFCxfIlCkTc+fOTdTgRFKFjz6C776zicoffwz+/jc83XGsTWTmTJg/37MjB0D9+pZMat5crW4SU/bsMGMGPPggTJxoVUz33ed2VJLeXbkCffrY8WuvQZEi7sYjIiIiIskr3omlcePGRUsseXt7kydPHmrVqkWOHDkSNTiRFG/HDujVy47fecf2cb2OQ4c8rW7bt3vWixXztLqVLJm04Urq98AD8MILMGkSdOxoA70DA92OStKz99+HPXugYEFPgklERERE0o9EG96d3mh4txAWZn1qq1bBvffC0qUxetauXIEvv7Rk0o8/2pavYO0izZtbYqB+fbW6SfxcugRVqsCuXZaQnDXL7YgkvTp2DG67zTYZmDXLfh5FREREJPVL0uHdM2fOJEuWLDz11FPR1hcuXEhQUBDt9axS0ouRIy2plC2b9bX9f3bIcWDNGk+r29mzni+5+25Pq5vykZJQmTPD7Nn28zR7tu0W99hjbkcl6dHgwZZUql7dhsuLiIiISPoT7zqJd955h9y5c8dYz5s3L2+//XaiBCWS4q1bB0OG2PHEiVC0KEeOwKhRUKEC1KoFH35oSaUiReD1161r7rffoFMnJZXk1tWrZ/NsALp2hRMn3I1H0p9Nm2DaNDseN06VlyIiIiLpVbwrlvbt20eJEiVirBcrVoz9+/cnSlAiKdrly/bWfFgYwU+04qsMbZjVGL7/3tPqljEjPPmkVSfde69ecEnSGDYMvv0W/vkHnn8eFi6Eq0bgiSQZx4GePe13XvPmVj0nIiIiIulTvF/u5s2bl02bNsVY37hxI7ly5UqUoERSMqf/ANb+m4mXMk2nwPJPaNHSiyVL7AVW3bowZQocPQpz58L99yupJEknciNCX1/b7v3TT92OSNKLb76BZctsE8xRo9yORkRERETcFO+XvK1ateKVV15h+fLlhIeHEx4ezs8//0z37t1p1apVUsQokiIcPQpjnttB5fc6UZO1fBDUiTNnvSlUCAYMsJ3e/vgDunTRLl2SfO64w+bcALz0ku0+KJKUQkKgd287fvVViKWIWURERETSkXjvChcSEkLbtm1ZuHAhvr7WSRcREUG7du348MMP8ff3T5JAUxrtCpc+hITA11/bbkfffecQHm59Rhl9QniihT8dOsB994GPj6thSjoXFmbVcmvWwMMPw5IlaomTpDN+vCWU8ua12XH6EygiIiKS9sQn5xHvxFKkHTt2sGHDBgICAqhUqRLFihVLULCplRJLaZfjwPr1lkz69FM4dcrzudr8SYfc39JyfT+yF87iWowi19q2zaqXrlyxwfHdurkdkaRFp05B6dK2McFHH9ngeBERERFJe+KT80jw9JfbbruNp556iiZNmtxSUmnSpEmUKFGCjBkzUr16dVasWHHD8z/44APKly9PQEAAZcuWZc6cOdE+v2jRImrUqEH27NnJnDkzVatW5eOPP45xO4cOHaJNmzbkypWLTJkyUbVqVdatW5fgxyGp3/HjtrNR1aq2dfaECfYiqkAB6PvYNv6lHH9630W3rxorqSQpTrlyELkxZ69esGuXu/FI2jR0qCWVKleGzp3djkZEREREUoJ47wrXvHlzatSoQb9+/aKtjx49mtWrV7Nw4cI439aCBQvo0aMHkyZNol69enz00Uc0atSIrVu3UrRo0RjnT548mf79+zN16lRq1qzJ6tWr6dKlCzly5KBp06YA5MyZk4EDB1KuXDn8/f355ptv6NixI3nz5uWhhx4C4MyZM9SrV4+GDRvy3XffkTdvXnbt2kX27Nnj++2QVC4kxNqGZs60j2Fhtu7vD48/Dh07wv0VjuBbtR5wGvoPhDp13AxZ5Lq6d4cvv4Rff7Wf3eXL1aYpiefff2HSJDseO1Y/WyIiIiJi4t0KlydPHn7++WcqVaoUbX3z5s3cf//9HDt2LM63VatWLapVq8bkyZOj1sqXL8/jjz/OiBEjYpxft25d6tWrx+jRo6PWevTowdq1a/n999+vez/VqlWjcePGvPnmmwD069ePP/7446bVUVcLDg4mODg46vr58+cpUqSIWuFSqY0bLZn0ySdw8qRn/c47oUMHaNkScubE+uIaN4bvvrM+o1WrLOskkkLt2WPVJBcvwrvvWvWSSGJo3NgS8E2bwldfuR2NiIiIiCSlJG2Fu3jxYqwDuv38/Dh//nycbyckJIR169bx4IMPRlt/8MEHWblyZaxfExwcTMaMGaOtBQQEsHr1akJDQ2Oc7zgOy5YtY/v27dxzzz1R61999RU1atTgqaeeIm/evNxxxx1MnTr1hvGOGDGCwMDAqEuRIkXi+lAlhThxAt57z/JDVava8cmTkD8/vPYabNkCf/0Fzz///0klgClTLKmUIQPMnaukkqR4JUpYSyfAwIHwzz/uxiNpw48/WlLJ19cSliIiIiIikeKdWKpYsSILFiyIsT5//nxuv/32ON/OyZMnCQ8PJ1++fNHW8+XLx9GjR2P9moceeohp06axbt06HMdh7dq1zJgxg9DQUE5eVXZy7tw5smTJgr+/P40bN2bChAk88MADUZ/fvXs3kydP5rbbbuOHH37gueee45VXXokxr+lq/fv359y5c1GXAwcOxPmxintCQ+2d9WbNoFAh6NEDNmyw/FDz5vDNN3DgAIwaBRUqXPPFO3dCz552PGIExOPnW8RNnTtDo0YQHAzt2tn/A5GECgvz/Cp86SUoU8bdeEREREQkZYn3jKVBgwbx5JNPsmvXLu69914Ali1bxqeffsrnn38e7wC8rtkT23GcGGtX3/fRo0epXbs2juOQL18+OnTowKhRo/C5athD1qxZ2bBhAxcvXmTZsmX07NmTkiVL0qBBAwAiIiKoUaMGb///pNs77riDf/75h8mTJ9OuXbtY7ztDhgxkyJAh3o9P3LF5s+3qNneuDeWOVL26tbq1bg25ct3gBsLC7BV5UBA0bGjDa0RSCS8vmDYNKlaEv/+2od5vvOF2VJJaTZ1qlW85c8LgwW5HIyIiIiIpTbwrlh599FG++OILdu7cyQsvvECvXr04dOgQP//8M8WLF4/z7eTOnRsfH58Y1UnHjx+PUcUUKSAggBkzZhAUFMTevXvZv38/xYsXJ2vWrOTOndvzoLy9KV26NFWrVqVXr140b9482symAgUKxKiuKl++PPv3749z/JLynDplO7lVr24zZsaOtaRS3rw2Z2bTJli71t5xv2FSCayE6c8/IVs2y1B5J3gDRRFXFCzoGbQ8fDho00tJiLNnPcmkoUMhRw5XwxERERGRFChBr5YbN27MH3/8waVLl9i5cyfNmjWjR48eVK9ePc634e/vT/Xq1Vm6dGm09aVLl1K3bt0bfq2fnx+FCxfGx8eH+fPn06RJE7xv8MLfcZxog7fr1avH9u3bo53z33//UaxYsTjHLylDWJi1szVvDgUKwCuvWIWGn5+1v331FRw8aDNBrpk3f31//+0p75g4EWLZoVAkNWjVClq08BTgXbnidkSS2rz1ls2iK1cOunVzOxoRERERSYni3QoX6eeff2bGjBksWrSIYsWK8eSTTzJ9+vR43UbPnj1p27YtNWrUoE6dOkyZMoX9+/fz3HPPATbX6NChQ1Gzj/777z9Wr15NrVq1OHPmDGPHjmXLli3Mnj076jZHjBhBjRo1KFWqFCEhISxZsoQ5c+ZE23nu1VdfpW7durz99tu0aNGC1atXM2XKFKZMmZLQb4cks3/+sUKijz+GqzcivOMOa3V7+mm4qogt7q5cgbZt7ZX4k09CmzaJFLGIOz74AH79FbZuhddf1+BlibudO22TA4AxYyxhLyIiIiJyrXgllg4ePMisWbOYMWMGly5dokWLFoSGhvK///0vXoO7I7Vs2ZJTp04xbNgwjhw5QsWKFVmyZElU5dCRI0eitaeFh4czZswYtm/fjp+fHw0bNmTlypXRWvAuXbrECy+8wMGDBwkICKBcuXLMnTuXli1bRp1Ts2ZNFi9eTP/+/Rk2bBglSpRg/PjxPPPMM/F+DJJ8Tp+G+fMtobRmjWc9d27L/3ToAFWq3OKdDBhgr8Dz5YMPP7RhNSKpWO7cNm+paVNrD330Ubhqk0yR6+rTxwa/P/SQDYMXEREREYmNl+M4TlxOfOSRR/j9999p0qQJzzzzDA8//DA+Pj74+fmxcePGBCWWUrPz588TGBjIuXPnyJYtm9vhpFlhYbbN9axZ8OWXEBJi676+0LgxdOxoL3j8/RPhzpYvh/8fSM8339gdiKQRnTvDjBlQooTNG8uSxe2IJCX75Rfbt8DHBzZujGXXTBERERFJ0+KT84hzxdKPP/7IK6+8wvPPP89tt912y0GK3Mi//3pa3Y4c8axXrmzJpKeftqHciebcOWjf3o67dlVSSdKcceNg2TLYswd697aCPJHYhIfDq6/acdeuSiqJiIiIyI3FeXj3ihUruHDhAjVq1KBWrVpMnDiREydOJGVsks6cOWMvdmvXhttvt43ZjhyxHdwih3Jv3Ag9eiRyUgnsDg4cgFKlbJiISBqTLRvMnGnHH30E33/vbjyScs2eDRs2QGCg7QQnIiIiInIjcU4s1alTh6lTp3LkyBG6devG/PnzKVSoEBERESxdupQLFy4kZZySRoWHww8/2O5VBQrA88/DX39Z+0XTpvC//8HhwzZA9o47kiiI//0P5swBb2/7qB4hSaMaNrQcKlhr3Jkz7sYjKc+FCzBwoB0PGgR58rgbj4iIiIikfHGesRSb7du3M336dD7++GPOnj3LAw88wFdffZWY8aVYmrF0a7Zvt1a3OXMscRSpQgVrdWvTxuZnJ7kjR6BSJTh1ygZ3v/VWMtypiHuCgixJ+99/8MwzMHeu2xFJSvL66/ZrsFQp230zQwa3IxIRERERN8Qn53FLiaVI4eHhfP3118yYMUOJJbmuc+dgwQJLKP35p2c9Z06bmdShA1SrlowbsTkONGkCS5bYK+1VqxJpCrhIyvbXX1C3LkREwOefw5NPuh2RpAT79kHZshAcDIsWwRNPuB2RiIiIiLgl2RNL6ZESS3ETHg4//2zJpEWL4MoVW/f2tt3cOnSwljdX3hWfMgW6dbM7X7dOE2olXYmsTMmVyypTkqVCUFK01q1h/nxo0MB+bydbkl9EREREUhwllpKBEks3tmOHDYCdPRsOHvSsly/vaXUrUMC9+Ni1C6pUgUuXbFh3z54uBiOS/EJC4M47bSD+o4/CF18okZCerVwJ9erZz8Dff0PVqm5HJCIiIiJuik/OwzeZYpJ04Px5WLjQdp764w/Pevbs9k54x45Qo0YKePEaHg7t2llSqUED22ZOJJ3x97cZZzVqwFdf2XH79m5HJW6IiIBXX7Xjjh2VVBIRERGR+InzrnAisYmIgGXLoG1byJ8fnn3WkkqRrW4LFth87EmToGbNFJBUAhg1yt6ez5bNevS89d9A0qfKlWHYMDt+5RXYv9/deMQd8+bB6tW2Iebw4W5HIyIiIiKpjSqWJEF27fK0ul39YrRsWU+rW6FC7sV3XevXw+DBdjxhAhQr5m48Ii577TX48kubXd+pE/z4o3Kt6UlQEPTrZ8f9+7vcoiwiIiIiqZISSxJnFy7YDlKzZsFvv3nWAwOhVSsbxF2rVgqpSorNlSuW8QoLg2bNrMxKJJ3z8bE2uCpVrPpw0iR46SW3o5Lk8u67NgevaFFPO5yIiIiISHxoeHcCpZfh3RERlkSaOdOSSkFBtu7lBQ88YMmkxx+HgAA3o4yjXr1g7Fjb/mrLFsid2+2IRFKMiRPh5Zft//LGjXDbbW5HJEnt0CEoU8Z+r8+bZ28QiIiIiIiAhndLItizx9PqtnevZ/2226zVrW1bKFzYtfDi75dfYNw4O54+XUklkWu88ILtDLdsmQ3xXrHCqpkk7Ro40JJKdepAy5ZuRyMiIiIiqZUSSxLl4kX43/+s1e2XXzzrWbN6Wt3q1EnBrW7Xc+6cvVJ2HOjSBRo3djsikRTH2xtmzIBKleDPP2H0aM/sHUl71q61Nw4Axo9Phb/XRURERCTFUGIpnXMcq0yYNQs++wwuXbJ1Ly+47z5LJj3xBGTK5GaUt6h7d5swXrKktcKJSKyKFoX33rOqxMGD4ZFHbOc4SVscxzNP6Zln4M473Y1HRERERFI3JZbSsQkT7J3q3bs9a6VKWTKpXTt7kZnqLVpkb8t7e9uE4ixZ3I5IJEVr3x4WL4avvrLfA6tXg7+/21FJYvrf/+D3322e1ogRbkcjIiIiIqmdNpVOx/bssaRSliy2zfiKFbBjB7z+ehpJKh09Cl272nHfvlCvnrvxiKQCXl4wZYqNIdu4EYYNczsiSUxXrkCfPnb82mtQpIi78YiIiIhI6qdd4RIoLewKt327VSM0awaZM7sdTSJzHGjaFL79FqpWhb/+UtmFSDx8/jk89ZQV+61cCbVquR2RJIaRI212VsGC8N9/afB3v4iIiIgkivjkPFSxlI6VLWu7u6XJFxbTpllSyd8fPv5YSSWReGreHJ5+GiIirCUuKMjtiORWHTsGb71lxyNGpNHf/SIiIiKS7JRYkrRn1y7PZNq334aKFd2NRySVmjjRU9kyYIDb0citGjwYLlyAGjWgTRu3oxERERGRtEKJJUlbwsNt+vClS1C/vifBJCLxliMHTJ9ux++9B8uXuxuPJNymTVbICbY5prf++ouIiIhIItFTS0lbRo+GP/6ArFk9u8GJSII9/DB062bHHTvC+fPuxiPx5zjQs6e1NT71FNx9t9sRiYiIiEhaolfdknZs2GC9HgATJkCxYq6GI5JWjB4NJUrAvn0qAkyNvvkGli2zUXMjR7odjYiIiIikNUosSdpw5YoNDQkNhSeesGnDIpIoIgsAvbxgxgxLVEjqEBICvXrZ8auvWoJQRERERCQxKbEkacPrr8M//0C+fPDRR/YKWEQSzd13WzsVQJcucOqUu/FI3EyaBDt2QN68GsAuIiIiIklDiSVJ/X791abRgk2nzZPH3XhE0qjhw6F8eTh6FF54we1o5GZOnYKhQ+14+HDIls3deEREREQkbVJiSVK38+dtFzjHgWefhSZN3I5IJM3KmBHmzAEfH/jsM5g/3+2I5EaGDIGzZ6FyZejUye1oRERERCStUmJJUrfu3W2icMmSnqolEUkyNWpY5ylY1dKRI+7GI7H791+YPNmOx461ZKCIiIiISFJQYklSr8WLYdYs8Pa2MoqsWd2OSCRdGDgQqleHM2esUNBx3I5IrtW7N4SHw6OPwn33uR2NiIiIiKRlSixJ6nT0KHTtasd9+kC9eu7GI5KO+PnZLnEZMsCSJTB9utsRydV++MH+XXx9YfRot6MRERERkbROiSVJfRzHtqU6eRKqVPFMpxWRZFOhgg2EBtvGfs8ed+MRExbm2b3vpZegTBl34xERERGRtE+JJUl9pk+Hb74Bf3+YO9c+ikiye/VVuPtuuHgROnaEiAi3I5KpU2HrVsiZEwYPdjsaEREREUkPlFiS1GX3bns1C/DWW1CxorvxiKRjPj425ixzZvj1V3j/fbcjSt/OnvUkk4YOhRw5XA1HRERERNIJJZYk9QgPh3btrDzinns8CSYRcU3JkjBmjB337w/btrkbT3o2fLh1CJcrB926uR2NiIiIiKQXSixJ6vHuu/DHH7b72+zZ2j9bJIXo2hUeegiuXLHcb1iY2xGlPzt3eirGxoyxAesiIiIiIslBiSVJHTZsgEGD7Pj996F4cTejEZGreHnZ6LPs2WHNGhgxwu2I0p8+fSA01BJ8jRq5HY2IiIiIpCdKLEnKd+UKtG1rr5oefxzat3c7IhG5RqFCMHGiHQ8bBuvXuxtPerJ8OSxebEWcY8ZYok9EREREJLkosSQp36BBsGUL5M0LU6boVZNICvX00/Dkk9YK164dBAe7HVHaFx4OPXvacdeuUKGCu/GIiIiISPqjxJKkbL/+6pkMPG0a5Mnjbjwicl1eXjB5suWAt2zRdvfJYfZs6xQODLSd4EREREREkpsSS5JynT9vbW+OA507Q9OmbkckIjeRJ48VFgKMHm3z9iVpXLgAAwbY8aBByruLiIiIiDuUWJKUq0cP2LcPSpSAcePcjkZE4uixxzw54fbt4dIltyNKm955B44dg1Kl4KWX3I5GRERERNIrJZYkZfriC5g503pr5syBrFndjkhE4uG996BIEdi1y3Ysk8S1b5+nS/jddyFDBnfjEREREZH0S4klSXmOHYMuXey4Tx+46y534xGReAsMhBkz7HjSJFi61N140pp+/Ww4eoMGViEmIiIiIuIWJZYkZXEcSyqdPAmVK2sarUgqdv/98OKLdtyxI5w962o4acbKlTB/vhV0jhunjTJFRERExF1KLEnKMmMGfP01+PvD3Lnq7xBJ5UaOhNKl4dAh6N7d7WhSv4gIePVVO+7UCapWdTUcERERERElliQF2b3bBnYDDB8OlSq5Go6I3LrMmW1Mmre3ffziC7cjSt3mzYPVqyFLFvs1KSIiIiLiNiWWJGUID7ftoy5ehHvugZ493Y5IRBJJnTqeAd5du8Lx4+7Gk1oFBdlsJYD+/SF/fnfjEREREREBJZYkpXj3Xfj9d9v9bfZs8PFxOyIRSURDhlgR4okT8NxzNk5N4ufdd+HgQSha1NMOJyIiIiLiNiWWxH0bN8KgQXb83ntQvLir4YhI4suQwVrh/Pxg8WL45BO3I0pdDh2yeVUAo0ZBQIC78YiIiIiIRFJiSdwVHAxt20JoqO2Z3aGD2xGJSBKpWhXeeMOOX3rJqm8kbgYMsFa4unWhRQu3oxERERER8VBiSdw1aBBs3gx588KUKdo3WySN69sX7rwTzp2Dzp3VEhcXa9datRfAuHH6NSkiIiIiKYsSS+Ke336zoSEAU6dacklE0jRfXxujljEj/PgjfPih2xGlbI7jmafUpo0l5UREREREUhIllsQd58/bLnCOY2ULjz7qdkQikkzKlYN33rHj3r1h1y5340nJPv/c9jUICIARI9yORkREREQkJiWWxB2vvgp790KJEtbbISLpyssvQ8OGNjeofXsID3c7opTnyhXo08eOX3sNChd2Nx4RERERkdi4nliaNGkSJUqUIGPGjFSvXp0VK1bc8PwPPviA8uXLExAQQNmyZZkTOXji/y1atIgaNWqQPXt2MmfOTNWqVfn444+ve3sjRozAy8uLHj16JMbDkbj48kuYMcMGhcyeDVmzuh2RiCQzb2/7NZA1K/zxB4wd63ZEKc9771n+vWBBT4JJRERERCSlcTWxtGDBAnr06MHAgQNZv349d999N40aNWL//v2xnj958mT69+/PkCFD+Oeffxg6dCgvvvgiX3/9ddQ5OXPmZODAgfz5559s2rSJjh070rFjR3744YcYt7dmzRqmTJlC5cqVk+wxyjWOH4cuXez4tdfg7rvdjUdEXFO8uKdg8fXXYcsWV8NJUY4dg7fesuMRIyBzZnfjERERERG5Hi/HcW9Pnlq1alGtWjUmT54ctVa+fHkef/xxRsQyTKJu3brUq1eP0aNHR6316NGDtWvX8vvvv1/3fqpVq0bjxo158803o9YuXrxItWrVmDRpEsOHD6dq1aqMHz/+urcRHBxMcHBw1PXz589TpEgRzp07R7Zs2eL6kNM3x4HHH4evvoLKlWH1asiQwe2oRMRFjgNNm8K338Idd8Bff4Gfn9tRua9rV9vToEYN+554u15fLCIiIiLpyfnz5wkMDIxTzsO1p6ohISGsW7eOBx98MNr6gw8+yMqVK2P9muDgYDJmzBhtLSAggNWrVxMaGhrjfMdxWLZsGdu3b+eee+6J9rkXX3yRxo0bc//998cp3hEjRhAYGBh1KVKkSJy+Tq4yc6Yllfz94eOPlVQSEby8LIGSMyesXw/Dh7sdkfs2bYLp0+147FgllUREREQkZXPt6erJkycJDw8nX7580dbz5cvH0aNHY/2ahx56iGnTprFu3Tocx2Ht2rXMmDGD0NBQTp48GXXeuXPnyJIlC/7+/jRu3JgJEybwwAMPRH1+/vz5/P3337FWRV1P//79OXfuXNTlwIED8XzE6dyePdC9ux0PH24VSyIiQIECEFm4+tZbsGaNu/G4yXGgZ0+IiICnnlK3sIiIiIikfL5uB+Dl5RXtuuM4MdYiDRo0iKNHj1K7dm0cxyFfvnx06NCBUaNG4ePjE3Ve1qxZ2bBhAxcvXmTZsmX07NmTkiVL0qBBAw4cOED37t358ccfY1Q/3UiGDBnIoAqbhAkPt22fLl60V0k9e7odkYikMC1awKJFsGABtGsHf/8NAQFuR5X8vv4ali2zws6RI92ORkRERETk5lyrWMqdOzc+Pj4xqpOOHz8eo4opUkBAADNmzCAoKIi9e/eyf/9+ihcvTtasWcmdO3fUed7e3pQuXZqqVavSq1cvmjdvHlWdtG7dOo4fP0716tXx9fXF19eXX3/9lffffx9fX1/Cted14hszBlasgCxZbBe4q5KAIiKRPvgA8ueHbdtsmHd6ExICvXvb8auvQokS7sYjIiIiIhIXriWW/P39qV69OkuXLo22vnTpUurWrXvDr/Xz86Nw4cL4+Pgwf/58mjRpgvcNhlA4jhM1ePu+++5j8+bNbNiwIepSo0YNnnnmGTZs2BCt8kkSwaZNMGiQHb/3nl4pich15crlmS00bhz8+qu78SS3SZNgxw7ImxcGDHA7GhERERGRuHG1Fa5nz560bduWGjVqUKdOHaZMmcL+/ft57rnnAJtrdOjQIebMmQPAf//9x+rVq6lVqxZnzpxh7NixbNmyhdmzZ0fd5ogRI6hRowalSpUiJCSEJUuWMGfOnKid57JmzUrFihWjxZE5c2Zy5coVY11uUXAwtGljb8M/+ih07Oh2RCKSwj3yCDz7LEybBh06WG46a1a3o0p6p07B0KF2PHw4aLNREREREUktXE0stWzZklOnTjFs2DCOHDlCxYoVWbJkCcWKFQPgyJEj7N+/P+r88PBwxowZw/bt2/Hz86Nhw4asXLmS4sWLR51z6dIlXnjhBQ4ePEhAQADlypVj7ty5tGzZMrkfngweDJs3Q548tu3TdWZniYhcbcwYWLoU9u6FXr1gyhS3I0p6Q4bA2bO2r0GnTm5HIyIiIiISd16O4zhuB5EanT9/nsDAQM6dO0c2vbUc04oVUL++bXH0xRfw2GNuRyQiqcgvv0DDhna8ZAk0auRqOEnq33+hUiXb52DZMrj3XrcjEhEREZH0Lj45D9dmLEkaduGC7QLnOPbWu5JKIhJPDRpAjx523LkznD7tZjRJq3dvSyo9+qiSSiIiIiKS+iixJInv1Vdhzx4oXtwm8IqIJMDbb0PZsnDkCLz0ktvRJI0ffrCKLF9fGD3a7WhEREREROJPiSVJXF9+ads6eXnBnDmaQCsiCRYQYL9GfHxg3jxYuNDtiBJXWBj07GnHL70EZcq4G4+IiIiISEIosSSJ5/hx6NLFjnv3hrvvdjceEUn17rwT+ve34+efh6NH3Y0nMU2dClu3Qs6ctteBiIiIiEhqpMSSJA7Hga5d4cQJm0L75ptuRyQiacSgQXDHHXDqlP2aSQtbTpw9a48LYOhQyJHD1XBERERERBJMiSVJHLNmWRucnx98/DFkyOB2RCKSRvj7W0ucvz98/bX9uknthg+3RFm5ctCtm9vRiIiIiIgknBJLcuv27oXu3e14+HCoUsXVcEQk7alY0VMI2b077Nvnbjy3YudOeP99Ox471vLxIiIiIiKplRJLcmvCw6FdO7hwwWYq9erldkQikkb16gV169qvm44dISLC7YgS5rXXIDQUHnoIGjVyOxoRERERkVujxJLcmrFjYcUKyJIFZs+27ZtERJKAj4/9msmUCZYvhw8+cDui+Fu+HL74wh7LmDFuRyMiIiIicuuUWJKE27QJXn/djsePhxIlXA1HRNK+0qVh9Gg77tsX/vvP3XjiIzwceva0427doEIFd+MREREREUkMSixJwgQHQ9u2EBICTZtCp05uRyQi6cTzz8MDD8Dly9aJGxbmdkRxM2sWbNgAgYG2E5yIiIiISFqgxJIkzBtvWMVSnjwwdSp4ebkdkYikE15eMH26JWj++gtGjXI7opu7cAEGDrTjQYMgd2534xERERERSSxKLEn8/f6755XclCmQL5+78YhIulOkiGdntSFDYONGV8O5qXfegWPHrJXv5ZfdjkZEREREJPEosSTxc+GC9Z44jm3L9PjjbkckIulU27b2Kyg01H4tBQe7HVHs9u3zDOoePRr8/d2NR0REREQkMSmxJPHz6quwZw8UL24Du0VEXOLlBR99ZG1lmzal3LlFffta0qtBA3jsMbejERERERFJXEosSdx99ZUNNvHysj2/s2VzOyIRSefy5rXkEsDIkfDnn+7Gc62VK2HBAvu1OW6cxtGJiIiISNqjxJLEzYkT0KWLHffqBffc4248IiL/r1kzaNMGIiKgfXsICnI7IhMRYUWeYBtnVq3qajgiIiIiIklCiSW5OceBrl3h+HGoWBHefNPtiEREopkwAQoVgh07oF8/t6Mxn34Kq1dDliwwfLjb0YiIiIiIJA0lluTmZs+GL74APz+YOxcyZnQ7IhGRaLJnhxkz7HjCBFi2zNVwCAqC/v3tuH9/yJ/f3XhERERERJKKEktyY3v3wiuv2PGbb0KVKq6GIyJyPQ8+CM89Z8cdO8K5c+7F8u67cPAgFCvmaYcTEREREUmLlFiS6wsPt4ElFy7AXXdB795uRyQickOjR0PJknDggHsJnUOHbJA42MeAAHfiEBERERFJDkosyfWNGwe//WYDQmbPBh8ftyMSEbmhyF9XXl4wcyZ8/XXyxzBggLXC1a0LLVok//2LiIiIiCQnJZYkdps3w8CBdjxunJUAiIikAlcXWHbpAidPJt99r10Lc+bY8bhxluASEREREUnLlFiSmIKDoW1bCAmBpk2hc2e3IxIRiZdhw6BCBTh2DJ5/3ja3TGqOAz162HGbNnDnnUl/nyIiIiIiblNiSWIaMgQ2boTcuWHqVL3lLiKpTsaMVjnk6wuffw7z5yf9fX7+Ofzxh81UGjEi6e9PRERERCQlUGJJovvjDxg1yo6nToV8+dyNR0QkgapVg0GD7PjFF+Hw4aS7rytXoE8fO37tNShcOOnuS0REREQkJVFiSTwuXIB27SAiAjp0gMcfdzsiEZFb0r8/1KgBZ85YV29StcS99x7s3QsFC3oSTCIiIiIi6YESS+LRsyfs3g3FitmrJBGRVM7Pz3aJy5ABvv/eCjET27Fj8NZbdjxiBGTOnPj3ISIiIiKSUimxJObrr2HaNJunNHs2ZMvmdkQiIoni9tvh7bftODJ/npgGDbKCzxo1bGi3iIiIiEh6osSSwIkT8OyzdtyzJ9Sv7248IiKJrEcPuOceuHQJOna0jt/EsHEjTJ9ux+PGgbf+qoqIiIhIOqOnwOmd40C3bnD8OFSsCMOHux2RiEii8/aGWbOsTe2332D8+Fu/TcexXHxEBDz1FNx1163fpoiIiIhIaqPEUno3Zw4sXmyDSD7+2PboFhFJg0qUgLFj7XjAANi69dZu7+uv4eefwd8fRo689fhERERERFIjJZbSs3374OWX7XjYMKha1dVwRESSWpcu0KgRBAdD+/YQGpqw2wkJgd697bhnT0taiYiIiIikR0ospWddu9rE2Xr14LXX3I5GRCTJeXnZPgU5csDatbaLW0J88AHs2AF580L//okbo4iIiIhIaqLEUno2ahTUqWO7wPn4uB2NiEiyKFjQEkMAb74J69bF7+tPnbIiT7CxdNpEU0RERETSMyWW0rMqVeCPP6BUKbcjERFJVq1aQfPmEBYG7drBlStx/9ohQ+DsWahcGTp1SqoIRURERERSByWW0jsvL7cjEBFJdl5eMHky5MtnQ7wHD47b123dal8HMG6cij1FRERERJRYEhGRdCl3bpg61Y7ffRd+//3mX9O7N4SHw6OPwr33Jm18IiIiIiKpgRJLIiKSbjVtCh07guPYLnEXL17/3B9+gO++A19fGD06+WIUEREREUnJlFgSEZF0bfx4KFoUdu++/gaZYWHQs6cdv/wylCmTbOGJiIiIiKRoSiyJiEi6li0bzJxpxx9+aJVJ15oyxeYr5coFgwYlb3wiIiIiIimZEksiIpLu3XuvVSIBdO4MZ854Pnf2rGe495AhkCNHckcnIiIiIpJyKbEkIiICvPOOtbgdOgSvvOJZHz4cTp2C8uWhWzf34hMRERERSYmUWBIREQEyZYLZs8HbG+bOhUWLYMcOeP99+/yYMeDn526MIiIiIiIpjRJLIiIi/692bejb1467dYMXXoDQUHjoIWjUyN3YRP6vvXuPqbp+/Dj+OiCXAx3xwkBIU8pS1AwBv15Ap1kkXibO0pya2JZfJpDEampK3j376rxsGhSmfvOWzqVJfSkjm3jLgSRiRtjWFuQlpBwgLlT4/P5ont/v/FCz8xU+eng+trNx3ud9znl9/ni7+dr78z4AAAAPIothGIbZIR5GNTU1CggIUHV1tdq2bWt2HADAfVJfL/3jH1JJyZ/PPT2l06el3r3NzQUAAAC0lL/TebBjCQCA/8PHR9q27X9ve/vnPymVAAAAgDtpY3YAAAAeNH37Sv/+t/Sf/0hLl5qdBgAAAHhwcSuci7gVDgAAAAAAuCNuhQMAAAAAAECzo1gCAAAAAACASyiWAAAAAAAA4BKKJQAAAAAAALiEYgkAAAAAAAAuMb1YyszMVFhYmHx9fRUVFaUjR47cdf67776r8PBwWa1W9ejRQ1u3bnV6fe/evYqOjla7du3k7++viIgIbdu2zWmO3W5X//79ZbPZFBQUpISEBJWVld33awMAAAAAAHBnphZLu3fvVlpamubPn69Tp05pyJAhio+PV3l5+W3nZ2Vlad68eVq0aJHOnj2rxYsXKzk5WZ9++qljTocOHTR//nx98803Kikp0YwZMzRjxgwdOHDAMSc/P1/Jyck6ceKE8vLydPPmTcXFxamurq7ZrxkAAAAAAMBdWAzDMMz68gEDBigyMlJZWVmOsfDwcCUkJMhutzeZP3jwYMXExGjVqlWOsbS0NJ08eVJHjx694/dERkZq9OjRWrp06W1fv3z5soKCgpSfn6+hQ4feU/aamhoFBASourpabdu2vaf3AAAAAAAAPOj+Tudh2o6l69evq6ioSHFxcU7jcXFxOn78+G3fU19fL19fX6cxq9WqgoIC3bhxo8l8wzB08OBBlZWV3bUwqq6ulvTnbqc7qa+vV01NjdMDAAAAAACgNTOtWKqqqlJDQ4OCg4OdxoODg3Xp0qXbvueFF17QBx98oKKiIhmGoZMnT2rz5s26ceOGqqqqHPOqq6v1yCOPyNvbW6NHj9b69ev1/PPP3/YzDcNQenq6YmNj1adPnzvmtdvtCggIcDy6dOniwlUDAAAAAAC4D9MP77ZYLE7PDcNoMnZLRkaG4uPjNXDgQHl5eWncuHFKTEyUJHl6ejrm2Ww2FRcXq7CwUMuXL1d6eroOHTp0289MSUlRSUmJPvroo7vmnDdvnqqrqx2PioqKe79IAAAAAAAAN9TGrC8ODAyUp6dnk91JlZWVTXYx3WK1WrV582a9//77+vXXXxUSEqLs7GzZbDYFBgY65nl4eKh79+6SpIiICJWWlsput2vYsGFOn5eamqqcnBwdPnxYnTt3vmteHx8f+fj4OJ7fOpqKW+IAAAAAAIA7udV13Mux3KYVS97e3oqKilJeXp7Gjx/vGM/Ly9O4cePu+l4vLy9HEbRr1y6NGTNGHh533nxlGIbq6+udnqempmrfvn06dOiQwsLC/nb+2tpaSeKWOAAAAAAA4JZqa2sVEBBw1zmmFUuSlJ6ermnTpik6OlqDBg1Sdna2ysvLlZSUJOnP28/Onz+vrVu3SpLOnTungoICDRgwQFeuXNGaNWv03Xff6cMPP3R8pt1uV3R0tJ544gldv35dubm52rp1q9MvzyUnJ2vnzp3av3+/bDabY9dUQECArFbrPWUPDQ1VRUWFbDbbHW/de9DV1NSoS5cuqqio4JftgGbGegNaBmsNaBmsNaBlsNZgFsMwVFtbq9DQ0L+ca2qxNGnSJP32229asmSJLl68qD59+ig3N1ddu3aVJF28eFHl5eWO+Q0NDVq9erXKysrk5eWl4cOH6/jx4+rWrZtjTl1dnWbNmqVffvlFVqtVPXv21Pbt2zVp0iTHnFsl0/+/NW7Lli2OM5v+ioeHx1/ePvewaNu2Lf9IAS2E9Qa0DNYa0DJYa0DLYK3BDH+1U+kWi3EvN8zBLdXU1CggIEDV1dX8IwU0M9Yb0DJYa0DLYK0BLYO1hoeB6b8KBwAAAAAAgIcTxVIr5uPjo4ULFzr92h2A5sF6A1oGaw1oGaw1oGWw1vAw4FY4AAAAAAAAuIQdSwAAAAAAAHAJxRIAAAAAAABcQrEEAAAAAAAAl1AsAQAAAAAAwCUUS61YZmamwsLC5Ovrq6ioKB05csTsSIBbsdvt6t+/v2w2m4KCgpSQkKCysjKzYwFuz263y2KxKC0tzewogFs6f/68pk6dqo4dO8rPz08REREqKioyOxbgVm7evKkFCxYoLCxMVqtVjz/+uJYsWaLGxkazowFNUCy1Urt371ZaWprmz5+vU6dOaciQIYqPj1d5ebnZ0QC3kZ+fr+TkZJ04cUJ5eXm6efOm4uLiVFdXZ3Y0wG0VFhYqOztbffv2NTsK4JauXLmimJgYeXl56fPPP9f333+v1atXq127dmZHA9zKv/71L7333nvasGGDSktLtXLlSq1atUrr1683OxrQhMUwDMPsEGh5AwYMUGRkpLKyshxj4eHhSkhIkN1uNzEZ4L4uX76soKAg5efna+jQoWbHAdzO1atXFRkZqczMTC1btkwRERFat26d2bEAtzJ37lwdO3aMne5AMxszZoyCg4O1adMmx9iECRPk5+enbdu2mZgMaIodS63Q9evXVVRUpLi4OKfxuLg4HT9+3KRUgPurrq6WJHXo0MHkJIB7Sk5O1ujRo/Xcc8+ZHQVwWzk5OYqOjtZLL72koKAg9evXTxs3bjQ7FuB2YmNjdfDgQZ07d06SdPr0aR09elSjRo0yORnQVBuzA6DlVVVVqaGhQcHBwU7jwcHBunTpkkmpAPdmGIbS09MVGxurPn36mB0HcDu7du3St99+q8LCQrOjAG7tp59+UlZWltLT0/X222+roKBAr7/+unx8fPTKK6+YHQ9wG3PmzFF1dbV69uwpT09PNTQ0aPny5Zo8ebLZ0YAmKJZaMYvF4vTcMIwmYwDuj5SUFJWUlOjo0aNmRwHcTkVFhWbPnq0vv/xSvr6+ZscB3FpjY6Oio6O1YsUKSVK/fv109uxZZWVlUSwB99Hu3bu1fft27dy5U71791ZxcbHS0tIUGhqq6dOnmx0PcEKx1AoFBgbK09Ozye6kysrKJruYAPz3UlNTlZOTo8OHD6tz585mxwHcTlFRkSorKxUVFeUYa2ho0OHDh7VhwwbV19fL09PTxISA+wgJCVGvXr2cxsLDw/Xxxx+blAhwT2+99Zbmzp2rl19+WZL09NNP6+eff5bdbqdYwgOHM5ZaIW9vb0VFRSkvL89pPC8vT4MHDzYpFeB+DMNQSkqK9u7dq6+//lphYWFmRwLc0ogRI3TmzBkVFxc7HtHR0ZoyZYqKi4splYD7KCYmRmVlZU5j586dU9euXU1KBLina9euycPD+b/rnp6eamxsNCkRcGfsWGql0tPTNW3aNEVHR2vQoEHKzs5WeXm5kpKSzI4GuI3k5GTt3LlT+/fvl81mc+wSDAgIkNVqNTkd4D5sNluTs8v8/f3VsWNHzjQD7rM33nhDgwcP1ooVKzRx4kQVFBQoOztb2dnZZkcD3MrYsWO1fPlyPfbYY+rdu7dOnTqlNWvW6NVXXzU7GtCExTAMw+wQMEdmZqZWrlypixcvqk+fPlq7di0/gQ7cR3c6s2zLli1KTExs2TBAKzNs2DBFRERo3bp1ZkcB3M5nn32mefPm6ccff1RYWJjS09P12muvmR0LcCu1tbXKyMjQvn37VFlZqdDQUE2ePFnvvPOOvL29zY4HOKFYAgAAAAAAgEs4YwkAAAAAAAAuoVgCAAAAAACASyiWAAAAAAAA4BKKJQAAAAAAALiEYgkAAAAAAAAuoVgCAAAAAACASyiWAAAAAAAA4BKKJQAAAAAAALiEYgkAAMCNWSwWffLJJ2bHAAAAbopiCQAAoJkkJibKYrE0eYwcOdLsaAAAAPdFG7MDAAAAuLORI0dqy5YtTmM+Pj4mpQEAALi/2LEEAADQjHx8fNSpUyenR/v27SX9eZtaVlaW4uPjZbVaFRYWpj179ji9/8yZM3r22WdltVrVsWNHzZw5U1evXnWas3nzZvXu3Vs+Pj4KCQlRSkqK0+tVVVUaP368/Pz89OSTTyonJ6d5LxoAALQaFEsAAAAmysjI0IQJE3T69GlNnTpVkydPVmlpqSTp2rVrGjlypNq3b6/CwkLt2bNHX331lVNxlJWVpeTkZM2cOVNnzpxRTk6Ounfv7vQdixcv1sSJE1VSUqJRo0ZpypQp+v3331v0OgEAgHuyGIZhmB0CAADAHSUmJmr79u3y9fV1Gp8zZ44yMjJksViUlJSkrKwsx2sDBw5UZGSkMjMztXHjRs2ZM0cVFRXy9/eXJOXm5mrs2LG6cOGCgoOD9eijj2rGjBlatmzZbTNYLBYtWLBAS5culSTV1dXJZrMpNzeXs54AAMB/jTOWAAAAmtHw4cOdiiNJ6tChg+PvQYMGOb02aNAgFRcXS5JKS0v1zDPPOEolSYqJiVFjY6PKyspksVh04cIFjRgx4q4Z+vbt6/jb399fNptNlZWVrl4SAACAA8USAABAM/L3929ya9pfsVgskiTDMBx/326O1Wq9p8/z8vJq8t7Gxsa/lQkAAOB2OGMJAADARCdOnGjyvGfPnpKkXr16qbi4WHV1dY7Xjx07Jg8PDz311FOy2Wzq1q2bDh482KKZAQAAbmHHEgAAQDOqr6/XpUuXnMbatGmjwMBASdKePXsUHR2t2NhY7dixQwUFBdq0aZMkacqUKVq4cKGmT5+uRYsW6fLly0pNTdW0adMUHBwsSVq0aJGSkpIUFBSk+Ph41dbW6tixY0pNTW3ZCwUAAK0SxRIAAEAz+uKLLxQSEuI01qNHD/3www+S/vzFtl27dmnWrFnq1KmTduzYoV69ekmS/Pz8dODAAc2ePVv9+/eXn5+fJkyYoDVr1jg+a/r06frjjz+0du1avfnmmwoMDNSLL77YchcIAABaNX4VDgAAwCQWi0X79u1TQkKC2VEAAABcwhlLAAAAAAAAcAnFEgAAAAAAAFzCGUsAAAAm4UQCAADwsGPHEgAAAAAAAFxCsQQAAAAAAACXUCwBAAAAAADAJRRLAAAAAAAAcAnFEgAAAAAAAFxCsQQAAAAAAACXUCwBAAAAAADAJRRLAAAAAAAAcMn/ALBHMOb1/Q0bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the training and validation accuracies as functions of epoch\n",
    "plt.figure(figsize = (14, 4))\n",
    "\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'accuracy', color = 'red', label = 'Training')\n",
    "sns.lineplot(data = hist, x = 'epoch', y = 'val_accuracy', color = 'blue', label = 'Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy as a Function of Epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRQVlebC3agy"
   },
   "source": [
    "Evaluate the performance of the model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "Gws1IXkFv6Ka"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.1873\n",
      "The loss value of the model on the test data is 0.19693484902381897\n",
      "The accuracy of the model on the test data is 0.939466655254364\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy of the model on the testing data set using the 'evaluate()' method\n",
    "performance_test = nn2.evaluate(X_test, y_test)\n",
    "\n",
    "print('The loss value of the model on the test data is {}'.format(performance_test[0]))\n",
    "print('The accuracy of the model on the test data is {}'.format(performance_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n56Gz3vc3vJ3"
   },
   "source": [
    "**Checklist:**\n",
    "- Importing necessary libraries for machine learning and deep learning\n",
    "- Preprocessed the data\n",
    "- Divided the data set into train and test splits\n",
    "- Handled class imbalance using random undersampling and random oversampling\n",
    "- Built and evaluated different machine learning models such as logistic regression, decision trees, KNN and random forest models with and without treating class imbalance\n",
    "- Tuned the best machine learning using GridSearchCV for the optimal hyperparameters\n",
    "- Built and evaluated a neural network model and tuned for its hyperparameters using GridSearchCV and RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juV5XGj_d81q"
   },
   "source": [
    "## Task 6: Business Insights: Misclassification Costs\n",
    "Our first step is to understand the current profitability of the telecomminucation service program, and then to is to estimate the impact of our model. We are going to use misclassification costs to study the impact.\n",
    "\n",
    "We are going to use \\$500 as an approximation company loss for the false negative cost, and \\$300 company loss for the false positive cost. Note: We are interested in finding the best cut-off that will maximize the benefit of our machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "shUswx0DDI5n"
   },
   "outputs": [],
   "source": [
    "# Define the false positive and false negative missclassification cost here\n",
    "\n",
    "fn_cost = 500\n",
    "fp_cost = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8L6GR6vDJNy"
   },
   "source": [
    "#### We will use the optimal model and its corresponding data set that was implemented in the GridSearchCV section. Let's first see the performance metrics of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "fgrZKCfs-8WO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-17 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-17 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-17 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-17 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-17 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=30, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=30, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=30, random_state=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the most optimal machine learning model that you obtained from the GridSearchCV section and the corresponding data set you used (normal, RUS or ROS)\n",
    "best_model_ = DecisionTreeClassifier( max_depth = best_params_ , random_state = 0)\n",
    "best_model_.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Evaluating the accuracy of the training and validation sets\n",
    "tree_train_acc = best_model_.score(X_train_ros, y_train_ros)\n",
    "tree_val_acc = best_model_.score(X_test_ros, y_test_ros)\n",
    "\n",
    "# Calculate the F1 score, Precision and Recall on the validation set\n",
    "y_pred_train = best_model_.predict(X_train_ros)\n",
    "y_pred_test = best_model_.predict(X_test_ros)\n",
    "f_score = f1_score(y_test_ros, y_pred_test, average = 'weighted')\n",
    "precision = precision_score(y_test_ros, y_pred_test)\n",
    "recall = metrics.recall_score(y_test_ros, y_pred_test)\n",
    "\n",
    "model_name =  'Decision Tree - Random Oversampling'\n",
    "# creating a dataframe to compare the performance of different models\n",
    "new_model_eval_data = [[model_name, tree_train_acc, tree_val_acc, f_score, precision, recall]]\n",
    "new_evaluate_df = pd.DataFrame(new_model_eval_data, columns=['Model Name', 'Training Score', 'Testing Score',\n",
    "                                          'F1 Score', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "IXgdIhgRCRgR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree - Random Oversampling</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>0.973512</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.94969</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model Name  Training Score  Testing Score  \\\n",
       "0  Decision Tree - Random Oversampling        0.998186       0.973512   \n",
       "\n",
       "   F1 Score  Precision  Recall  \n",
       "0  0.973494    0.94969     1.0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_evaluate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5RZ7kZgCd5L"
   },
   "source": [
    "#### We now calculate the current misclassification cost in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "xZybKG6aCh0T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of False Positives: 146\n",
      "Number of False Negatives: 0\n",
      "Prediction Misclassification Cost: 43800.00\n"
     ]
    }
   ],
   "source": [
    "# Obtain the count of false positive and false negative classifications from your model\n",
    "cf = confusion_matrix(y_test_ros, y_pred_test)\n",
    "\n",
    "fp_count = cf[0,1]\n",
    "fn_count = cf[1,0]\n",
    "\n",
    "# Calculate the total misclassification cost using the FN and FP cost and FN and FP count\n",
    "misclassification_cost = fp_count * fp_cost + fn_count * fn_cost \n",
    "\n",
    "print('Number of False Positives: %d' % fp_count)\n",
    "print('Number of False Negatives: %d' % fn_count)\n",
    "print('Prediction Misclassification Cost: %.2f' % misclassification_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Au5XGxGbDdVC"
   },
   "source": [
    "#### We now calculate the misclassification cost as we raise the cut-off value from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "jdzrfvyiDt1E"
   },
   "outputs": [],
   "source": [
    "# Predict probabilities for the training set and retain them for only positive outcomes\n",
    "lr_probs_train =best_model_.predict_proba(X_train_ros)[:, 1]\n",
    "\n",
    "# Predict probabilities for the validation set and retain them for only positive outcomes\n",
    "lr_probs_test = best_model_.predict_proba(X_test_ros)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "EOx1ry1MDfbN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Misclassification Cost on the training is 12000.00 at Cut-off 0.000\n",
      "Applying that cut-off to the validation data results in Misclassification Cost of 43800.00 \n"
     ]
    }
   ],
   "source": [
    "# Calculate and store the misclassification costs for different values of cut-off probability\n",
    "cost_train = []\n",
    "cost_val=[]\n",
    "\n",
    "for cutoff in np.arange(0, 1, 0.01):\n",
    "    # Get the classification predictions using the probabilities obtained for the training data set and the cutoff\n",
    "    # Get the false positive and false negative count from the predictions\n",
    "    # Calculate the training misclassification cost and append it to the cost_train array\n",
    "    curr_preds = np.where(lr_probs_train > cutoff ,1 , 0)\n",
    "    curr_cf = confusion_matrix(y_train_ros, curr_preds)\n",
    "    curr_fp_count = curr_cf[0,1]\n",
    "    curr_fn_count = curr_cf[1,0]\n",
    "    \n",
    "    curr_misclassification_cost = curr_fp_count * fp_cost + curr_fn_count * fn_cost\n",
    "    cost_train.append(curr_misclassification_cost)\n",
    "\n",
    "    # Get the classification predictions using the probabilities obtained for the validation data set and the cutoff\n",
    "    # Get the false positive and false negative count from the predictions\n",
    "    # Calculate the training misclassification cost and append it to the cost_val array\n",
    "    curr_preds = np.where(lr_probs_test > cutoff , 1, 0)\n",
    "    curr_cf = confusion_matrix(y_test_ros, curr_preds)\n",
    "    curr_fp_count = curr_cf[0,1]\n",
    "    curr_fn_count = curr_cf[1,0]\n",
    "    \n",
    "    curr_misclassification_cost = curr_fp_count * fp_cost + curr_fn_count * fn_cost\n",
    "    cost_val.append(curr_misclassification_cost)\n",
    "\n",
    "\n",
    "# Get the X values (cut-off values)\n",
    "cutoffs = np.arange(0, 1, 0.01)\n",
    "\n",
    "# Plot misclassification cost against cut-off value\n",
    "plt.plot(cutoffs,cost_train, label='Training')\n",
    "plt.plot(cutoffs,cost_val, label='Validaiton')\n",
    "plt.xlabel('Cut-off')\n",
    "plt.ylabel('Misclassification Cost')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Find the minimum misclassification cost and its associated cut-off value based on the training data\n",
    "best_cost = min(cost_train)\n",
    "best_cutoff = cutoffs[cost_train.index(best_cost)]\n",
    "\n",
    "#apply the cut-off value to the validation data\n",
    "best_valcost = cost_val[cost_train.index(best_cost)]\n",
    "\n",
    "\n",
    "print('Best Misclassification Cost on the training is %.2f at Cut-off %.3f' % (best_cost, best_cutoff));\n",
    "print('Applying that cut-off to the validation data results in Misclassification Cost of %.2f ' % best_valcost);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yfGnZZE3yaR"
   },
   "source": [
    "Checklist:\n",
    " - Chose the optimal model and calculated the current misclassification cost in the validation set\n",
    " - Calculated the misclassification cost for different values of cut-off value from 0 to 1\n",
    " - Found the minimum misclassification cost and its associated best cut-off value based on the training data\n",
    " - Applyied the same cut-off to the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nX4iEYxM14xL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
